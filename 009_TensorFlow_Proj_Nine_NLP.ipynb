{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp9eEC9IChwW73mjt5ocgF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ariahosseini/DeepML/blob/main/009_TensorFlow_Proj_Nine_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-a1tZp3Tap-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os, sys, warnings, pathlib, shutil, random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(action=\"ignore\")"
      ],
      "metadata": {
        "id": "UOcCxTvOT-nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tensorflow:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ntA6_snT-jc",
        "outputId": "2897e5ef-c089-4efb-f844-72ff8688d797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow: 2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEkWg9SxT_DO",
        "outputId": "63d018b9-c8b5-4aa6-9de6-8e9ebfdf2c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  51.0M      0  0:00:01  0:00:01 --:--:-- 51.0M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "id": "Xdlmk2PfT_GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat aclImdb/train/pos/10001_10.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gavsB2u8T_Jg",
        "outputId": "c34a63fb-c76c-48b6-ecab-a886731461b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brilliant over-acting by Lesley Ann Warren. Best dramatic hobo lady I have ever seen, and love scenes in clothes warehouse are second to none. The corn on face is a classic, as good as anything in Blazing Saddles. The take on lawyers is also superb. After being accused of being a turncoat, selling out his boss, and being dishonest the lawyer of Pepto Bolt shrugs indifferently \"I'm a lawyer\" he says. Three funny words. Jeffrey Tambor, a favorite from the later Larry Sanders show, is fantastic here too as a mad millionaire who wants to crush the ghetto. His character is more malevolent than usual. The hospital scene, and the scene where the homeless invade a demolition site, are all-time classics. Look for the legs scene and the two big diggers fighting (one bleeds). This movie gets better each time I see it (which is quite often)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = pathlib.Path(\"aclImdb\") # define the directories that will be used to store the data.\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(val_dir / category) # Creates a subdirectory in val_dir with the name of the category (e.g. \"val/neg\").\n",
        "    files = os.listdir(train_dir / category) # Lists all the files in the corresponding category directory in train_dir.\n",
        "    random.Random(1337).shuffle(files) # Shuffles the list of files in a reproducible way using a fixed seed (1337).\n",
        "    num_val_samples = int(0.2 * len(files)) # Calculates the number of validation samples as 20% of the total number of files in the category.\n",
        "    val_files = files[-num_val_samples:] # Selects the last num_val_samples files in the shuffled list as the validation files.\n",
        "    for fname in val_files: # Moves each validation file from train_dir to val_dir for the current category using shutil.move()\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)\n"
      ],
      "metadata": {
        "id": "5eyS6aLuWzcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size=batch_size)\n",
        "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size)\n",
        "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdE1J_SyWzf-",
        "outputId": "713b6a34-174b-4e12-960b-13c03c74c140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuL-LCDWWzjV",
        "outputId": "015a848d-5b29-47a6-ebae-e0e2a8502ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b\"The Gospel of Lou was a major disappointment for me. I had received an E-Mail from the theater showing it that it was a great and inspirational movie. It was neither great nor inspirational. The cinematography was pretty iffy with the whole movie. A lot the scenes were flash backs that were done in a way that couldn't tell at times what they were about. The voices were often distorted for no reason. Also many of the people in the movie were far fetched. The relationship he has with his ex & son is never made clear. Also the whole movie has most him one way, and then all of a sudden BAM, he is cured and inspiring people. The whole movie seems to show that boxing is one of the things that is bad in his life, making him live his life the way that he is living it, but when he changes, he doesn't leave boxing, he teaches others how to box. Thumbs Down.\", shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ") # This layer will be used to vectorize the textual data in the datasets.\n",
        "\n",
        "# prepare the TextVectorization layer for use by fitting it to the training dataset.\n",
        "text_only_train_ds = train_ds.map(lambda x,y : x) # discarding the labels y.\n",
        "text_vectorization.adapt(text_only_train_ds) #  adapt method analyzes the text data to generate a vocabulary and configure the layer's settings for text processing.\n",
        "\n",
        "# creating new datasets with the vectorized data\n",
        "binary_1gram_train_ds = train_ds.map(\n",
        "    lambda x,y : (text_vectorization(x), y),\n",
        "    num_parallel_calls=4) #  The num_parallel_calls argument specifies the number of parallel calls to use for the mapping operation, which can speed up processing for large datasets.\n",
        "binary_1gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_1gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "7FOAGy4zWzmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in binary_1gram_train_ds.take(1):\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcM0ZDCTWzpp",
        "outputId": "6318ad0d-6b94-4b98-bb63-743db48addb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32, 20000)\n",
            "inputs.dtype: <dtype: 'float32'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor([0. 1. 0. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(max_tokens=20000, hidden_dim=16):\n",
        "    inputs = tf.keras.Input(shape=(max_tokens,))\n",
        "    x = tf.keras.layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "z42Qi7oXWztG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7SJOB5BdnLN",
        "outputId": "ec0da5bf-fbc8-495e-a061-3e02c65627ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320033 (1.22 MB)\n",
            "Trainable params: 320033 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(binary_1gram_train_ds.cache(),\n",
        "          validation_data=binary_1gram_val_ds.cache(),\n",
        "          epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yJ3AtAwdnO2",
        "outputId": "e20b5a56-8262-4931-ff55-3493c6713004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 0.4014 - accuracy: 0.8296 - val_loss: 0.2808 - val_accuracy: 0.8874\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2682 - accuracy: 0.9009 - val_loss: 0.2789 - val_accuracy: 0.8944\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2421 - accuracy: 0.9128 - val_loss: 0.2930 - val_accuracy: 0.8960\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 6ms/step - loss: 0.2229 - accuracy: 0.9259 - val_loss: 0.3033 - val_accuracy: 0.8958\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2148 - accuracy: 0.9303 - val_loss: 0.3199 - val_accuracy: 0.8978\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2132 - accuracy: 0.9319 - val_loss: 0.3268 - val_accuracy: 0.8960\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2169 - accuracy: 0.9309 - val_loss: 0.3425 - val_accuracy: 0.8950\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2070 - accuracy: 0.9352 - val_loss: 0.3487 - val_accuracy: 0.8972\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1997 - accuracy: 0.9366 - val_loss: 0.3623 - val_accuracy: 0.8954\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1994 - accuracy: 0.9374 - val_loss: 0.3699 - val_accuracy: 0.8912\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7db254f60670>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZxBOCEjdnSS",
        "outputId": "b82471a6-7d77-49e2-d4a6-8a13f8cf6303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 8ms/step - loss: 0.3764 - accuracy: 0.8824\n",
            "Test acc: 0.882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization = tf.keras.layers.TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "binary_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "model = get_model()\n",
        "model.fit(binary_2gram_train_ds.cache(),\n",
        "          validation_data=binary_2gram_val_ds.cache(),\n",
        "          epochs=3)\n",
        "print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrqxrZQ4dnVH",
        "outputId": "164fbcd3-f196-4054-a1db-748a6cb5a27e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 11s 16ms/step - loss: 0.3790 - accuracy: 0.8456 - val_loss: 0.2752 - val_accuracy: 0.8926\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2360 - accuracy: 0.9136 - val_loss: 0.2682 - val_accuracy: 0.9010\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1986 - accuracy: 0.9339 - val_loss: 0.2925 - val_accuracy: 0.9002\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.2952 - accuracy: 0.8927\n",
            "Test acc: 0.893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization = tf.keras.layers.TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"tf_idf\",\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "binary_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "model = get_model()\n",
        "model.fit(binary_2gram_train_ds.cache(),\n",
        "          validation_data=binary_2gram_val_ds.cache(),\n",
        "          epochs=3)\n",
        "print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLywDGzydnZR",
        "outputId": "326b25ed-9143-4dd3-b7a7-306029de385a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.5257 - accuracy: 0.7534 - val_loss: 0.3004 - val_accuracy: 0.8950\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.3368 - accuracy: 0.8620 - val_loss: 0.2918 - val_accuracy: 0.8940\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2911 - accuracy: 0.8810 - val_loss: 0.3057 - val_accuracy: 0.8720\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.3152 - accuracy: 0.8696\n",
            "Test acc: 0.870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 600\n",
        "max_tokens = 20000\n",
        "text_vectorization = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=max_tokens, output_dim=256)\n",
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = tf.keras.layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32))(embedded)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=1)\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl-bvFvmdndW",
        "outputId": "d09e8702-cd3a-4731-bacf-2cb3336af84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, None, 256)         5120000   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 64)                73984     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5194049 (19.81 MB)\n",
            "Trainable params: 5194049 (19.81 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "625/625 [==============================] - 455s 722ms/step - loss: 0.5285 - accuracy: 0.7265 - val_loss: 0.4855 - val_accuracy: 0.8102\n",
            "782/782 [==============================] - 115s 147ms/step - loss: 0.5062 - accuracy: 0.8015\n",
            "Test acc: 0.802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = tf.keras.layers.Embedding(\n",
        "    input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32))(embedded)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=1)\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cubJnrLkdnfQ",
        "outputId": "eb8b9bad-cc92-42b7-a79b-9df1e65ebf01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, None, 256)         5120000   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 64)                73984     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5194049 (19.81 MB)\n",
            "Trainable params: 5194049 (19.81 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "625/625 [==============================] - 630s 991ms/step - loss: 0.4617 - accuracy: 0.7773 - val_loss: 0.3335 - val_accuracy: 0.8576\n",
            "782/782 [==============================] - 145s 185ms/step - loss: 0.3478 - accuracy: 0.8549\n",
            "Test acc: 0.855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "25XBAHTxdnh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1) #  The maxsplit=1 argument ensures that the split is only performed once, so that the coefficients string can contain spaces.\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \") # This line converts the string of coefficients to a NumPy array of float32 values. values should be separated by spaces.\n",
        "        embeddings_index[word] = coefs\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")\n",
        "# the GloVe file contains pre-trained word vectors for 400,000 unique words.\n",
        "embedding_dim = 100\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary)))) # maps each token in the vocabulary to an integer index.\n",
        "\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i < max_tokens:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "embedding_layer = tf.keras.layers.Embedding(\n",
        "    max_tokens, # The maximum vocabulary size, which was previously defined as 20,000\n",
        "    embedding_dim, # The dimensionality of the word embeddings, which was previously defined as 100.\n",
        "    embeddings_initializer = tf.keras.initializers.Constant(embedding_matrix), # used to initialize the weights with the pre-trained GloVe word embeddings that were loaded earlier.\n",
        "    trainable=False, # specifies whether the weights of the embedding layer should be trainable during training of the model\n",
        "    mask_zero=True, # specifies whether the embedding layer should treat zeros as a special \"padding\" value that should be masked out during training.\n",
        ")\n",
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32))(embedded)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=1)\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")\n",
        "text_vectorization = tf.keras.layers.TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")\n",
        "# Adapt the TextVectorization layer to the training data\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "input_text = [\"That was an excellent movie, I loved it.\", \"This was the worst movie ever. I hated it!!\"] # list of your new reviews\n",
        "vectorized_text = text_vectorization(input_text)\n",
        "output = model.predict(vectorized_text)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "grx5rBuFdnlK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}