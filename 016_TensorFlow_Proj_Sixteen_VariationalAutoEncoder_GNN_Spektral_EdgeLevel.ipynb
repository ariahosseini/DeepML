{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMnu4hIAWxEEC2p6vEvqwDn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ariahosseini/DeepML/blob/main/016_TensorFlow_Proj_Sixteen_VariationalAutoEncoder_GNN_Spektral_EdgeLevel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to the doc: https://arxiv.org/pdf/1611.07308.pdf"
      ],
      "metadata": {
        "id": "A1-DDkCxI3iW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rvusxE0zEGS"
      },
      "outputs": [],
      "source": [
        "# install\n",
        "# !pip install spektral"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "# sklearn\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "# tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "# spektral\n",
        "from spektral.datasets import citation\n",
        "from spektral.layers import GCNConv\n",
        "from spektral.utils.sparse import sp_matrix_to_sp_tensor"
      ],
      "metadata": {
        "id": "dMekWgjdJLQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "# if len(physical_devices) > 0:\n",
        "#     tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "metadata": {
        "id": "GN35w4-75eye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "1O2nJalPJGZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sparse_to_tuple(sparse_mx):\n",
        "    if not sp.isspmatrix_coo(sparse_mx):\n",
        "        sparse_mx = sparse_mx.tocoo()\n",
        "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
        "    values = sparse_mx.data\n",
        "    shape = sparse_mx.shape\n",
        "    return coords, values, shape"
      ],
      "metadata": {
        "id": "TKT9WvidJG7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_test_edges(adj): # func to build test set with 10% positive links\n",
        "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape) # remove diagonal elements\n",
        "    adj.eliminate_zeros()\n",
        "    assert np.diag(adj.todense()).sum() == 0 # check that diag is zero\n",
        "    adj_triu = sp.triu(adj)\n",
        "    adj_tuple = sparse_to_tuple(adj_triu)\n",
        "    edges = adj_tuple[0]\n",
        "    edges_all = sparse_to_tuple(adj)[0]\n",
        "    num_test = int(np.floor(edges.shape[0] / 10.))\n",
        "    num_val = int(np.floor(edges.shape[0] / 20.))\n",
        "    all_edge_idx = list(range(edges.shape[0]))\n",
        "    np.random.shuffle(all_edge_idx)\n",
        "    val_edge_idx = all_edge_idx[:num_val]\n",
        "    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
        "    test_edges = edges[test_edge_idx]\n",
        "    val_edges = edges[val_edge_idx]\n",
        "    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
        "    def ismember(a, b, tol=5):\n",
        "        rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n",
        "        return np.any(rows_close)\n",
        "    test_edges_false = []\n",
        "    while len(test_edges_false) < len(test_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], edges_all):\n",
        "            continue\n",
        "        if test_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
        "                continue\n",
        "        test_edges_false.append([idx_i, idx_j])\n",
        "    val_edges_false = []\n",
        "    while len(val_edges_false) < len(val_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], val_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], val_edges):\n",
        "            continue\n",
        "        if val_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(val_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
        "                continue\n",
        "        val_edges_false.append([idx_i, idx_j])\n",
        "    assert ~ismember(test_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges, train_edges)\n",
        "    assert ~ismember(test_edges, train_edges)\n",
        "    assert ~ismember(val_edges, test_edges)\n",
        "    data = np.ones(train_edges.shape[0])\n",
        "    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape) # re-build adj matrix\n",
        "    adj_train = adj_train + adj_train.T\n",
        "    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false # note: these edge lists only contain single direction of edge!"
      ],
      "metadata": {
        "id": "TKH7bj_FJHpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_roc_score(edges_pos, edges_neg, adj_rec):\n",
        "    preds = []\n",
        "    for e in edges_pos:\n",
        "        preds.append(adj_rec[e[0], e[1]])\n",
        "    preds_neg = []\n",
        "    for e in edges_neg:\n",
        "        preds_neg.append(adj_rec[e[0], e[1]])\n",
        "    preds_all = np.hstack([preds, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\n",
        "    ap_score = average_precision_score(labels_all, preds_all)\n",
        "    return roc_score, ap_score"
      ],
      "metadata": {
        "id": "bT4qevx5JHsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auto Encoder"
      ],
      "metadata": {
        "id": "r3saEfpuKr8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "dataset = citation.Cora()\n",
        "graph = dataset[0]\n",
        "nodes = graph.x # nodes features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbWO-czXJHvn",
        "outputId": "8bc1e0d2-884b-46a8-cfec-341e36c93baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading cora dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# target graph to reconstruct\n",
        "adj_label = graph.a + sp.eye(graph.a.shape[0], dtype=np.float32)\n",
        "adj_label = adj_label.toarray().reshape([-1])"
      ],
      "metadata": {
        "id": "R-rqv89PKwIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove edges randomly from training set and put them in the validation/test sets\n",
        "adj_train, _, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(graph.a)"
      ],
      "metadata": {
        "id": "7N1loKwaVD8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the adj matrix and convert it to sparse tensor\n",
        "adj_norm = GCNConv.preprocess(adj_train)\n",
        "adj_norm = sp_matrix_to_sp_tensor(adj_norm)"
      ],
      "metadata": {
        "id": "_oyznCWmVEAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the class weights (necessary due to imbalanceness in the number of non-zero edges)\n",
        "pos_weight = float(adj_train.shape[0] * adj_train.shape[0] - adj_train.sum()) / adj_train.sum()"
      ],
      "metadata": {
        "id": "VAkBaFcOVEDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# params\n",
        "hidden_dim1, hidden_dim2 = 32, 16 # units in the GCN layers\n",
        "dropout = 0.0                     # dropout rate\n",
        "l2_reg = 0e-5                     # L2 regularization rate\n",
        "learning_rate = 1e-2              # learning rate\n",
        "epochs = 20                      # max number of training epochs\n",
        "val_epochs = 2                   # after how many epochs should check the validation set\n",
        "num_nodes = dataset.n_nodes               # number of nodes in the graph\n",
        "num_feats = dataset.n_node_features       # original size of node features"
      ],
      "metadata": {
        "id": "ZRzw-JGHVOm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GNN architecture\n",
        "nodes_input = Input(shape=(num_feats,))\n",
        "adj_input = Input((num_nodes,), sparse=True)\n",
        "gc = GCNConv(hidden_dim1, activation=\"relu\", kernel_regularizer=l2(l2_reg))([nodes_input, adj_input])\n",
        "gc = Dropout(dropout)(gc)\n",
        "z = GCNConv(hidden_dim2, activation=None, kernel_regularizer=l2(l2_reg))([gc, adj_input])\n",
        "output = tf.matmul(z, tf.transpose(z))\n",
        "adj_rec = tf.keras.layers.Activation('sigmoid')(output)\n",
        "output = tf.reshape(output, [-1])\n",
        "model = Model(inputs=[nodes_input, adj_input], outputs=[output, adj_rec, z]) # build model\n",
        "optimizer = Adam(learning_rate=learning_rate)"
      ],
      "metadata": {
        "id": "JBoErmM6VR5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train & test\n",
        "@tf.function\n",
        "def train():\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _, _ = model([nodes, adj_norm], training=True)\n",
        "        loss = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=predictions, labels=adj_label, pos_weight=pos_weight))\n",
        "        loss += sum(model.losses)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "# train\n",
        "best_val_roc = 0\n",
        "for epoch in range(1, epochs):\n",
        "    loss = train()\n",
        "    print(f\"epoch: {epoch:d} -- loss: {loss:.3f}\")\n",
        "    if epoch%val_epochs==0:\n",
        "        _, adj_rec, _ = model([nodes, adj_norm])\n",
        "        adj_rec = adj_rec.numpy()\n",
        "        val_roc, _ = get_roc_score(val_edges, val_edges_false, adj_rec)\n",
        "        if val_roc <= best_val_roc:\n",
        "            break\n",
        "        else:\n",
        "            best_val_roc = val_roc\n",
        "            acc = np.mean(np.round(adj_rec) == graph.a.toarray())\n",
        "            print(f\"Val AUC: {best_val_roc*100:.1f}, Accuracy: {acc*100:.1f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zsxi1fEWKwSX",
        "outputId": "4e8f5bf1-eff6-4f58-a909-28c9de64f376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 -- loss: 0.869\n",
            "epoch: 2 -- loss: 0.869\n",
            "Val AUC: 98.2, Accuracy: 57.4\n",
            "epoch: 3 -- loss: 0.868\n",
            "epoch: 4 -- loss: 0.867\n",
            "Val AUC: 98.3, Accuracy: 57.5\n",
            "epoch: 5 -- loss: 0.866\n",
            "epoch: 6 -- loss: 0.865\n",
            "Val AUC: 98.4, Accuracy: 57.5\n",
            "epoch: 7 -- loss: 0.865\n",
            "epoch: 8 -- loss: 0.864\n",
            "Val AUC: 98.5, Accuracy: 57.5\n",
            "epoch: 9 -- loss: 0.863\n",
            "epoch: 10 -- loss: 0.863\n",
            "Val AUC: 98.5, Accuracy: 57.5\n",
            "epoch: 11 -- loss: 0.862\n",
            "epoch: 12 -- loss: 0.861\n",
            "Val AUC: 98.6, Accuracy: 57.5\n",
            "epoch: 13 -- loss: 0.861\n",
            "epoch: 14 -- loss: 0.860\n",
            "Val AUC: 98.6, Accuracy: 57.5\n",
            "epoch: 15 -- loss: 0.860\n",
            "epoch: 16 -- loss: 0.859\n",
            "Val AUC: 98.6, Accuracy: 57.5\n",
            "epoch: 17 -- loss: 0.859\n",
            "epoch: 18 -- loss: 0.858\n",
            "Val AUC: 98.7, Accuracy: 57.5\n",
            "epoch: 19 -- loss: 0.858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "_, adj_rec, node_emb = model([nodes, adj_norm])\n",
        "adj_rec = adj_rec.numpy()\n",
        "roc_score, ap_score = get_roc_score(test_edges, test_edges_false, adj_rec)\n",
        "print(f\"AUC: {roc_score*100:.1f}, AP: {ap_score*100:.1f}\")\n",
        "test_acc = np.mean(np.round(adj_rec.ravel()) == adj_label)\n",
        "print(f\"Test accuracy: {test_acc*100:.1f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4TNmIOiJHyc",
        "outputId": "bfa3aa09-abd5-4169-f31b-91286e5c8eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 98.3, AP: 97.9\n",
            "Test accuracy: 57.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variational Auto Encoder"
      ],
      "metadata": {
        "id": "FjhCkQXqwdvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "dataset = citation.Cora()\n",
        "graph = dataset[0]\n",
        "nodes = graph.x # nodes features"
      ],
      "metadata": {
        "id": "R1ugRTEz1UY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d621256-e512-4426-e74d-65d1a17e2544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# target graph to reconstruct\n",
        "adj_label = graph.a + sp.eye(graph.a.shape[0], dtype=np.float32)\n",
        "adj_label = adj_label.toarray().reshape([-1])"
      ],
      "metadata": {
        "id": "jY9HGK6sY7bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove edges randomly from training set and put them in the validation/test sets\n",
        "adj_train, _, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(graph.a)"
      ],
      "metadata": {
        "id": "WSA1b2flY7lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the adj matrix and convert it to sparse tensor\n",
        "adj_norm = GCNConv.preprocess(adj_train)\n",
        "adj_norm = sp_matrix_to_sp_tensor(adj_norm)"
      ],
      "metadata": {
        "id": "cvgs3q0OZDFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the class weights (necessary due to imbalanceness in the number of non-zero edges)\n",
        "pos_weight = float(adj_train.shape[0] * adj_train.shape[0] - adj_train.sum()) / adj_train.sum()\n",
        "norm = adj_train.shape[0] * adj_train.shape[0] / float((adj_train.shape[0] * adj_train.shape[0] - adj_train.sum()) * 2)"
      ],
      "metadata": {
        "id": "m12Lg0mdZDOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# params\n",
        "hidden_dim1, hidden_dim2 = 32, 16 # units in the GCN layers\n",
        "dropout = 0.0                     # dropout rate\n",
        "l2_reg = 0e-5                     # L2 regularization rate\n",
        "learning_rate = 1e-2              # learning rate\n",
        "epochs = 20                       # max number of training epochs\n",
        "val_epochs = 2                    # after how many epochs should check the validation set\n",
        "num_nodes = dataset.n_nodes               # number of nodes in the graph\n",
        "num_feats = dataset.n_node_features       # original size of node features"
      ],
      "metadata": {
        "id": "WUpuBqMAZPyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GNN architecture\n",
        "nodes_input = Input(shape=(num_feats,))\n",
        "adj_input = Input((num_nodes,), sparse=True)\n",
        "gc = GCNConv(hidden_dim1, activation=\"relu\", kernel_regularizer=l2(l2_reg))([nodes_input, adj_input])\n",
        "gc = Dropout(dropout)(gc)\n",
        "z_mean = GCNConv(hidden_dim2, activation=None, kernel_regularizer=l2(l2_reg))([gc, adj_input])\n",
        "z_log_std = GCNConv(hidden_dim2, activation=None, kernel_regularizer=l2(l2_reg))([gc, adj_input])\n",
        "z = z_mean + tf.random.normal([num_nodes, hidden_dim2]) * tf.exp(z_log_std)\n",
        "output = tf.matmul(z, tf.transpose(z))\n",
        "output = tf.reshape(output, [-1])\n",
        "output_det = tf.matmul(z_mean, tf.transpose(z_mean)) # this is not used for training and we make it deterministic\n",
        "adj_rec = tf.keras.layers.Activation('sigmoid')(output_det)\n",
        "model = Model(inputs=[nodes_input, adj_input], outputs=[output, adj_rec, z_mean, z_log_std]) # build model\n",
        "optimizer = Adam(learning_rate=learning_rate)"
      ],
      "metadata": {
        "id": "eP11i41pZP7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tain\n",
        "@tf.function\n",
        "def train():\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _, model_z_mean, model_z_log_std = model([nodes, adj_norm], training=True)\n",
        "        rec_loss = norm*tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=predictions, labels=adj_label, pos_weight=pos_weight)) # reconstruction loss\n",
        "        kl_loss = (0.5 / num_nodes) * tf.reduce_mean(tf.reduce_sum(1 + 2 * model_z_log_std - tf.square(model_z_mean) - tf.square(tf.exp(model_z_log_std)), 1)) # latent loss\n",
        "        loss = rec_loss - kl_loss + sum(model.losses) # total loss\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "best_val_roc = 0\n",
        "for epoch in range(1, epochs):\n",
        "    loss = train()\n",
        "    print(f\"epoch: {epoch:d} -- loss: {loss:.3f}\")\n",
        "    if epoch%val_epochs==0:\n",
        "        _, adj_rec, _, _ = model([nodes, adj_norm])\n",
        "        adj_rec = adj_rec.numpy()\n",
        "        val_roc, _ = get_roc_score(val_edges, val_edges_false, adj_rec)\n",
        "        if val_roc <= best_val_roc:\n",
        "            break\n",
        "        else:\n",
        "            best_val_roc = val_roc\n",
        "            acc = np.mean(np.round(adj_rec) == graph.a.toarray())\n",
        "            print(f\"Val AUC: {best_val_roc*100:.1f}, Accuracy: {acc*100:.1f}\")"
      ],
      "metadata": {
        "id": "dws1aPLc1UK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd8f8ba-1558-4046-d741-0dba076bf315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 -- loss: 1.863\n",
            "epoch: 2 -- loss: 1.452\n",
            "Val AUC: 70.5, Accuracy: 0.1\n",
            "epoch: 3 -- loss: 1.249\n",
            "epoch: 4 -- loss: 1.092\n",
            "Val AUC: 72.4, Accuracy: 0.1\n",
            "epoch: 5 -- loss: 0.960\n",
            "epoch: 6 -- loss: 0.863\n",
            "Val AUC: 76.9, Accuracy: 0.5\n",
            "epoch: 7 -- loss: 0.795\n",
            "epoch: 8 -- loss: 0.752\n",
            "Val AUC: 79.2, Accuracy: 2.4\n",
            "epoch: 9 -- loss: 0.725\n",
            "epoch: 10 -- loss: 0.704\n",
            "Val AUC: 83.8, Accuracy: 11.4\n",
            "epoch: 11 -- loss: 0.679\n",
            "epoch: 12 -- loss: 0.654\n",
            "Val AUC: 84.6, Accuracy: 33.9\n",
            "epoch: 13 -- loss: 0.627\n",
            "epoch: 14 -- loss: 0.597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "_, adj_rec, node_emb, _ = model([nodes, adj_norm])\n",
        "adj_rec = adj_rec.numpy()\n",
        "roc_score, ap_score = get_roc_score(test_edges, test_edges_false, adj_rec)\n",
        "print(f\"AUC: {roc_score*100:.1f}, AP: {ap_score*100:.1f}\")\n",
        "test_acc = np.mean(np.round(adj_rec.ravel()) == adj_label)\n",
        "print(f\"Test accuracy: {test_acc*100:.1f}\")"
      ],
      "metadata": {
        "id": "c2ZVFP0e1UkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79f78860-a7de-47c3-cc57-bcf2d4a69607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 85.0, AP: 83.3\n",
            "Test accuracy: 45.7\n"
          ]
        }
      ]
    }
  ]
}