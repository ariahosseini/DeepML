{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "F2WwO8watiyO",
        "ClPV3-wi6Bpt",
        "Bu56WYctP2yy",
        "El3USV92myr9",
        "7fzbE6UGrpty",
        "TLcLoBWKsSBr",
        "Zi7TLXhFoxI5",
        "qH6HqcdbrjoP",
        "YVjMHgidue7e",
        "yCsv5wvBn-nr",
        "pa1ElLfxqZ9L",
        "v3utlaNz7C-O"
      ],
      "authorship_tag": "ABX9TyPvs3o6MN9CZmxVb3MjxUUm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f33bc2be9ee44f97bb61961a369f8015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec6ab814e802427785d3b2af8b978741",
              "IPY_MODEL_72880013e5e84cea8aeb7e5618256752",
              "IPY_MODEL_6fe6dcb8b976448db353771c713652aa"
            ],
            "layout": "IPY_MODEL_eb9a40792a5d4f2980965637a2733f3b"
          }
        },
        "ec6ab814e802427785d3b2af8b978741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f71d7a18f1542e0a4c005e21df42479",
            "placeholder": "​",
            "style": "IPY_MODEL_188871e816d44b27968ae717083cd509",
            "value": "/root/.dgl/cora_v2.zip: 100%"
          }
        },
        "72880013e5e84cea8aeb7e5618256752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1ac5b6b1ab1448eb2536ab6be94e7e0",
            "max": 132173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59c419513fa2424d959b28fa4f9eead9",
            "value": 132173
          }
        },
        "6fe6dcb8b976448db353771c713652aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc0696f5fc3c4f89aef25245ad52d344",
            "placeholder": "​",
            "style": "IPY_MODEL_326c692efb7344eab8b2c6f75472374a",
            "value": " 132k/132k [00:00&lt;00:00, 2.30MB/s]"
          }
        },
        "eb9a40792a5d4f2980965637a2733f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f71d7a18f1542e0a4c005e21df42479": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "188871e816d44b27968ae717083cd509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1ac5b6b1ab1448eb2536ab6be94e7e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59c419513fa2424d959b28fa4f9eead9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc0696f5fc3c4f89aef25245ad52d344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "326c692efb7344eab8b2c6f75472374a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ariahosseini/DeepML/blob/main/017_PyTorch_Proj_Seventeen_GNN_DGL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVXPSFSeXwQb"
      },
      "outputs": [],
      "source": [
        "!pip install  dgl -f https://data.dgl.ai/wheels/repo.html\n",
        "!pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "F2WwO8watiyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\""
      ],
      "metadata": {
        "id": "iDOA24RUHGhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# util\n",
        "import math\n",
        "import random\n",
        "import os, sys, itertools\n",
        "import time\n",
        "import argparse\n",
        "import multiprocessing\n",
        "import urllib.request\n",
        "\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from functools import partial, reduce, wraps\n",
        "from tqdm.auto import tqdm\n",
        "from tqdm import tqdm\n",
        "from functools import partial\n",
        "from collections import defaultdict\n",
        "from gensim.models.keyedvectors import Vocab\n",
        "from six import iteritems\n",
        "# sklearn\n",
        "from sklearn.metrics import (roc_auc_score, accuracy_score, auc,\n",
        "                             f1_score, precision_recall_curve)\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "# pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.optim as optim\n",
        "# graph\n",
        "import networkx as nx\n",
        "import dgl\n",
        "import dgl.graphbolt as gb\n",
        "import dgl.function as fn\n",
        "from dgl.data import GINDataset, DGLDataset\n",
        "from dgl.dataloading import GraphDataLoader\n",
        "from dgl.nn import GraphConv, SAGEConv\n",
        "from dgl.nn.pytorch.conv import GINConv\n",
        "from dgl.nn.pytorch.glob import SumPooling\n",
        "# visual\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "25Ehmg_i6FQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O18O5XQbwJUF",
        "outputId": "bc2f7a64-1adf-4899-ff9f-8fcfb74a4856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TORCH'] = torch.__version__"
      ],
      "metadata": {
        "id": "QZlcFCfMtZSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\" # use NVIDIA GPU (if available)\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\" # use Apple Silicon GPU (if available)\n",
        "else:\n",
        "    device = \"cpu\" # default to CPU if no GPU is available"
      ],
      "metadata": {
        "id": "d4-8VXgTo8uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import torchinfo\n",
        "except:\n",
        "    !pip install torchinfo\n",
        "    import torchinfo\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "8zcVZ66LFKMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa4f84c3-77f7-4f8a-c130-9d153f6224e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node Classification"
      ],
      "metadata": {
        "id": "ClPV3-wi6Bpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset\n",
        "dataset = dgl.data.CoraGraphDataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253,
          "referenced_widgets": [
            "f33bc2be9ee44f97bb61961a369f8015",
            "ec6ab814e802427785d3b2af8b978741",
            "72880013e5e84cea8aeb7e5618256752",
            "6fe6dcb8b976448db353771c713652aa",
            "eb9a40792a5d4f2980965637a2733f3b",
            "2f71d7a18f1542e0a4c005e21df42479",
            "188871e816d44b27968ae717083cd509",
            "f1ac5b6b1ab1448eb2536ab6be94e7e0",
            "59c419513fa2424d959b28fa4f9eead9",
            "dc0696f5fc3c4f89aef25245ad52d344",
            "326c692efb7344eab8b2c6f75472374a"
          ]
        },
        "id": "xQ2KNUqZ6D3G",
        "outputId": "510e7769-b5cc-4a9f-c370-78fc524569e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/root/.dgl/cora_v2.zip:   0%|          | 0.00/132k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f33bc2be9ee44f97bb61961a369f8015"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting file to /root/.dgl/cora_v2_d697a464\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of graphs:\", len(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiIZt9YO79UD",
        "outputId": "0c364fe9-78a2-4bd4-ba90-5797e4f9ac28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of graphs: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# graph\n",
        "graph = dataset[0]"
      ],
      "metadata": {
        "id": "ChID8fpd6EDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Node features\")\n",
        "print(graph.ndata)\n",
        "print(\"Edge features\")\n",
        "print(graph.edata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGqktMIWMRSb",
        "outputId": "34f0540c-daa5-41da-806a-f78b101a8c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node features\n",
            "{'train_mask': tensor([ True,  True,  True,  ..., False, False, False]), 'val_mask': tensor([False, False, False,  ..., False, False, False]), 'test_mask': tensor([False, False, False,  ...,  True,  True,  True]), 'label': tensor([3, 4, 4,  ..., 3, 3, 3]), 'feat': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
            "Edge features\n",
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats)\n",
        "        self.conv2 = GraphConv(h_feats, num_classes)\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = func.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "Qj2dAw8SCthW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(gr, model):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    best_val_acc = 0\n",
        "    best_test_acc = 0\n",
        "    features = graph.ndata[\"feat\"]\n",
        "    labels = graph.ndata[\"label\"]\n",
        "    train_mask = graph.ndata[\"train_mask\"]\n",
        "    val_mask = graph.ndata[\"val_mask\"]\n",
        "    test_mask = graph.ndata[\"test_mask\"]\n",
        "    for e in range(101):\n",
        "        logits = model(gr, features) # forward\n",
        "        pred = logits.argmax(1) # compute prediction\n",
        "        loss = func.cross_entropy(logits[train_mask], labels[train_mask]) # compute loss\n",
        "        # compute accuracy on training/validation/test\n",
        "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
        "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
        "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
        "        if best_val_acc < val_acc:\n",
        "          best_val_acc = val_acc # best validation\n",
        "          best_test_acc = test_acc # corresponding test accuracy\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if e%20 == 0:\n",
        "            print(f\"In epoch {e}, loss: {loss:.3f}, val acc: {val_acc:.3f} (best {best_val_acc:.3f}), test acc: {test_acc:.3f} (best {best_test_acc:.3f})\")"
      ],
      "metadata": {
        "id": "X-_NUg82OQ5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model with given dimensions\n",
        "model = GCN(graph.ndata[\"feat\"].shape[1], 16, dataset.num_classes)"
      ],
      "metadata": {
        "id": "pOlrUCEwOQ8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model=model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4TOHoodDkIa",
        "outputId": "8d549df1-ae18-4a6c-b584-df84d35b0b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "GCN                                      --\n",
              "├─GraphConv: 1-1                         22,944\n",
              "├─GraphConv: 1-2                         119\n",
              "=================================================================\n",
              "Total params: 23,063\n",
              "Trainable params: 23,063\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(graph, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBDOCBOaF_fT",
        "outputId": "19eda20b-fd4c-402c-c16f-a80a8f7ea429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, loss: 1.940, val acc: 0.150 (best 0.150), test acc: 0.174 (best 0.174)\n",
            "In epoch 20, loss: 1.540, val acc: 0.606 (best 0.606), test acc: 0.623 (best 0.623)\n",
            "In epoch 40, loss: 0.907, val acc: 0.732 (best 0.732), test acc: 0.739 (best 0.739)\n",
            "In epoch 60, loss: 0.415, val acc: 0.764 (best 0.764), test acc: 0.763 (best 0.763)\n",
            "In epoch 80, loss: 0.187, val acc: 0.772 (best 0.772), test acc: 0.777 (best 0.774)\n",
            "In epoch 100, loss: 0.096, val acc: 0.768 (best 0.772), test acc: 0.770 (best 0.774)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.grad is not None:\n",
        "        print(name, param.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSXtrL6yLUIQ",
        "outputId": "456489e3-a679-4a6a-83bc-4ce9310458ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight tensor([[ 4.3620e-06, -9.5856e-07,  4.8928e-06,  ..., -2.5690e-06,\n",
            "         -2.1256e-06,  1.7325e-06],\n",
            "        [-3.9137e-05,  2.6413e-05,  6.2629e-05,  ...,  5.6700e-06,\n",
            "          1.6510e-05, -8.4654e-06],\n",
            "        [ 1.6541e-05,  4.7706e-06, -2.5239e-06,  ..., -1.1444e-05,\n",
            "          8.1274e-06,  2.9964e-05],\n",
            "        ...,\n",
            "        [ 4.4795e-06,  6.5537e-06,  6.5312e-06,  ..., -1.2038e-05,\n",
            "         -3.8341e-06, -6.6567e-06],\n",
            "        [ 8.7922e-06,  4.3539e-07,  1.6204e-05,  ..., -1.2503e-05,\n",
            "         -3.0691e-05, -2.9384e-05],\n",
            "        [-9.2137e-06, -4.8213e-06,  1.3109e-05,  ...,  9.7941e-06,\n",
            "         -5.4078e-06,  2.5396e-06]])\n",
            "conv1.bias tensor([-2.5215e-03, -3.2461e-04, -1.5162e-03, -5.3790e-04, -3.9194e-03,\n",
            "        -7.7308e-05,  2.6398e-04, -6.1865e-04, -7.7050e-04, -2.9080e-03,\n",
            "        -1.4211e-03, -6.8168e-04,  4.6984e-04, -8.6706e-04, -2.1759e-04,\n",
            "        -6.1422e-04])\n",
            "conv2.weight tensor([[ 0.0049, -0.0029, -0.0018, -0.0021,  0.0026, -0.0005, -0.0002],\n",
            "        [-0.0016,  0.0013,  0.0015, -0.0020, -0.0013,  0.0040, -0.0019],\n",
            "        [ 0.0021,  0.0047, -0.0066,  0.0013, -0.0014,  0.0030, -0.0032],\n",
            "        [-0.0025,  0.0016,  0.0013,  0.0005,  0.0017, -0.0012, -0.0015],\n",
            "        [-0.0009, -0.0075,  0.0067, -0.0004,  0.0023,  0.0015, -0.0018],\n",
            "        [-0.0015,  0.0011,  0.0008, -0.0033, -0.0015,  0.0029,  0.0014],\n",
            "        [-0.0024, -0.0007, -0.0014,  0.0043,  0.0005, -0.0024,  0.0021],\n",
            "        [ 0.0019, -0.0012,  0.0022,  0.0015, -0.0026, -0.0031,  0.0014],\n",
            "        [ 0.0031,  0.0010,  0.0001, -0.0024,  0.0008, -0.0010, -0.0017],\n",
            "        [ 0.0016, -0.0039, -0.0006,  0.0004, -0.0013,  0.0025,  0.0013],\n",
            "        [-0.0032, -0.0023, -0.0007,  0.0036,  0.0002,  0.0018,  0.0006],\n",
            "        [-0.0010,  0.0054, -0.0073, -0.0009,  0.0029, -0.0013,  0.0020],\n",
            "        [ 0.0014,  0.0017,  0.0005, -0.0030, -0.0017, -0.0010,  0.0021],\n",
            "        [-0.0027,  0.0011,  0.0011,  0.0043,  0.0013, -0.0025, -0.0027],\n",
            "        [-0.0011,  0.0014,  0.0014, -0.0019, -0.0009, -0.0009,  0.0021],\n",
            "        [ 0.0017,  0.0008,  0.0013,  0.0027, -0.0020, -0.0023, -0.0022]])\n",
            "conv2.bias tensor([ 1.9936e-03, -2.0008e-04, -2.3780e-03,  1.1806e-05,  4.4121e-04,\n",
            "        -4.2162e-04,  5.5312e-04])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DGL Graph Representation"
      ],
      "metadata": {
        "id": "Bu56WYctP2yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = dgl.graph(([0, 0, 0, 0, 0], [1, 2, 3, 4, 5]), num_nodes=6)\n",
        "graph.ndata[\"x\"] = torch.randn(6, 3) # assign a 3-dimensional node feature vector for each node\n",
        "graph.ndata[\"y\"] = torch.randn(6, 5, 4) # assign a 5x4 node feature matrix for each node\n",
        "graph.edata[\"a\"] = torch.randn(5, 4) # assign a 4-dimensional edge feature vector for each edge"
      ],
      "metadata": {
        "id": "5h80ND_4ORA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(graph.edata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13rw7nGcexWC",
        "outputId": "98875912-dfa7-4e06-b33c-b599c0e4e5b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': tensor([[-0.7597,  0.1666,  0.2882,  0.9317],\n",
            "        [-0.2731, -0.7164, -1.1395, -2.6688],\n",
            "        [ 1.5812, -1.3539,  0.6563,  1.5207],\n",
            "        [ 0.0222, -1.3592,  0.9294,  0.3498],\n",
            "        [ 0.7542, -0.9402,  1.3791, -0.6899]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(graph.ndata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLgGkcU2exaa",
        "outputId": "119166df-f780-4dea-fef7-9ac8e2107070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'x': tensor([[ 1.2560, -0.0398, -0.2730],\n",
            "        [ 0.5024, -0.1735,  0.9923],\n",
            "        [ 1.0957, -0.8739, -1.2375],\n",
            "        [-0.2404,  0.1506,  1.4728],\n",
            "        [ 0.4652,  0.5377, -1.6812],\n",
            "        [ 1.9863,  0.2965,  0.9501]]), 'y': tensor([[[-0.2589, -1.6404,  0.1041,  0.5290],\n",
            "         [ 0.0296,  1.2908, -0.2452,  0.1767],\n",
            "         [ 1.2068, -1.2861, -0.3502, -0.1656],\n",
            "         [ 0.1909,  0.6888,  0.2044, -0.2370],\n",
            "         [-1.6794,  1.2477, -0.7168, -0.9567]],\n",
            "\n",
            "        [[ 0.0782,  1.9676,  1.2159,  0.0562],\n",
            "         [-0.0960, -0.7131, -0.7554, -0.0150],\n",
            "         [-0.7142,  0.7439,  0.4542,  1.2753],\n",
            "         [ 0.4011,  0.9091, -0.4937,  1.4777],\n",
            "         [ 0.4880,  0.8199, -1.0829, -0.2461]],\n",
            "\n",
            "        [[ 0.0825,  0.6047, -0.1716,  0.3194],\n",
            "         [-0.3651, -0.6832,  0.2585,  1.0798],\n",
            "         [-1.0124,  1.3636, -2.1527, -0.2159],\n",
            "         [ 1.1300,  0.9593,  0.6202, -0.8698],\n",
            "         [-0.7551, -0.4903, -0.2283,  0.1867]],\n",
            "\n",
            "        [[-0.1740, -1.1883, -1.6545,  0.7846],\n",
            "         [-0.2963, -0.2045, -1.5685,  2.5684],\n",
            "         [-0.0957,  0.4578,  0.5501, -0.2307],\n",
            "         [-0.0621,  0.3771, -0.5407, -0.6149],\n",
            "         [ 0.6534,  0.8962,  0.5089, -0.4358]],\n",
            "\n",
            "        [[ 0.0367,  1.2679,  0.3816,  0.4660],\n",
            "         [-0.4190, -1.8237,  0.3404,  0.3871],\n",
            "         [-1.7864,  2.0611, -1.1496,  0.1891],\n",
            "         [-1.5420, -0.5770,  0.7513, -0.0818],\n",
            "         [-1.1401, -0.1071,  1.8927, -1.9039]],\n",
            "\n",
            "        [[ 0.9768,  0.9235,  0.0260, -0.4796],\n",
            "         [ 1.7396, -1.5068,  0.1763,  0.2452],\n",
            "         [-0.2695,  0.6084,  1.0877, -0.2925],\n",
            "         [-1.5831,  1.1633, -0.9526,  0.5927],\n",
            "         [ 0.7154,  1.5098, -1.3109,  0.1069]]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of nodes:\", graph.num_nodes())\n",
        "print(\"Number of edges:\", graph.num_edges())\n",
        "print(\"Out-degrees of the center node:\", graph.out_degrees(0))\n",
        "print(\"In-degrees of the center node:\", graph.in_degrees(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8I52M7Vexdf",
        "outputId": "254759f6-e5a0-42ce-a362-c711a47c6b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 6\n",
            "Number of edges: 5\n",
            "Out-degrees of the center node: 5\n",
            "In-degrees of the center node: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gr = graph.to_networkx()\n",
        "pos = nx.spring_layout(gr)  # layout algorithm (spring layout)\n",
        "plt.figure(figsize=(2,2))\n",
        "nx.draw(gr, pos, with_labels=True, font_weight='bold', node_size=700, node_color='skyblue', edge_color='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "y3Q52-zGexfu",
        "outputId": "e9ec48c2-6f67-40d9-f23c-7614aebd6cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subgr_one = graph.subgraph([0, 1, 3]) # induce a subgraph from node 0, node 1 and node 3\n",
        "subgr_two = graph.edge_subgraph([0, 1, 3]) # induce a subgraph from edge 0, edge 1 and edge 3"
      ],
      "metadata": {
        "id": "6tJhdFpOOREn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr = subgr_one.to_networkx()\n",
        "pos = nx.spring_layout(gr)\n",
        "plt.figure(figsize=(2,2))\n",
        "nx.draw(gr, pos, with_labels=True, font_weight='bold', node_size=700, node_color='skyblue', edge_color='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "_gPPD4FEhvCe",
        "outputId": "ba0176b6-739c-4589-c791-b90def74b172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANwAAADcCAYAAAAbWs+BAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAQpklEQVR4nO3dfWwb52HH8d9DHknxRaZVV5In2XTkWLJjORbkwnbyRz04AgJpzQrES5FuxZKi3bJibf5YvBVIsQ3t0GVbhwRo1g0ouiXoCmQNmiarl8xGWtuJsmC2k1mWLRua7DieFCm27EamzReRvOOzP2TS1outuyP5HI/8ff4JTR2PTxJ9/fDeeEJKKUFESnicHgBRPWFwRAoxOCKFGByRQgyOSCEGR6QQgyNSiMERKcTgiBTSnB4AUaVIKTEWz+LopTSmUjoEACunVXkA5AG0hTTsbA2iK+qHEKKkMQme2kW1KJHL48D4dZy7lrMc2kKF129Y4UN/rBERn/0PhgyOas7oTAb7xxPI5mVJoS0kAPg9AgOxCDY1Beytg8FRLTk2ncahyWTF36evPYztLUHLr+NOE6oZqmIDgIOTSbw3nbb8OgZHNWF0JqMstoKDk0mMzmQsvYbBkeslcnnsH0848t77xxNI5vKml2dw5GpSShwYv45s3pldEdm8xIGJBMzuCmFw5Gpj8SzOXcuVdW+kFRLA2XgWY/GsqeV54Jtc7eiltOXjbKn4DAb/9QcYH34PH505gdzs3M6Pbb/9KL7wnR9YHoPA3A6bjSuXP1TA4Mi1ptM6plK65dddvfgR3n7x+bKNQwKYTJobB4Mj1zp+edbWWSRenx8d2+5HrGc7kp9cwfu/eKnksZjdNuM2HLnWWDxja9utdf1GPPHP+9D/5F9gTXdvWcZidj8lgyNXSubySOnuO0mKwZErXbSx7VYNGBy50nR67nIbt2Fw5EqzhkSJl6Y5gsGRKxkuvciFwZEred04vYHH4cilGrwCdie5bDqF/333VwCAqdFTxeevfvwRTv1qHwBgzeZeNLWtLXmcCzE4cqWWoGb7/MnkzBW89M2vLnr+/Pvv4vz77wIAHvn28/jM53+3hBEujR8pyZVWh9w5V7hz1FT3wj4PQpqwdfC7qS2Gvzl+uQKjWh5nOHKtrmigao7F8VxKqnnbmhscuw5uIZ5LSTWvJaihLaQ5PssJAO1hc1tnDI5cbWdr0PFZTgLYYfIr8xgcuVpX1I8NK3yOzXICQGfUj66o39TyDI5cTQiB/lgj/B5nkvN7BPrXRkzfc4DBketFfB4MxCKOvPdALIKwhXsNMDhyPcMwELg6hQfaQkrft689bPkeA7y3ALmSYRi4cOECTp8+jZMnT8IwDDz22GO4El6Ng1V8bwGeaUKuMjExgaGhIZw5cwaZTAZCCEgp4fV6sW7dOnR4PGj0ear27jkMjlxDSomXX34ZyWRy3nNCCPT09MDjmdtC2tQUwJqIr/z3h4v60b/W2jbbQtyGI9cQQmDPnj3wer3znpdSYvPmzfOei/g8+J31K/BwRyN+48aJzlZ/2QvLt4U1PNzRiD0djSXFBnCGI5dZv349tmzZguHh4eJzgUAAHR0di5YVQmDjygA2rgxgOq3j+OVZnI1nkLxxwrMA5n1Ng5Q3Z8KwJtAZDWBbcwNaguXLhMGRqwwODmJ4eBg9PT0YGRmBYRjo7u4ufpy8nZaghv5YBP2IIJnL42JKx3RaR8aQ0KWEJgQCXoGWoIbVIa3kmex2GBy5xuDgIA4fPozdu3dj165d2Lp1K1599VX09lr7Mtewz4O7o37cbfLskHLiYQFyhYWxFRR2mrgFd5pQ1btdbABcFRvA4KjK3Sk2N2JwVLVqLTaAwVGVqsXYAAZHVahWYwMYHFWZWo4NYHBURWo9NoDBUZWoh9gABkdVoF5iAxgcOayeYgMYHDmo3mIDGBw5pB5jAxgcOaBeYwMYHClWz7EBDI4UqvfYAAZHijC2OQyOKo6x3cTgqKIY23wMjiqGsS3G4KgiGNvS+K1dVHZvv/023nrrLca2BM5wVFaM7c4YHJUNY1seg6OyYGzmMDgqGWMzj8FRSRibNQyObGNs1jE4soWx2cPgyDLGZh+DI0sYW2kYHJnG2ErH4MgUxlYeDI6WxdjKh8HRHTG28mJwdFuMrfwYHC2JsVUGg6NFGFvlMDiah7FVFoOjIsZWeQyOADA2VRgcMTaFGFydY2xq8Vu7XCKZy+NiSsd0WsesIWFICa8QaPAKtAQ1rA5pCPus/f3J2NRjcFVsOq3j+OVZjMUzSOkSACAACHFzGSkBeeNxSBPoigawrbkBLcE7/69lbM4QUkq5/GKkipQSY/Esjl5KYyqlQ+BmUGZ4AOQBtIU07GwNoivqh7i1UDA2JzG4KpLI5XFg/DrOXctZDm2hwus3rPChP9aIyI2Pm4zNWQyuSozOZLB/PIFsXpYU2kICgN8jMBCL4NLJI4zNYQyuChybTuPQZLLi76OPvINd61YxNgdxp4nDVMUGANqWzyLYHlbyXrQ0Hodz0OhMRllsBQcnkxidySh9T7qJwTkkkctj/3jCkffeP55AMpd35L3rHYNzgJQSB8avI5t3ZvM5m5c4MJEAN9/VY3AOGItnce5arqx7I62QAM7GsxiLZx0aQf3iThMHHL2UtnWcTc9m8M5P/gkn/vMVfDL5f/AFQ+jovQ8P/OFetN/TY2ldAnM7bDauDFgcBZWChwUUm07reGH0quXXGbqOF7/xKD44NrjoZ5o/gMe//xI27LS+u/8rm1YuexoYlQ8/Uip2/PIsxPKLLXLkZy8UY2vdcA++9PcvYvcfPAVgbuZ75dtPQs9a2/vouTEeUofBKTYWz9jadjv2yo+Lj/f8+XPY0vcQHvzjp9F5/24AQPzSFEbfedPSOvMAzsZ5iEAlBqdQMpcvnvVvRSo+g+kPxwAAXs2HNd29xZ+t69lRfPzh8SPWx6RLHiJQiMEpdDGl23rdzNR48XFoZRM8Xm/xz5FPfXrJ5VSMi6xjcApNp3Vb22/ZdKr42Kv55/3Mq/mWXM4scWNcpAaDU2jWkBA2ivMHQ8XHem7+Npeh55ZcziwhgIzBHdWqMDiFDJtHYJraYsXHqfgMDP3mjHT9yvSSy1mh88iQMgxOIa+d6Q1AKNqElo4uAEBe1/HR6aHiz8ZPvld83LHtPlvr12yOi6xjcAo1eAXsTiY7Hnm8+Pi17z6FkYOv481/fAZnj7wFAIi2tmHTZx+0vF4pgYCXwanCM00U+iCexc/OX7P12kqdaQIAX1i/AndH/csvSCXjDKfQ6pD9U6i8moYvP/8SHvz6t9B8Vyc0fwDBaBPu+c1+fO3FN2zHVuq4yBrOcIo9f+rXtg5+V0pYE3jy3lVOD6NucIZTrCsasHUsrhI8ADqjvFpAJQan2LbmBseug1soj7nxkDoMTrGWoIa2kOb4LCcAtIc1XpqjGINzwM7WoOOznASwoyXo8CjqD4NzQFfUjw0rfI7NcgJAZ9SPLh4KUI7BOUAIgf5YI/weZ5LzewT610YW3XOAKo/BOSTi82AgFnHkvQdiEcu3tqLy4H91B02fOgp95B2l79nXHsamJh4KcAqDc8jg4CAOHz6MXetWoU/R14/3tYexnTtKHMV9wg4oxHbrXWwafZ6K3z2HM5vzeGqXYkvFVlCJ+8N1Rv3oX8tttmrB4BS6U2wFC++AWrijqVmF5dvDGna0LH0HVHIOg1PETGwLFe7xfTaeQdLEPb7DmkCnyXt8kzMYnAJ2YlsomcvjYkrHdFpHxpDQpYQmBAJegZaghtUhjR8bXYDBVVg5YqPawb8SK4ix0UIMrkIYGy2FwVUAY6PbYXBlxtjoThhcGTE2Wg6DKxPGRmYwuDJgbGQWgysRYyMrGFwJGBtZxeBsYmxkB4OzgbGRXQzOIsZGpWBwFjA2KhWDM4mxUTkwOBMYG5ULg1sGY6NyYnB3wNio3BjcbTA2qgQGtwTGRpXC4BZgbFRJDO4WjI0qjcHdwNhIBQYHxkbq1H1wjI1UquvgGBupVrfBMTZyQl0Gx9jIKXUXHGMjJ9VVcIyNnFY3wTE2qgZ1ERxjo2pR88ExNqomNR0cY6NqU7PBMTaqRjUZHGOjalVzwTE2qmY1FRxjo2pXM8ExNnKDmgiOsZFbuD44xkZu4qrgpJTz/szYyG1cE9zExASeffZZnD9/HgBjI3cScuG0UaX27duHoaEheL1ebNmyBcPDw4yNXEer5MqTuTwupnRMp3XMGhKGlPAKgQavQEtQw+qQhrBv+UnWMAycOXOm+Hh4eBg9PT2MjVyn7MFNp3UcvzyLsXgGKX1u8hQAhLi5jJRAYVoNaQJd0QC2NTegJbj0cC5cuIBMJjPvuZGREWzduhXr168v978CUcWU5SOllBJj8SyOXkpjKqVD4GZQZngA5AG0hTTsbA2iK+qHuKXQffv24cSJE4t2moTDYezdu3feskTVrOQZLpHL48D4dZy7lkPh195qwfkb//w4peO1D69jwwof+mONiPg8MAwDJ0+ehJQSQghIKREIBNDd3Y3e3l7GRq5SUnCjMxnsH08gm59LrNSpsvD6D67l8KMzMxiIRRC4OgXDMOD1etHT04PNmzejo6MDHo9rdrASFdn+SHlsOo1Dk8lyj2eRB9pCaE5dwrp16xgZuZ6t32BVsQHAoakUroRXMzaqCZZ/i0dnMspiKzg4mcToTGb5BYmqnKXgErk89o8nKjWWO9o/nkAyl19+QaIqZjo4KSUOjF8v7iBRLZuXODCRWHRogMhNTAc3Fs/i3LVcyXsi7ZIAzsazGItnHRoBUelMHxY4eilt+YD21OhJnHzz3/Hh8SO4+vEEkjO/RkNkBdbe+xnsevwb6Nh2v6XBCsztsNm4MmDpdUTVwvRhgb8dumJ55a/99Z/i2M9/vPQbezz4vb/7F2zpe8jyer+yaeVtTwMjqmamP1LaPZ+j8dMt2P3VP8GX/+GnePSZH6L5rg0AAJnP443n/tLy+jwAjl+etTkaImeZnibsbLv1/tYj+NxTfwV/MFR8rnV9F57/4m4AwNWPJ5D45DIin2o2vc48gLPxDPoRsTEiImdV9HPZXb33LXpu1dr5Z/f7GoKW15vUJZK5vKlLe4iqifLf2JGDrxcf39V7HwIhezPVxZReriERKaM0uMkzw/iP7z0NAND8ATy097u21iMwd90dkdsoC+7C0BH86GsPYzZxDR5Nwxef+SHaN/fYWpcQQMbgAXByHyXBjf33Ybzw9UeRSVyH5g/gS997Ad0PfK6kdeo844RcqOIHs04fegP/9vQTMHJZ+IMh/P5zP8GGnaV/F4nGC0/JhSoa3Klf/gI//dYfIW8YEEKg74k/g+b348LQkeIya7p7ofmtnTkiJRDwMjhyn4oGN/pfv0TeMADMnfy8//vfWbTMN1//HzS1xSytVwI804RcybUHslaHGBy5T0XPpayUsCbw5L2rnB4GkWUVP5ey3DwAOqO8WoDcyfwFqJUchQV5ANuaG5weBpEtpoNrC2mOz3ICQHtY4w4Tci3Twe1sDTo+y0kAO1qsn+xMVC1MB9cV9WPDCp9js5wA0Bn1oyvqd2gERKUzv9NECPTHGuH3OJOc3yPQvzbCrzYnV7N0HC7i82Ag5syFnwOxCK9/I9ez/Bu8qSmAvvZwJcZyW33tYWxq4qEAcj9bU8b2lqCy6Praw9jOHSVUI0q6P9ytd88p5x5MgblttoFYhDMb1ZSSb8i48P5wpays8PrOqB/9a7nNRrWnIndALdzR1KzC8u1hDTtaFt8BlahWlCU4IjKHn9mIFGJwRAoxOCKFGByRQgyOSCEGR6QQgyNSiMERKfT/iPE0jMcmFHcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gr = subgr_two.to_networkx()\n",
        "pos = nx.spring_layout(gr)\n",
        "plt.figure(figsize=(2,2))\n",
        "nx.draw(gr, pos, with_labels=True, font_weight='bold', node_size=700, node_color='skyblue', edge_color='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "mlyGAoa1hvGG",
        "outputId": "942cd4fe-f611-43b8-eeef-5566253ca68e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original IDs of each node in subgr_one\", subgr_one.ndata[dgl.NID])\n",
        "print(\"Original IDs of each edge in subgr_one\", subgr_one.edata[dgl.EID])\n",
        "print(\"Original IDs of each noce in subgr_two\", subgr_two.ndata[dgl.NID])\n",
        "print(\"Original IDs of each edge in subgr_two\", subgr_two.edata[dgl.EID])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG255xJXhvJl",
        "outputId": "988d7f70-987c-4a36-8187-366516755f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original IDs of each node in subgr_one tensor([0, 1, 3])\n",
            "Original IDs of each edge in subgr_one tensor([0, 2])\n",
            "Original IDs of each noce in subgr_two tensor([0, 1, 2, 4])\n",
            "Original IDs of each edge in subgr_two tensor([0, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bidir_gr = dgl.add_reverse_edges(graph)\n",
        "print(bidir_gr.edges())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL450J7xjnu6",
        "outputId": "1c544a79-4d6d-4108-d17b-e99abc9089aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0, 0, 0, 0, 0, 1, 2, 3, 4, 5]), tensor([1, 2, 3, 4, 5, 0, 0, 0, 0, 0]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GraphSAGE Conv Implementation"
      ],
      "metadata": {
        "id": "El3USV92myr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dgl.data.CoraGraphDataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX_gfmnvp8px",
        "outputId": "f3094d2b-9453-48dd-985e-3c2f9830423b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = dataset[0]"
      ],
      "metadata": {
        "id": "F2IpA-ynp8zZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGEConv(nn.Module):\n",
        "    \"\"\"Graph convolution module used by the GraphSAGE model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_feat : int\n",
        "        Input feature size.\n",
        "    out_feat : int\n",
        "        Output feature size.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv, self).__init__()\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat) # project the input and neighbor features to the output.\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        \"\"\"Forward computation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        g : Graph\n",
        "            The input graph.\n",
        "        h : Tensor\n",
        "            The input node feature.\n",
        "        \"\"\"\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            # update_all is a message passing API\n",
        "            g.update_all(message_func=fn.copy_u(\"h\", \"m\"), reduce_func=fn.mean(\"m\", \"h_N\"))\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "metadata": {
        "id": "UGqxb633jn1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats)\n",
        "        self.conv2 = SAGEConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = func.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "CHClkBXIm5l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(g, model):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    all_logits = []\n",
        "    best_val_acc = 0\n",
        "    best_test_acc = 0\n",
        "    features = g.ndata[\"feat\"]\n",
        "    labels = g.ndata[\"label\"]\n",
        "    train_mask = g.ndata[\"train_mask\"]\n",
        "    val_mask = g.ndata[\"val_mask\"]\n",
        "    test_mask = g.ndata[\"test_mask\"]\n",
        "    for e in range(201):\n",
        "        logits = model(g, features) # forward\n",
        "        pred = logits.argmax(1) # prediction\n",
        "        loss = func.cross_entropy(logits[train_mask], labels[train_mask])\n",
        "        # compute accuracy on training/validation/test\n",
        "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
        "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
        "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
        "        # save the best validation accuracy and the corresponding test accuracy\n",
        "        if best_val_acc < val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        all_logits.append(logits.detach())\n",
        "        if e % 20 == 0:\n",
        "            print(\"In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})\".format(e, loss, val_acc, best_val_acc, test_acc, best_test_acc))"
      ],
      "metadata": {
        "id": "j9XaxG0Vm5pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(g.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
        "train(g, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqZUTI7um5r6",
        "outputId": "cfae1735-baf3-4d8f-b8d3-b28b2d8a81e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, loss: 1.951, val acc: 0.316 (best 0.316), test acc: 0.319 (best 0.319)\n",
            "In epoch 20, loss: 1.356, val acc: 0.482 (best 0.586), test acc: 0.459 (best 0.566)\n",
            "In epoch 40, loss: 0.388, val acc: 0.750 (best 0.750), test acc: 0.744 (best 0.744)\n",
            "In epoch 60, loss: 0.068, val acc: 0.742 (best 0.756), test acc: 0.755 (best 0.752)\n",
            "In epoch 80, loss: 0.022, val acc: 0.748 (best 0.756), test acc: 0.755 (best 0.752)\n",
            "In epoch 100, loss: 0.013, val acc: 0.746 (best 0.756), test acc: 0.752 (best 0.752)\n",
            "In epoch 120, loss: 0.009, val acc: 0.746 (best 0.756), test acc: 0.751 (best 0.752)\n",
            "In epoch 140, loss: 0.007, val acc: 0.744 (best 0.756), test acc: 0.751 (best 0.752)\n",
            "In epoch 160, loss: 0.005, val acc: 0.742 (best 0.756), test acc: 0.752 (best 0.752)\n",
            "In epoch 180, loss: 0.004, val acc: 0.740 (best 0.756), test acc: 0.751 (best 0.752)\n",
            "In epoch 200, loss: 0.003, val acc: 0.740 (best 0.756), test acc: 0.754 (best 0.752)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weighted GraphSAGE Conv Implementation"
      ],
      "metadata": {
        "id": "7fzbE6UGrpty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dgl.data.CoraGraphDataset()\n",
        "g = dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLAEbl42hmvy",
        "outputId": "a464b4d6-a424-474c-bf09-f9178d537b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightedSAGEConv(nn.Module):\n",
        "    \"\"\"Graph convolution module used by the GraphSAGE model with edge weights.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_feat : int\n",
        "        Input feature size.\n",
        "    out_feat : int\n",
        "        Output feature size.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(WeightedSAGEConv, self).__init__()\n",
        "        # a linear submodule for projecting the input and neighbor feature to the output\n",
        "        self.linear = nn.Linear(in_feat*2, out_feat)\n",
        "\n",
        "    def forward(self, g, h, w):\n",
        "        \"\"\"Forward computation\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        g : Graph\n",
        "            The input graph.\n",
        "        h : Tensor\n",
        "            The input node feature.\n",
        "        w : Tensor\n",
        "            The edge weight.\n",
        "        \"\"\"\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.edata[\"w\"] = w\n",
        "            g.update_all(message_func=fn.u_mul_e(\"h\", \"w\", \"m\"),reduce_func=fn.mean(\"m\", \"h_N\"))\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "metadata": {
        "id": "kf_wC8v7m5vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = WeightedSAGEConv(in_feats, h_feats)\n",
        "        self.conv2 = WeightedSAGEConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat, torch.ones(g.num_edges(), 1).to(g.device))\n",
        "        h = func.relu(h)\n",
        "        h = self.conv2(g, h, torch.ones(g.num_edges(), 1).to(g.device))\n",
        "        return h"
      ],
      "metadata": {
        "id": "tnUbmhY7m5zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(g, model):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    all_logits = []\n",
        "    best_val_acc = 0\n",
        "    best_test_acc = 0\n",
        "    features = g.ndata[\"feat\"]\n",
        "    labels = g.ndata[\"label\"]\n",
        "    train_mask = g.ndata[\"train_mask\"]\n",
        "    val_mask = g.ndata[\"val_mask\"]\n",
        "    test_mask = g.ndata[\"test_mask\"]\n",
        "    for e in range(201):\n",
        "        logits = model(g, features) # forward\n",
        "        pred = logits.argmax(1) # prediction\n",
        "        loss = func.cross_entropy(logits[train_mask], labels[train_mask])\n",
        "        # compute accuracy on training/validation/test\n",
        "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
        "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
        "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
        "        # save the best validation accuracy and the corresponding test accuracy\n",
        "        if best_val_acc < val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        all_logits.append(logits.detach())\n",
        "        if e % 20 == 0:\n",
        "            print(\"In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})\".format(e, loss, val_acc, best_val_acc, test_acc, best_test_acc))"
      ],
      "metadata": {
        "id": "07YyHKDOsLtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(g.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
        "train(g, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJPLuHAIm54H",
        "outputId": "a55d1783-b410-4fd2-dcb2-b2c2f997128e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10556, 1]) torch.Size([2708, 1433])\n",
            "torch.Size([10556, 1]) torch.Size([2708, 16])\n",
            "In epoch 0, loss: 1.953, val acc: 0.316 (best 0.316), test acc: 0.319 (best 0.319)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Link Prediction"
      ],
      "metadata": {
        "id": "TLcLoBWKsSBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dgl.data.CoraGraphDataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sezqOktjn6I",
        "outputId": "1cf8874e-6ab3-4b16-8660-368b8ded9c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = dataset[0]"
      ],
      "metadata": {
        "id": "Lko6fece-sU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u, v = graph.edges() # split edge set for training and testing\n",
        "eids = np.arange(graph.num_edges())\n",
        "eids = np.random.permutation(eids)\n",
        "test_size = int(len(eids) * 0.1)\n",
        "train_size = graph.num_edges() - test_size\n",
        "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
        "# find all negative edges and split them for training and testing\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
        "adj_neg = 1 - adj.todense() - np.eye(graph.num_nodes())\n",
        "neg_u, neg_v = np.where(adj_neg!=0)\n",
        "neg_eids = np.random.choice(len(neg_u), graph.num_edges())\n",
        "test_neg_u, test_neg_v = (\n",
        "    neg_u[neg_eids[:test_size]],\n",
        "    neg_v[neg_eids[:test_size]],\n",
        "    )\n",
        "train_neg_u, train_neg_v = (\n",
        "    neg_u[neg_eids[test_size:]],\n",
        "    neg_v[neg_eids[test_size:]],\n",
        "    )"
      ],
      "metadata": {
        "id": "Liw1as4l-scj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_graph = dgl.remove_edges(graph, eids[:test_size]) # remove the edges in the test set from the original graph"
      ],
      "metadata": {
        "id": "JSpT2MHJBLwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build a two-layer GraphSAGE model\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, \"mean\")\n",
        "        self.conv2 = SAGEConv(h_feats, h_feats, \"mean\")\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = func.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "yE-WOIwSBc27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# positive and negative graphs\n",
        "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=graph.num_nodes())\n",
        "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=graph.num_nodes())\n",
        "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=graph.num_nodes())\n",
        "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=graph.num_nodes())"
      ],
      "metadata": {
        "id": "FPB5t9B_Bc6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            # compute a new edge feature named 'score' by a dot-product between the\n",
        "            # source node feature 'h' and destination node feature 'h'.\n",
        "            g.apply_edges(fn.u_dot_v(\"h\", \"h\", \"score\"))\n",
        "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
        "            return g.edata[\"score\"][:, 0]\n",
        "\n",
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self, h_feats):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
        "        self.W2 = nn.Linear(h_feats, 1)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        \"\"\"\n",
        "        Computes a scalar score for each edge of the given graph\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        edges :\n",
        "            Has three members ``src``, ``dst`` and ``data``, each of\n",
        "            which is a dictionary representing the features of the\n",
        "            source nodes, the destination nodes, and the edges\n",
        "            themselves\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            A dictionary of new edge features.\n",
        "        \"\"\"\n",
        "        h = torch.cat([edges.src[\"h\"], edges.dst[\"h\"]], 1)\n",
        "        return {\"score\": self.W2(func.relu(self.W1(h))).squeeze(1)}\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.apply_edges(self.apply_edges)\n",
        "            return g.edata[\"score\"]"
      ],
      "metadata": {
        "id": "tHBpCNOVBc9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphSAGE(train_graph.ndata[\"feat\"].shape[1], 16)\n",
        "pred = DotPredictor() # replace DotPredictor with MLPPredictor as pred = MLPPredictor(16)\n",
        "\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
        "        )\n",
        "    return func.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
        "    ).numpy()\n",
        "    return roc_auc_score(labels, scores)"
      ],
      "metadata": {
        "id": "PL1SfnmcBdAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
        "all_logits = []\n",
        "for e in range(101):\n",
        "    # forward\n",
        "    h = model(train_graph, train_graph.ndata[\"feat\"])\n",
        "    pos_score = pred(train_pos_g, h)\n",
        "    neg_score = pred(train_neg_g, h)\n",
        "    loss = compute_loss(pos_score, neg_score)\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if e%20==0:\n",
        "        print(\"In epoch {}, loss: {}\".format(e, loss))\n",
        "\n",
        "with torch.no_grad():\n",
        "    pos_score = pred(test_pos_g, h)\n",
        "    neg_score = pred(test_neg_g, h)\n",
        "    print(\"AUC\", compute_auc(pos_score, neg_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWH48mM3BdDm",
        "outputId": "142219a6-f0f7-4756-ec38-3a470c902ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, loss: 0.6983332633972168\n",
            "In epoch 20, loss: 0.5125433802604675\n",
            "In epoch 40, loss: 0.4140874743461609\n",
            "In epoch 60, loss: 0.32917582988739014\n",
            "In epoch 80, loss: 0.24367840588092804\n",
            "In epoch 100, loss: 0.1606931835412979\n",
            "AUC 0.8633184339974393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Classification"
      ],
      "metadata": {
        "id": "Zi7TLXhFoxI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a synthetic dataset with 10000 graphs, ranging from 10 to 500 nodes.\n",
        "dataset = dgl.data.GINDataset(\"PROTEINS\", self_loop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgmpmm7Jo3us",
        "outputId": "e8762cd5-2d8b-4683-fd5a-eeb22081cd84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/GINDataset.zip from https://raw.githubusercontent.com/weihua916/powerful-gnns/master/dataset.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.dgl/GINDataset.zip: 100%|██████████| 33.4M/33.4M [00:00<00:00, 37.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting file to /root/.dgl/GINDataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Node feature dimensionality:\", dataset.dim_nfeats)\n",
        "print(\"Number of graph categories:\", dataset.gclasses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcD_13Gro340",
        "outputId": "9fcffd10-1c22-44e5-a1a3-a371e629d8c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node feature dimensionality: 3\n",
            "Number of graph categories: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_examples = len(dataset)\n",
        "num_train = int(num_examples * 0.8)\n",
        "train_sampler = SubsetRandomSampler(torch.arange(num_train))\n",
        "test_sampler = SubsetRandomSampler(torch.arange(num_train, num_examples))\n",
        "train_dataloader = GraphDataLoader(dataset, sampler=train_sampler, batch_size=5, drop_last=False)\n",
        "test_dataloader = GraphDataLoader(dataset, sampler=test_sampler, batch_size=5, drop_last=False)"
      ],
      "metadata": {
        "id": "85KUZMXNo4CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "it = iter(train_dataloader)\n",
        "batch = next(it)\n",
        "print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PF2ZtnXo4GK",
        "outputId": "59cb982c-19a2-4da6-c9db-0843bcec22fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Graph(num_nodes=148, num_edges=700,\n",
            "      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'attr': Scheme(shape=(3,), dtype=torch.float32)}\n",
            "      edata_schemes={}), tensor([0, 0, 0, 0, 0])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batched_graph, labels = batch\n",
        "print(\n",
        "    \"Number of nodes for each graph element in the batch:\",\n",
        "    batched_graph.batch_num_nodes(),\n",
        "    )\n",
        "print(\n",
        "    \"Number of edges for each graph element in the batch:\",\n",
        "    batched_graph.batch_num_edges(),\n",
        "    )\n",
        "# recover the original graph elements from the minibatch\n",
        "graphs = dgl.unbatch(batched_graph)\n",
        "print(\"The original graphs in the minibatch:\")\n",
        "print(graphs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7L6hrB-o4Jm",
        "outputId": "523ba374-a4a3-4270-9f92-c0f3ce3bd60f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes for each graph element in the batch: tensor([35,  9, 32, 55, 17])\n",
            "Number of edges for each graph element in the batch: tensor([175,  45, 144, 263,  73])\n",
            "The original graphs in the minibatch:\n",
            "[Graph(num_nodes=35, num_edges=175,\n",
            "      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'attr': Scheme(shape=(3,), dtype=torch.float32)}\n",
            "      edata_schemes={}), Graph(num_nodes=9, num_edges=45,\n",
            "      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'attr': Scheme(shape=(3,), dtype=torch.float32)}\n",
            "      edata_schemes={}), Graph(num_nodes=32, num_edges=144,\n",
            "      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'attr': Scheme(shape=(3,), dtype=torch.float32)}\n",
            "      edata_schemes={}), Graph(num_nodes=55, num_edges=263,\n",
            "      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'attr': Scheme(shape=(3,), dtype=torch.float32)}\n",
            "      edata_schemes={}), Graph(num_nodes=17, num_edges=73,\n",
            "      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'attr': Scheme(shape=(3,), dtype=torch.float32)}\n",
            "      edata_schemes={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats)\n",
        "        self.conv2 = GraphConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = func.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        g.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(g, \"h\")"
      ],
      "metadata": {
        "id": "ZMJM3Z-to4ON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model with given dimensions\n",
        "model = GCN(dataset.dim_nfeats, 16, dataset.gclasses)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "for epoch in range(20):\n",
        "    for batched_graph, labels in train_dataloader:\n",
        "        pred = model(batched_graph, batched_graph.ndata[\"attr\"].float())\n",
        "        loss = func.cross_entropy(pred, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "num_correct = 0\n",
        "num_tests = 0\n",
        "for batched_graph, labels in test_dataloader:\n",
        "    pred = model(batched_graph, batched_graph.ndata[\"attr\"].float())\n",
        "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
        "    num_tests += len(labels)\n",
        "print(\"Test accuracy:\", num_correct / num_tests)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfoMsHmao4RO",
        "outputId": "4f418b67-b7af-41c7-8d16-0694836142b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.2914798206278027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Isomorphism Network (GIN)"
      ],
      "metadata": {
        "id": "qH6HqcdbrjoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    \"\"\"construct two-layer MLP-type aggreator for GIN model\"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.linears = nn.ModuleList()\n",
        "        # two-layer mlp\n",
        "        self.linears.append(nn.Linear(input_dim, hidden_dim, bias=False))\n",
        "        self.linears.append(nn.Linear(hidden_dim, output_dim, bias=False))\n",
        "        self.batch_norm = nn.BatchNorm1d((hidden_dim))\n",
        "    def forward(self, x):\n",
        "        h = x\n",
        "        h = func.relu(self.batch_norm(self.linears[0](h)))\n",
        "        return self.linears[1](h)"
      ],
      "metadata": {
        "id": "JD4VV7-RsyD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GIN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.ginlayers = nn.ModuleList()\n",
        "        self.batch_norms = nn.ModuleList()\n",
        "        num_layers = 5\n",
        "        # five-layer GCN with two-layer MLP aggregator and sum-neighbor-pooling scheme\n",
        "        for layer in range(num_layers - 1):  # excluding the input layer\n",
        "            if layer == 0:\n",
        "                mlp = MLP(input_dim, hidden_dim, hidden_dim)\n",
        "            else:\n",
        "                mlp = MLP(hidden_dim, hidden_dim, hidden_dim)\n",
        "            self.ginlayers.append(\n",
        "                GINConv(mlp, learn_eps=False)\n",
        "                )  # set to True if learning epsilon\n",
        "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
        "        # linear functions for graph sum poolings of output of each layer\n",
        "        self.linear_prediction = nn.ModuleList()\n",
        "        for layer in range(num_layers):\n",
        "            if layer == 0:\n",
        "                self.linear_prediction.append(nn.Linear(input_dim, output_dim))\n",
        "            else:\n",
        "                self.linear_prediction.append(nn.Linear(hidden_dim, output_dim))\n",
        "        self.drop = nn.Dropout(0.5)\n",
        "        self.pool = (SumPooling())  # change to mean readout (AvgPooling) on social network datasets\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        # list of hidden representation at each layer (including the input layer)\n",
        "        hidden_rep = [h]\n",
        "        for i, layer in enumerate(self.ginlayers):\n",
        "            h = layer(g, h)\n",
        "            h = self.batch_norms[i](h)\n",
        "            h = func.relu(h)\n",
        "            hidden_rep.append(h)\n",
        "        score_over_layer = 0\n",
        "        # perform graph sum pooling over all nodes in each layer\n",
        "        for i, h in enumerate(hidden_rep):\n",
        "            pooled_h = self.pool(g, h)\n",
        "            score_over_layer += self.drop(self.linear_prediction[i](pooled_h))\n",
        "        return score_over_layer"
      ],
      "metadata": {
        "id": "y39mN6jMsyPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_fold10(labels, fold_idx=0):\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
        "    idx_list = []\n",
        "    for idx in skf.split(np.zeros(len(labels)), labels):\n",
        "        idx_list.append(idx)\n",
        "    train_idx, valid_idx = idx_list[fold_idx]\n",
        "    return train_idx, valid_idx"
      ],
      "metadata": {
        "id": "0Ze6TfV3s8Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader, model):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    total_correct = 0\n",
        "    for batched_graph, labels in dataloader:\n",
        "        batched_graph = batched_graph\n",
        "        labels = labels\n",
        "        feat = batched_graph.ndata.pop(\"attr\")\n",
        "        total += len(labels)\n",
        "        logits = model(batched_graph, feat)\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "    acc = 1.0 * total_correct / total\n",
        "    return acc"
      ],
      "metadata": {
        "id": "2Id49uaQs8R5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, val_loader, model):\n",
        "    # loss function, optimizer and scheduler\n",
        "    loss_fcn = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
        "    # training loop\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch, (batched_graph, labels) in enumerate(train_loader):\n",
        "            batched_graph = batched_graph\n",
        "            labels = labels\n",
        "            feat = batched_graph.ndata.pop(\"attr\")\n",
        "            logits = model(batched_graph, feat)\n",
        "            loss = loss_fcn(logits, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        scheduler.step()\n",
        "        train_acc = evaluate(train_loader, model)\n",
        "        valid_acc = evaluate(val_loader, model)\n",
        "        print(\"Epoch {:05d} | Loss {:.4f} | Train Acc. {:.4f} | Validation Acc. {:.4f} \".format(\n",
        "            epoch, total_loss / (batch + 1), train_acc, valid_acc))"
      ],
      "metadata": {
        "id": "GkxA_BnMs8X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"MUTAG\"\n",
        "dataset = GINDataset(dataset, self_loop=True, degree_as_nlabel=False)  # add self_loop and disable one-hot encoding for input features\n",
        "labels = [l for _, l in dataset]\n",
        "train_idx, val_idx = split_fold10(labels)\n",
        "# create dataloader\n",
        "train_loader = GraphDataLoader(\n",
        "    dataset, sampler=SubsetRandomSampler(train_idx),\n",
        "    batch_size=128, pin_memory=torch.cuda.is_available(),\n",
        "    )\n",
        "val_loader = GraphDataLoader(\n",
        "    dataset, sampler=SubsetRandomSampler(val_idx),\n",
        "    batch_size=128, pin_memory=torch.cuda.is_available(),\n",
        "    )\n",
        "# create GIN model\n",
        "in_size = dataset.dim_nfeats\n",
        "out_size = dataset.gclasses\n",
        "model = GIN(in_size, 16, out_size)\n",
        "# model training/validating\n",
        "print(\"Training...\")\n",
        "train(train_loader, val_loader, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8dIlSNFs8gS",
        "outputId": "b813dd81-8370-456d-ade5-539c571a270c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/GINDataset.zip from https://raw.githubusercontent.com/weihua916/powerful-gnns/master/dataset.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.dgl/GINDataset.zip: 100%|██████████| 33.4M/33.4M [00:00<00:00, 57.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting file to /root/.dgl/GINDataset\n",
            "Training...\n",
            "Epoch 00000 | Loss 7.9970 | Train Acc. 0.6746 | Validation Acc. 0.7368 \n",
            "Epoch 00001 | Loss 2.5250 | Train Acc. 0.6627 | Validation Acc. 0.6842 \n",
            "Epoch 00002 | Loss 2.5683 | Train Acc. 0.6627 | Validation Acc. 0.6842 \n",
            "Epoch 00003 | Loss 2.8745 | Train Acc. 0.6627 | Validation Acc. 0.6842 \n",
            "Epoch 00004 | Loss 2.7105 | Train Acc. 0.6627 | Validation Acc. 0.6842 \n",
            "Epoch 00005 | Loss 1.7668 | Train Acc. 0.6627 | Validation Acc. 0.6842 \n",
            "Epoch 00006 | Loss 1.4262 | Train Acc. 0.6627 | Validation Acc. 0.6842 \n",
            "Epoch 00007 | Loss 1.4870 | Train Acc. 0.6627 | Validation Acc. 0.6842 \n",
            "Epoch 00008 | Loss 1.1107 | Train Acc. 0.6627 | Validation Acc. 0.6842 \n",
            "Epoch 00009 | Loss 1.0967 | Train Acc. 0.6627 | Validation Acc. 0.6842 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Dataset"
      ],
      "metadata": {
        "id": "YVjMHgidue7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Dataset for Node Classification or Link Prediction from CSV"
      ],
      "metadata": {
        "id": "3Zy96iMkcYSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://data.dgl.ai/tutorial/dataset/members.csv\", \"./members.csv\")\n",
        "urllib.request.urlretrieve(\"https://data.dgl.ai/tutorial/dataset/interactions.csv\", \"./interactions.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXe8DygDcKXE",
        "outputId": "228d1572-4365-4363-8174-165953911f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./interactions.csv', <http.client.HTTPMessage at 0x79f043b27b50>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "members = pd.read_csv(\"./members.csv\") # the attributes of all members\n",
        "members.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gSEReHfWcKg-",
        "outputId": "ebc992f0-da30-4d71-d212-75b809facfc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id    Club  Age\n",
              "0   0  Mr. Hi   44\n",
              "1   1  Mr. Hi   37\n",
              "2   2  Mr. Hi   37\n",
              "3   3  Mr. Hi   40\n",
              "4   4  Mr. Hi   30"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-570ba217-9c2c-49d2-9585-1651c6a6473c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Club</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Mr. Hi</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Mr. Hi</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Mr. Hi</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Mr. Hi</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Mr. Hi</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-570ba217-9c2c-49d2-9585-1651c6a6473c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-570ba217-9c2c-49d2-9585-1651c6a6473c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-570ba217-9c2c-49d2-9585-1651c6a6473c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-515e03ff-0e75-4e6a-a19b-73832cc390da\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-515e03ff-0e75-4e6a-a19b-73832cc390da')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-515e03ff-0e75-4e6a-a19b-73832cc390da button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interactions = pd.read_csv(\"./interactions.csv\") # the pair-wise interactions between two club members\n",
        "interactions.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BW108FpDcKlu",
        "outputId": "700a60df-fe59-4d65-fb8b-8fc9224f134d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Src  Dst    Weight\n",
              "0    0    1  0.043591\n",
              "1    0    2  0.282119\n",
              "2    0    3  0.370293\n",
              "3    0    4  0.730570\n",
              "4    0    5  0.821187"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf46d3ec-abb6-45ca-a3a9-60408ec8fd56\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Src</th>\n",
              "      <th>Dst</th>\n",
              "      <th>Weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.043591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.282119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.370293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.730570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.821187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf46d3ec-abb6-45ca-a3a9-60408ec8fd56')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf46d3ec-abb6-45ca-a3a9-60408ec8fd56 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf46d3ec-abb6-45ca-a3a9-60408ec8fd56');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6a00fd36-cea2-4277-bbb6-050f7b9a627a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a00fd36-cea2-4277-bbb6-050f7b9a627a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6a00fd36-cea2-4277-bbb6-050f7b9a627a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "members.Club.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urQwXyINcKs2",
        "outputId": "323cfda5-fa01-4f2e-ea67-ec976b1619a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Mr. Hi', 'Officer'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KarateClubDataset(DGLDataset):\n",
        "    def __init__(self):\n",
        "        super().__init__(name=\"karate_club\")\n",
        "\n",
        "    def process(self):\n",
        "        nodes_data = pd.read_csv(\"./members.csv\")\n",
        "        edges_data = pd.read_csv(\"./interactions.csv\")\n",
        "        node_features = torch.from_numpy(nodes_data[\"Age\"].to_numpy())\n",
        "        node_labels = torch.from_numpy(\n",
        "            nodes_data[\"Club\"].astype(\"category\").cat.codes.to_numpy()\n",
        "            )\n",
        "        edge_features = torch.from_numpy(edges_data[\"Weight\"].to_numpy())\n",
        "        edges_src = torch.from_numpy(edges_data[\"Src\"].to_numpy())\n",
        "        edges_dst = torch.from_numpy(edges_data[\"Dst\"].to_numpy())\n",
        "        self.graph = dgl.graph(\n",
        "            (edges_src, edges_dst), num_nodes=nodes_data.shape[0]\n",
        "            )\n",
        "        self.graph.ndata[\"feat\"] = node_features\n",
        "        self.graph.ndata[\"label\"] = node_labels\n",
        "        self.graph.edata[\"weight\"] = edge_features\n",
        "        # if the dataset is a node classification dataset, one needs to assign\n",
        "        # masks indicating whether a node belongs to training, validation, and test set\n",
        "        n_nodes = nodes_data.shape[0]\n",
        "        n_train = int(n_nodes * 0.6)\n",
        "        n_val = int(n_nodes * 0.2)\n",
        "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        train_mask[:n_train] = True\n",
        "        val_mask[n_train : n_train + n_val] = True\n",
        "        test_mask[n_train + n_val :] = True\n",
        "        self.graph.ndata[\"train_mask\"] = train_mask\n",
        "        self.graph.ndata[\"val_mask\"] = val_mask\n",
        "        self.graph.ndata[\"test_mask\"] = test_mask\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.graph\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1"
      ],
      "metadata": {
        "id": "x6dbqjjocK0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = KarateClubDataset()\n",
        "graph = dataset[0]\n",
        "print(graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsxnC6ZhcK6L",
        "outputId": "9474f2e3-53e0-44c2-c25b-3850583dbc81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=34, num_edges=156,\n",
            "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int8), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
            "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-5db7c809ca09>:9: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  node_labels = torch.from_numpy(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset for Graph Classification from CSV"
      ],
      "metadata": {
        "id": "av5QPF5xeJ7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\n",
        "    \"https://data.dgl.ai/tutorial/dataset/graph_edges.csv\", \"./graph_edges.csv\"\n",
        "    )\n",
        "urllib.request.urlretrieve(\n",
        "    \"https://data.dgl.ai/tutorial/dataset/graph_properties.csv\",\n",
        "    \"./graph_properties.csv\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHbpYMLqez_z",
        "outputId": "9db188eb-0ce1-4fac-bddb-c2e3c5057369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./graph_properties.csv', <http.client.HTTPMessage at 0x79f05bf33df0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edges = pd.read_csv(\"./graph_edges.csv\")\n",
        "edges.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pBtzvgTIe0Jo",
        "outputId": "e847a924-bc4d-4b8f-c5fb-b421ac761809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   graph_id  src  dst\n",
              "0         0    0    1\n",
              "1         0    0   14\n",
              "2         0    1    0\n",
              "3         0    1    2\n",
              "4         0    2    1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19e37807-30ea-48bc-91a7-f82e6cc95aac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>graph_id</th>\n",
              "      <th>src</th>\n",
              "      <th>dst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19e37807-30ea-48bc-91a7-f82e6cc95aac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-19e37807-30ea-48bc-91a7-f82e6cc95aac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-19e37807-30ea-48bc-91a7-f82e6cc95aac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0dcde1a1-9820-4560-95c9-999a8162d579\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0dcde1a1-9820-4560-95c9-999a8162d579')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0dcde1a1-9820-4560-95c9-999a8162d579 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "properties = pd.read_csv(\"./graph_properties.csv\")\n",
        "properties.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sNWnGILYe7kV",
        "outputId": "6128e15a-094d-4991-befd-4256e20c8919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   graph_id  label  num_nodes\n",
              "0         0      0         15\n",
              "1         1      0         10\n",
              "2         2      0         13\n",
              "3         3      0         13\n",
              "4         4      0         17"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11ae0a81-0961-4f4e-9eb7-917fefb4f7b6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>graph_id</th>\n",
              "      <th>label</th>\n",
              "      <th>num_nodes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11ae0a81-0961-4f4e-9eb7-917fefb4f7b6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-11ae0a81-0961-4f4e-9eb7-917fefb4f7b6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-11ae0a81-0961-4f4e-9eb7-917fefb4f7b6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fed91b75-438f-41f2-ac69-47f628ba9a40\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fed91b75-438f-41f2-ac69-47f628ba9a40')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fed91b75-438f-41f2-ac69-47f628ba9a40 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SyntheticDataset(DGLDataset):\n",
        "    def __init__(self):\n",
        "        super().__init__(name=\"synthetic\")\n",
        "\n",
        "    def process(self):\n",
        "        edges = pd.read_csv(\"./graph_edges.csv\")\n",
        "        properties = pd.read_csv(\"./graph_properties.csv\")\n",
        "        self.graphs = []\n",
        "        self.labels = []\n",
        "\n",
        "        # create a graph for each graph ID from the edges table\n",
        "        # first process the properties table into two dictionaries with graph IDs as keys\n",
        "        # the label and number of nodes are values\n",
        "        label_dict = {}\n",
        "        num_nodes_dict = {}\n",
        "        for _, row in properties.iterrows():\n",
        "            label_dict[row[\"graph_id\"]] = row[\"label\"]\n",
        "            num_nodes_dict[row[\"graph_id\"]] = row[\"num_nodes\"]\n",
        "\n",
        "        # for the edges, first group the table by graph IDs\n",
        "        edges_group = edges.groupby(\"graph_id\")\n",
        "        # for each graph ID...\n",
        "        for graph_id in edges_group.groups:\n",
        "            # find the edges as well as the number of nodes and its label\n",
        "            edges_of_id = edges_group.get_group(graph_id)\n",
        "            src = edges_of_id[\"src\"].to_numpy()\n",
        "            dst = edges_of_id[\"dst\"].to_numpy()\n",
        "            num_nodes = num_nodes_dict[graph_id]\n",
        "            label = label_dict[graph_id]\n",
        "            # create a graph and add it to the list of graphs and labels\n",
        "            g = dgl.graph((src, dst), num_nodes=num_nodes)\n",
        "            self.graphs.append(g)\n",
        "            self.labels.append(label)\n",
        "        # convert the label list to tensor for saving.\n",
        "        self.labels = torch.LongTensor(self.labels)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.graphs[i], self.labels[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graphs)"
      ],
      "metadata": {
        "id": "6hqSWK6eeSqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = SyntheticDataset()\n",
        "graph, label = dataset[0]\n",
        "print(graph, label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6BGfSAJe7zb",
        "outputId": "bccc405b-c7ee-410d-ffd9-5d84c8fd29b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=15, num_edges=45,\n",
            "      ndata_schemes={}\n",
            "      edata_schemes={}) tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GraphBolt Node Pred"
      ],
      "metadata": {
        "id": "yCsv5wvBn-nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = gb.BuiltinDataset(\"ogbn-arxiv\").load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDdeIZhseSyf",
        "outputId": "e7bb2d7e-4199-47c3-f0d4-12f81566cc24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datasets/ogbn-arxiv.zip from https://data.dgl.ai/dataset/graphbolt/ogbn-arxiv.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "datasets/ogbn-arxiv.zip: 100%|██████████| 84.6M/84.6M [00:04<00:00, 17.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting file to datasets\n",
            "The dataset is already preprocessed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = dataset.graph\n",
        "feature = dataset.feature\n",
        "train_set = dataset.tasks[0].train_set\n",
        "valid_set = dataset.tasks[0].validation_set\n",
        "test_set = dataset.tasks[0].test_set\n",
        "task_name = dataset.tasks[0].metadata[\"name\"]\n",
        "num_classes = dataset.tasks[0].metadata[\"num_classes\"]\n",
        "print(f\"Task: {task_name}. Number of classes: {num_classes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zmuxn5DHeS34",
        "outputId": "b0bc69f2-0ac8-4bee-f425-cc8c57983a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task: node_classification. Number of classes: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datapipe = gb.ItemSampler(train_set, batch_size=1024, shuffle=True)\n",
        "datapipe = datapipe.sample_neighbor(graph, [4, 4])\n",
        "datapipe = datapipe.fetch_feature(feature, node_feature_keys=[\"feat\"])\n",
        "datapipe = datapipe.copy_to(device)\n",
        "train_dataloader = gb.DataLoader(datapipe, num_workers=0)"
      ],
      "metadata": {
        "id": "REFWq8F4eS6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = next(iter(train_dataloader))\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyYbmqQfpC3H",
        "outputId": "b7418427-7ed4-45d2-c22b-8e8b03ca9f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MiniBatch(seed_nodes=tensor([132512, 168973, 150919,  ...,  56791,  29981,   3434]),\n",
            "          sampled_subgraphs=[SampledSubgraphImpl(sampled_csc=CSCFormatBase(indptr=tensor([   0,    1,    3,  ..., 6129, 6130, 6134]),\n",
            "                                                                         indices=tensor([1024, 1025, 1026,  ..., 7103, 7104, 7099]),\n",
            "                                                           ),\n",
            "                                               original_row_node_ids=tensor([132512, 168973, 150919,  ..., 159386,  24400,  49850]),\n",
            "                                               original_edge_ids=None,\n",
            "                                               original_column_node_ids=tensor([132512, 168973, 150919,  ..., 162861,  18715, 114037]),\n",
            "                            ),\n",
            "                            SampledSubgraphImpl(sampled_csc=CSCFormatBase(indptr=tensor([   0,    1,    3,  ..., 2226, 2227, 2230]),\n",
            "                                                                         indices=tensor([1024, 1025, 1026,  ..., 3213, 3214, 3215]),\n",
            "                                                           ),\n",
            "                                               original_row_node_ids=tensor([132512, 168973, 150919,  ..., 162861,  18715, 114037]),\n",
            "                                               original_edge_ids=None,\n",
            "                                               original_column_node_ids=tensor([132512, 168973, 150919,  ...,  56791,  29981,   3434]),\n",
            "                            )],\n",
            "          positive_node_pairs=None,\n",
            "          node_pairs_with_labels=None,\n",
            "          node_pairs=None,\n",
            "          node_features={'feat': tensor([[-0.0043, -0.0660, -0.1978,  ...,  0.1548,  0.0578, -0.1576],\n",
            "                                [-0.2923, -0.0707, -0.2717,  ...,  0.0655, -0.2148, -0.0493],\n",
            "                                [-0.0845,  0.2364, -0.1155,  ...,  0.2358, -0.3437, -0.1634],\n",
            "                                ...,\n",
            "                                [ 0.1118,  0.1697, -0.2353,  ...,  0.0779, -0.0012, -0.1039],\n",
            "                                [ 0.0091,  0.0171, -0.1879,  ...,  0.2108,  0.0230, -0.2570],\n",
            "                                [-0.0796, -0.0311, -0.1646,  ...,  0.2434,  0.1287, -0.1068]])},\n",
            "          negative_srcs=None,\n",
            "          negative_node_pairs=None,\n",
            "          negative_dsts=None,\n",
            "          labels=tensor([37,  2, 24,  ..., 31, 28, 19]),\n",
            "          input_nodes=tensor([132512, 168973, 150919,  ..., 159386,  24400,  49850]),\n",
            "          edge_features=[{},\n",
            "                        {}],\n",
            "          compacted_node_pairs=None,\n",
            "          compacted_negative_srcs=None,\n",
            "          compacted_negative_dsts=None,\n",
            "          blocks=[Block(num_src_nodes=7105, num_dst_nodes=3216, num_edges=6134),\n",
            "                 Block(num_src_nodes=3216, num_dst_nodes=1024, num_edges=2230)],\n",
            "       )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mfgs = data.blocks\n",
        "input_nodes = mfgs[0].srcdata[dgl.NID]\n",
        "print(f\"Input nodes: {input_nodes}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTHVZulPpECo",
        "outputId": "c54f2aa8-39f6-4aa1-8ffa-79cb05e410de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input nodes: tensor([132512, 168973, 150919,  ..., 159386,  24400,  49850]).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, aggregator_type=\"mean\")\n",
        "        self.conv2 = SAGEConv(h_feats, num_classes, aggregator_type=\"mean\")\n",
        "        self.h_feats = h_feats\n",
        "\n",
        "    def forward(self, mfgs, x):\n",
        "        h = self.conv1(mfgs[0], x)\n",
        "        h = func.relu(h)\n",
        "        h = self.conv2(mfgs[1], h)\n",
        "        return h\n",
        "\n",
        "in_size = feature.size(\"node\", None, \"feat\")[0]\n",
        "model = Model(in_size, 64, num_classes).to(device)"
      ],
      "metadata": {
        "id": "TGNtsztYpHD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "8YbQFc7OpHl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datapipe = gb.ItemSampler(valid_set, batch_size=1024, shuffle=False)\n",
        "datapipe = datapipe.sample_neighbor(graph, [4, 4])\n",
        "datapipe = datapipe.fetch_feature(feature, node_feature_keys=[\"feat\"])\n",
        "datapipe = datapipe.copy_to(device)\n",
        "valid_dataloader = gb.DataLoader(datapipe, num_workers=0)"
      ],
      "metadata": {
        "id": "ONR0kRBtpHrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    with tqdm.tqdm(train_dataloader) as tq:\n",
        "        for step, data in enumerate(tq):\n",
        "            x = data.node_features[\"feat\"]\n",
        "            labels = data.labels\n",
        "            predictions = model(data.blocks, x)\n",
        "            loss = func.cross_entropy(predictions, labels)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            accuracy = accuracy_score(\n",
        "                labels.cpu().numpy(),\n",
        "                predictions.argmax(1).detach().cpu().numpy(),\n",
        "                )\n",
        "            tq.set_postfix(\n",
        "                {\"loss\": \"%.03f\" % loss.item(), \"acc\": \"%.03f\" % accuracy},\n",
        "                refresh=False,\n",
        "                )\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    with tqdm.tqdm(valid_dataloader) as tq, torch.no_grad():\n",
        "        for data in tq:\n",
        "            x = data.node_features[\"feat\"]\n",
        "            labels.append(data.labels.cpu().numpy())\n",
        "            predictions.append(model(data.blocks, x).argmax(1).cpu().numpy())\n",
        "        predictions = np.concatenate(predictions)\n",
        "        labels = np.concatenate(labels)\n",
        "        accuracy = accuracy_score(labels, predictions)\n",
        "        print(\"Epoch {} Validation Accuracy {}\".format(epoch, accuracy))\n",
        "        break # note that this tutorial do not train the whole model to the end."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3txvauspHvD",
        "outputId": "1da133a7-13aa-4112-a994-bbe9bcf43e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "89it [00:03, 28.68it/s, loss=2.299, acc=0.385]\n",
            "30it [00:00, 79.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Validation Accuracy 0.3853820598006645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GraphBolt Link Pred"
      ],
      "metadata": {
        "id": "pa1ElLfxqZ9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = gb.BuiltinDataset(\"cora\").load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPVdybJaqc4K",
        "outputId": "9837e416-2582-440c-f1bf-f98eebd2ad47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading datasets/cora.zip from https://data.dgl.ai/dataset/graphbolt/cora.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "datasets/cora.zip: 100%|██████████| 240k/240k [00:00<00:00, 580kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting file to datasets\n",
            "Start to preprocess the on-disk dataset.\n",
            "Finish preprocessing the on-disk dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = dataset.graph\n",
        "feature = dataset.feature\n",
        "train_set = dataset.tasks[1].train_set\n",
        "test_set = dataset.tasks[1].test_set\n",
        "task_name = dataset.tasks[1].metadata[\"name\"]\n",
        "print(f\"Task: {task_name}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c397zpAqdCk",
        "outputId": "432b9843-da8a-470c-e2bd-7379691c07bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task: link_prediction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datapipe = gb.ItemSampler(train_set, batch_size=256, shuffle=True)\n",
        "datapipe = datapipe.sample_uniform_negative(graph, 5)\n",
        "datapipe = datapipe.sample_neighbor(graph, [5, 5, 5])\n",
        "datapipe = datapipe.transform(partial(gb.exclude_seed_edges, include_reverse_edges=True))\n",
        "datapipe = datapipe.fetch_feature(feature, node_feature_keys=[\"feat\"])\n",
        "datapipe = datapipe.copy_to(device)\n",
        "train_dataloader = gb.DataLoader(datapipe)"
      ],
      "metadata": {
        "id": "LFgI_6UItUvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = next(iter(train_dataloader))\n",
        "print(f\"MiniBatch: {data}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDOQSDXvtUzD",
        "outputId": "6ea637b8-f9a3-4b5f-ed72-7bc41307afb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MiniBatch: MiniBatch(seed_nodes=None,\n",
            "          sampled_subgraphs=[SampledSubgraphImpl(sampled_csc=CSCFormatBase(indptr=tensor([   0,    2,    5,  ..., 7659, 7660, 7662]),\n",
            "                                                                         indices=tensor([1308, 1125, 1309,  ..., 2267, 2516, 2268]),\n",
            "                                                           ),\n",
            "                                               original_row_node_ids=tensor([ 749, 1789, 1956,  ..., 1290, 2545, 2468]),\n",
            "                                               original_edge_ids=None,\n",
            "                                               original_column_node_ids=tensor([ 749, 1789, 1956,  ..., 2209, 2487,  517]),\n",
            "                            ),\n",
            "                            SampledSubgraphImpl(sampled_csc=CSCFormatBase(indptr=tensor([   0,    2,    5,  ..., 7073, 7076, 7077]),\n",
            "                                                                         indices=tensor([1308, 1125, 1309,  ..., 1632, 1303, 1304]),\n",
            "                                                           ),\n",
            "                                               original_row_node_ids=tensor([ 749, 1789, 1956,  ..., 2209, 2487,  517]),\n",
            "                                               original_edge_ids=None,\n",
            "                                               original_column_node_ids=tensor([ 749, 1789, 1956,  ..., 1520, 1766,    7]),\n",
            "                            ),\n",
            "                            SampledSubgraphImpl(sampled_csc=CSCFormatBase(indptr=tensor([   0,    2,    5,  ..., 3923, 3926, 3929]),\n",
            "                                                                         indices=tensor([1308, 1125, 1309,  ..., 2087, 1025, 1326]),\n",
            "                                                           ),\n",
            "                                               original_row_node_ids=tensor([ 749, 1789, 1956,  ..., 1520, 1766,    7]),\n",
            "                                               original_edge_ids=None,\n",
            "                                               original_column_node_ids=tensor([ 749, 1789, 1956,  ...,  246, 1727, 1639]),\n",
            "                            )],\n",
            "          positive_node_pairs=(tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
            "                                       14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
            "                                       28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
            "                                       42,  43,  44,  45,  46,   8,  47,  48,  49,  50,  51,  52,  53,  54,\n",
            "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
            "                                       69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
            "                                       83,  25,  84,  85,  86,  87,  88,  89,  90,  29,  91,  92,  93,  94,\n",
            "                                       95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,  78, 107,\n",
            "                                      108, 109, 110, 111, 112,  29, 113, 114, 115, 116, 117, 118, 119, 120,\n",
            "                                      121, 122,  63, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
            "                                      134, 135, 136, 137, 138, 139, 140, 140, 141, 142, 143, 123, 144, 145,\n",
            "                                        6, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,  65, 157,\n",
            "                                      158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
            "                                      172, 123, 173, 174, 175, 176, 177,  98, 178, 179, 180, 181, 182, 183,\n",
            "                                      184, 185,  25, 186, 187, 188, 189, 190,  27, 191, 192, 193, 194, 195,\n",
            "                                      196, 197, 198, 199, 200,  45, 201, 202, 203, 123, 204, 205, 206, 207,\n",
            "                                      207, 208, 209,  34, 210, 211, 212, 213, 214, 215, 216,  74,  83, 217,\n",
            "                                       46, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,  25, 228, 229,\n",
            "                                      230, 231, 232, 233]),\n",
            "                              tensor([234, 235, 236, 237, 203,  13, 142, 238, 239, 240, 241, 242, 243, 244,\n",
            "                                      245, 246, 247, 138, 248, 249, 250, 251, 115, 252, 253, 132, 254, 255,\n",
            "                                      256, 257, 258, 259,  78, 260, 261, 262, 263, 264, 265, 266, 267, 268,\n",
            "                                      269, 108,  25, 102, 270, 271, 204, 272, 273, 274, 275, 276, 277, 278,\n",
            "                                      279, 280, 281, 282, 245, 283, 284, 124, 285, 286, 287, 288, 289, 290,\n",
            "                                      291, 271, 292, 293, 294, 295, 242, 296, 118, 242, 297, 298, 299, 300,\n",
            "                                      301, 302, 150, 282, 303, 304, 305, 306,  19, 307, 308, 309, 310,  25,\n",
            "                                      311, 312, 313,  25, 285, 314, 315, 316, 317, 318, 319,  74,  32, 320,\n",
            "                                       43, 321, 322, 323, 171,   1, 324, 325, 190, 326, 327, 328,  30, 290,\n",
            "                                       49, 329, 142, 330, 331, 332, 333,  34, 334, 335, 336, 337,  74, 338,\n",
            "                                      301, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
            "                                      352, 353, 354, 355, 356,  84, 350,  27, 357, 358, 359, 360, 361, 362,\n",
            "                                      230, 363, 364,  25,  70,  27, 287, 365, 366, 367, 368, 369, 370, 371,\n",
            "                                      372, 373, 374,  25, 375,  62, 376, 377, 162, 378, 379, 380, 381,  74,\n",
            "                                      382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 367,\n",
            "                                      395, 396, 397, 354, 398, 399, 400, 401, 402, 403, 404, 405, 406, 314,\n",
            "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,  27,\n",
            "                                      420, 421,  26, 414,  25, 422, 423, 424, 425, 426,  25, 245, 427, 428,\n",
            "                                      429,  92, 430, 431])),\n",
            "          node_pairs_with_labels=((tensor([  0,   1,   2,  ..., 233, 233, 233]), tensor([ 234,  235,  236,  ...,  853,  802, 1307])),\n",
            "                                 tensor([1., 1., 1.,  ..., 0., 0., 0.])),\n",
            "          node_pairs=(tensor([ 749, 1789, 1956,  677,  175,   82, 2004, 1616, 2034, 1863, 2696, 1576,\n",
            "                              722, 1138, 2045, 2670, 2406,  407, 2063,  998,  621, 1959, 1051, 1784,\n",
            "                             2411, 1358, 1702,  306, 1985, 1015, 1481, 2503,  199, 1256, 1441, 1927,\n",
            "                             1191,  957,   75, 1906, 2189, 1951, 1062, 1590,  289,  279, 2126, 2034,\n",
            "                              623, 2705,   95,  833, 1109,  737, 2706, 2608, 1343, 1842,  446,  800,\n",
            "                             1546, 2147, 2441, 1443, 1996,  540,  174, 1446, 1610, 1692, 1351,  429,\n",
            "                              465, 1518, 2248, 1169, 1819, 2673,  867, 1869,  441, 2606, 1272, 1978,\n",
            "                              503, 1358, 1753,  889,  790, 1110, 1529, 1653,  978, 1015, 1189, 2383,\n",
            "                             2424, 1499, 1585, 1416, 2010, 1721,  928, 1825, 1209,  666, 2309, 2194,\n",
            "                              449,  823, 1869, 1509,  794, 1386, 1400, 1756, 2555, 1015,  411, 2252,\n",
            "                             2122,  580, 1503,  657, 2335, 1469, 1602, 1229, 1996,  525,  761,  185,\n",
            "                              836, 1958, 1558, 1801,  553,  281,  748, 2367, 2121, 1428, 1396, 2530,\n",
            "                             1681, 1719,   91,   91, 2202, 1986, 2481,  525,  990,  524, 2004,  842,\n",
            "                             2400,  397, 2501,  154, 1331,  236, 1334,  640, 1258,  542,  174,  350,\n",
            "                             2535,  458, 1246, 1732, 2041,  329, 2307,  415, 1018, 2139, 1553,  740,\n",
            "                             1528, 2599,  253,  525, 1524, 1620, 2080, 2240,  493, 1721,  788, 1901,\n",
            "                             2463, 1098, 1605,  552, 1973, 2163, 1358, 1961, 1675, 1464, 1899,  665,\n",
            "                              306,  378,  486,   94,  137,   17,   59, 1175,  102, 2399, 2419,  279,\n",
            "                             1777, 2241, 2217,  525,  444,   20,  529, 1354, 1354,  505,  690, 1441,\n",
            "                             2418, 2509, 1375,  138,  546, 1803,  704, 1169,  503,  958, 2126, 2584,\n",
            "                             1240, 1572, 1516, 1119, 1349,   99,  403, 2031,  757, 1358, 1185,  428,\n",
            "                             2534,  924, 2299, 1763]),\n",
            "                     tensor([1333,  109,  807,  954, 2217, 1138, 1986,  447, 1319, 1701, 2615, 1810,\n",
            "                             1273, 2250,  341, 1194,  523, 1681, 1325, 1431, 1332,  379, 2122, 1072,\n",
            "                             2410,  748,   22, 1656,  438, 2262, 1042,  616, 1869, 1091,  720, 1435,\n",
            "                             2339, 2167,   84, 1964,  847, 2204, 1192,  794, 1358,  666, 1111,   86,\n",
            "                              444,  287, 2182, 2495, 1533, 2178, 2707,  891, 1645, 2405,  118,  820,\n",
            "                              341,  658, 1599,  761,  327,   67, 1742, 1445, 2558,  756,  604,   86,\n",
            "                             1403, 1129,  837, 1720, 1810, 1257,  657, 1810,  193,  670, 1947,  478,\n",
            "                             2001,  797,  154,  820, 1548, 1224, 1984,   43,  998, 1068,   73,  893,\n",
            "                             1839, 1358,   89,  305, 2016, 1358,  327, 1183, 1737, 1850, 1399, 2193,\n",
            "                             2581, 1169,  199,  189, 1590, 2571, 2698, 1632, 2599, 1789, 1577,  121,\n",
            "                              665, 1758, 1502, 2523, 1481,  756,   95, 1254, 1986,  408, 1401,  297,\n",
            "                             2403, 1441, 2338, 1505,  745, 1000, 1169, 2370, 2001, 1534, 1421, 2442,\n",
            "                              409, 1317, 2380, 2123,  751, 1434,  840, 2054,  310,  979, 1987,  161,\n",
            "                              963, 2329, 1106, 1753,  310,  306, 1941, 1598,  452,  484, 2334, 1782,\n",
            "                             2534, 1555,  857, 1358,  429,  306, 1742,  204, 2378, 2140, 1827, 2033,\n",
            "                             1361,  961,  251, 2057, 2499, 1358,  655, 1443, 1759,  228, 2041, 1954,\n",
            "                              340, 1477, 1054, 1169,  252, 2162,  357, 1022, 1914,  181,  645, 2120,\n",
            "                             1775,  148, 2668, 2263, 2144, 2140, 1287,  987, 1448,  963,   65, 1195,\n",
            "                             1624, 2242,   96,  423, 2289, 2270, 1419, 1183,  400, 1251,  311, 2275,\n",
            "                             2021, 2114, 2586, 1776, 2127,  354, 2450,  439,  576,  306, 1608,  876,\n",
            "                             1702, 1776, 1358, 1663, 1634, 2455,  806,  903, 1358,  341,  278,  996,\n",
            "                              729, 2383, 2297, 1736])),\n",
            "          node_features={'feat': tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "                                [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "                                [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "                                ...,\n",
            "                                [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "                                [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "                                [0.0556, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])},\n",
            "          negative_srcs=None,\n",
            "          negative_node_pairs=(tensor([[  0,   0,   0,   0,   0],\n",
            "                                      [  1,   1,   1,   1,   1],\n",
            "                                      [  2,   2,   2,   2,   2],\n",
            "                                      ...,\n",
            "                                      [231, 231, 231, 231, 231],\n",
            "                                      [232, 232, 232, 232, 232],\n",
            "                                      [233, 233, 233, 233, 233]]),\n",
            "                              tensor([[ 432,  433,  434,  435,  436],\n",
            "                                      [ 437,  438,  439,  169,  440],\n",
            "                                      [ 327,  441,  442,  443,  444],\n",
            "                                      ...,\n",
            "                                      [ 581, 1301,   41,  428, 1302],\n",
            "                                      [ 562, 1303, 1240, 1304, 1305],\n",
            "                                      [1306,  434,  853,  802, 1307]])),\n",
            "          negative_dsts=tensor([[ 303, 2048,  286, 2433, 2590],\n",
            "                                [2281, 1299, 2074,  740,  166],\n",
            "                                [1502,  555,  277, 2531, 1289],\n",
            "                                ...,\n",
            "                                [1196,  744, 1951,  996,  490],\n",
            "                                [1125, 1750, 2269,  208,  246],\n",
            "                                [1727,  286, 1158,  661, 1639]]),\n",
            "          labels=None,\n",
            "          input_nodes=tensor([ 749, 1789, 1956,  ..., 1290, 2545, 2468]),\n",
            "          edge_features=[{},\n",
            "                        {},\n",
            "                        {}],\n",
            "          compacted_node_pairs=(tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
            "                                        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
            "                                        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
            "                                        42,  43,  44,  45,  46,   8,  47,  48,  49,  50,  51,  52,  53,  54,\n",
            "                                        55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
            "                                        69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
            "                                        83,  25,  84,  85,  86,  87,  88,  89,  90,  29,  91,  92,  93,  94,\n",
            "                                        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,  78, 107,\n",
            "                                       108, 109, 110, 111, 112,  29, 113, 114, 115, 116, 117, 118, 119, 120,\n",
            "                                       121, 122,  63, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
            "                                       134, 135, 136, 137, 138, 139, 140, 140, 141, 142, 143, 123, 144, 145,\n",
            "                                         6, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,  65, 157,\n",
            "                                       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
            "                                       172, 123, 173, 174, 175, 176, 177,  98, 178, 179, 180, 181, 182, 183,\n",
            "                                       184, 185,  25, 186, 187, 188, 189, 190,  27, 191, 192, 193, 194, 195,\n",
            "                                       196, 197, 198, 199, 200,  45, 201, 202, 203, 123, 204, 205, 206, 207,\n",
            "                                       207, 208, 209,  34, 210, 211, 212, 213, 214, 215, 216,  74,  83, 217,\n",
            "                                        46, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,  25, 228, 229,\n",
            "                                       230, 231, 232, 233]),\n",
            "                               tensor([234, 235, 236, 237, 203,  13, 142, 238, 239, 240, 241, 242, 243, 244,\n",
            "                                       245, 246, 247, 138, 248, 249, 250, 251, 115, 252, 253, 132, 254, 255,\n",
            "                                       256, 257, 258, 259,  78, 260, 261, 262, 263, 264, 265, 266, 267, 268,\n",
            "                                       269, 108,  25, 102, 270, 271, 204, 272, 273, 274, 275, 276, 277, 278,\n",
            "                                       279, 280, 281, 282, 245, 283, 284, 124, 285, 286, 287, 288, 289, 290,\n",
            "                                       291, 271, 292, 293, 294, 295, 242, 296, 118, 242, 297, 298, 299, 300,\n",
            "                                       301, 302, 150, 282, 303, 304, 305, 306,  19, 307, 308, 309, 310,  25,\n",
            "                                       311, 312, 313,  25, 285, 314, 315, 316, 317, 318, 319,  74,  32, 320,\n",
            "                                        43, 321, 322, 323, 171,   1, 324, 325, 190, 326, 327, 328,  30, 290,\n",
            "                                        49, 329, 142, 330, 331, 332, 333,  34, 334, 335, 336, 337,  74, 338,\n",
            "                                       301, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
            "                                       352, 353, 354, 355, 356,  84, 350,  27, 357, 358, 359, 360, 361, 362,\n",
            "                                       230, 363, 364,  25,  70,  27, 287, 365, 366, 367, 368, 369, 370, 371,\n",
            "                                       372, 373, 374,  25, 375,  62, 376, 377, 162, 378, 379, 380, 381,  74,\n",
            "                                       382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 367,\n",
            "                                       395, 396, 397, 354, 398, 399, 400, 401, 402, 403, 404, 405, 406, 314,\n",
            "                                       407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,  27,\n",
            "                                       420, 421,  26, 414,  25, 422, 423, 424, 425, 426,  25, 245, 427, 428,\n",
            "                                       429,  92, 430, 431])),\n",
            "          compacted_negative_srcs=None,\n",
            "          compacted_negative_dsts=tensor([[ 432,  433,  434,  435,  436],\n",
            "                                          [ 437,  438,  439,  169,  440],\n",
            "                                          [ 327,  441,  442,  443,  444],\n",
            "                                          ...,\n",
            "                                          [ 581, 1301,   41,  428, 1302],\n",
            "                                          [ 562, 1303, 1240, 1304, 1305],\n",
            "                                          [1306,  434,  853,  802, 1307]]),\n",
            "          blocks=[Block(num_src_nodes=2596, num_dst_nodes=2537, num_edges=7662),\n",
            "                 Block(num_src_nodes=2537, num_dst_nodes=2272, num_edges=7077),\n",
            "                 Block(num_src_nodes=2272, num_dst_nodes=1308, num_edges=3929)],\n",
            "       )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGE(nn.Module):\n",
        "    def __init__(self, in_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(SAGEConv(in_size, hidden_size, \"mean\"))\n",
        "        self.layers.append(SAGEConv(hidden_size, hidden_size, \"mean\"))\n",
        "        self.hidden_size = hidden_size\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, 1),\n",
        "            )\n",
        "\n",
        "    def forward(self, blocks, x):\n",
        "        hidden_x = x\n",
        "        for layer_idx, (layer, block) in enumerate(zip(self.layers, blocks)):\n",
        "            hidden_x = layer(block, hidden_x)\n",
        "            is_last_layer = layer_idx == len(self.layers) - 1\n",
        "            if not is_last_layer:\n",
        "                hidden_x = func.relu(hidden_x)\n",
        "        return hidden_x"
      ],
      "metadata": {
        "id": "GW27lZNotU3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_size = feature.size(\"node\", None, \"feat\")[0]\n",
        "model = SAGE(in_size, 128).to(device)"
      ],
      "metadata": {
        "id": "Shc4JCtvtwtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "7CbdVfUstU7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for step, data in tqdm.tqdm(enumerate(train_dataloader)):\n",
        "        # get node pairs with labels for loss calculation\n",
        "        compacted_pairs, labels = data.node_pairs_with_labels\n",
        "        node_feature = data.node_features[\"feat\"]\n",
        "        # convert sampled subgraphs to DGL blocks\n",
        "        blocks = data.blocks\n",
        "        # get the embeddings of the input nodes\n",
        "        y = model(blocks, node_feature)\n",
        "        logits = model.predictor(\n",
        "            y[compacted_pairs[0]] * y[compacted_pairs[1]]).squeeze()\n",
        "        # compute loss\n",
        "        loss = func.binary_cross_entropy_with_logits(logits, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch:03d} | Loss {total_loss / (step + 1):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59NSTyUtqdJm",
        "outputId": "74a2e443-fa13-45ee-b11b-f913de3f893e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "38it [00:06,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 000 | Loss 0.550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "38it [00:05,  7.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | Loss 0.449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "38it [00:05,  6.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 002 | Loss 0.444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "datapipe = gb.ItemSampler(test_set, batch_size=256, shuffle=False)\n",
        "# Since we need to use all neghborhoods for evaluation, we set the fanout to -1.\n",
        "datapipe = datapipe.sample_neighbor(graph, [-1, -1])\n",
        "datapipe = datapipe.fetch_feature(feature, node_feature_keys=[\"feat\"])\n",
        "datapipe = datapipe.copy_to(device)\n",
        "eval_dataloader = gb.DataLoader(datapipe, num_workers=0)\n",
        "logits = []\n",
        "labels = []\n",
        "for step, data in tqdm.tqdm(enumerate(eval_dataloader)):\n",
        "    # get node pairs with labels for loss calculation.\n",
        "    compacted_pairs, label = data.node_pairs_with_labels\n",
        "    # the features of sampled nodes\n",
        "    x = data.node_features[\"feat\"]\n",
        "    # forward\n",
        "    y = model(data.blocks, x)\n",
        "    logit = (model.predictor(y[compacted_pairs[0]] * y[compacted_pairs[1]]).squeeze().detach())\n",
        "    logits.append(logit)\n",
        "    labels.append(label)\n",
        "logits = torch.cat(logits, dim=0)\n",
        "labels = torch.cat(labels, dim=0)\n",
        "auc = roc_auc_score(labels.cpu(), logits.cpu())\n",
        "print(\"Link Prediction AUC:\", auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ7oqq2BqdRb",
        "outputId": "aca5582b-84b7-4214-c120-f7cbc3585ad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5it [00:00, 12.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Link Prediction AUC: 0.6908757664922172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GATNE: General Attributed Multiplex Heterogeneous Network Embedding"
      ],
      "metadata": {
        "id": "v3utlaNz7C-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "batch_sze = 64\n",
        "dimensions = 200\n",
        "edge_dim = 10\n",
        "negative_samples = 5\n",
        "att_dim = 20\n",
        "neigh_samples = 10\n",
        "number_workers = 16\n",
        "num_walks = 20\n",
        "window_size = 5\n",
        "eval_type = \"all\"\n",
        "patience = 5"
      ],
      "metadata": {
        "id": "KZat5sB-1Vzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for each line, the data is [edge_type, node, node]\n",
        "def load_training_data(f_name):\n",
        "    print(\"We are loading data from:\", f_name)\n",
        "    edge_data_by_type = dict()\n",
        "    all_nodes = list()\n",
        "    with open(f_name, \"r\") as f:\n",
        "        for line in f:\n",
        "            words = line[:-1].split(\" \")  # line[-1] == '\\n'\n",
        "            if words[0] not in edge_data_by_type:\n",
        "                edge_data_by_type[words[0]] = list()\n",
        "            x, y = words[1], words[2]\n",
        "            edge_data_by_type[words[0]].append((x, y))\n",
        "            all_nodes.append(x)\n",
        "            all_nodes.append(y)\n",
        "    all_nodes = list(set(all_nodes))\n",
        "    print(\"Total training nodes: \" + str(len(all_nodes)))\n",
        "    return edge_data_by_type\n",
        "\n",
        "\n",
        "# for each line, the data is [edge_type, node, node, true_or_false]\n",
        "def load_testing_data(f_name):\n",
        "    print(\"We are loading data from:\", f_name)\n",
        "    true_edge_data_by_type = dict()\n",
        "    false_edge_data_by_type = dict()\n",
        "    all_edges = list()\n",
        "    all_nodes = list()\n",
        "    with open(f_name, \"r\") as f:\n",
        "        for line in f:\n",
        "            words = line[:-1].split(\" \")\n",
        "            x, y = words[1], words[2]\n",
        "            if int(words[3]) == 1:\n",
        "                if words[0] not in true_edge_data_by_type:\n",
        "                    true_edge_data_by_type[words[0]] = list()\n",
        "                true_edge_data_by_type[words[0]].append((x, y))\n",
        "            else:\n",
        "                if words[0] not in false_edge_data_by_type:\n",
        "                    false_edge_data_by_type[words[0]] = list()\n",
        "                false_edge_data_by_type[words[0]].append((x, y))\n",
        "            all_nodes.append(x)\n",
        "            all_nodes.append(y)\n",
        "    all_nodes = list(set(all_nodes))\n",
        "    return true_edge_data_by_type, false_edge_data_by_type\n",
        "\n",
        "\n",
        "def load_node_type(f_name):\n",
        "    print(\"We are loading node type from:\", f_name)\n",
        "    node_type = {}\n",
        "    with open(f_name, \"r\") as f:\n",
        "        for line in f:\n",
        "            items = line.strip().split()\n",
        "            node_type[items[0]] = items[1]\n",
        "    return node_type\n",
        "\n",
        "\n",
        "def generate_pairs_parallel(walks, skip_window=None, layer_id=None):\n",
        "    pairs = []\n",
        "    for walk in walks:\n",
        "        walk = walk.tolist()\n",
        "        for i in range(len(walk)):\n",
        "            for j in range(1, skip_window + 1):\n",
        "                if i - j >= 0:\n",
        "                    pairs.append((walk[i], walk[i - j], layer_id))\n",
        "                if i + j < len(walk):\n",
        "                    pairs.append((walk[i], walk[i + j], layer_id))\n",
        "    return pairs\n",
        "\n",
        "\n",
        "def generate_pairs(all_walks, window_size, num_workers):\n",
        "    # for each node, choose the first neighbor and second neighbor of it to form pairs\n",
        "    # Get all worker processes\n",
        "    start_time = time.time()\n",
        "    print(\"We are generating pairs with {} cores.\".format(num_workers))\n",
        "\n",
        "    # Start all worker processes\n",
        "    pool = multiprocessing.Pool(processes=num_workers)\n",
        "    pairs = []\n",
        "    skip_window = window_size // 2\n",
        "    for layer_id, walks in enumerate(all_walks):\n",
        "        block_num = len(walks) // num_workers\n",
        "        if block_num > 0:\n",
        "            walks_list = [\n",
        "                walks[i * block_num : min((i + 1) * block_num, len(walks))]\n",
        "                for i in range(num_workers)\n",
        "            ]\n",
        "        else:\n",
        "            walks_list = [walks]\n",
        "        tmp_result = pool.map(\n",
        "            partial(\n",
        "                generate_pairs_parallel,\n",
        "                skip_window=skip_window,\n",
        "                layer_id=layer_id,\n",
        "            ),\n",
        "            walks_list,\n",
        "        )\n",
        "        pairs += reduce(lambda x, y: x + y, tmp_result)\n",
        "\n",
        "    pool.close()\n",
        "    end_time = time.time()\n",
        "    print(\"Generate pairs end, use {}s.\".format(end_time - start_time))\n",
        "    return np.array([list(pair) for pair in set(pairs)])\n",
        "\n",
        "\n",
        "def generate_vocab(network_data):\n",
        "    nodes, index2word = [], []\n",
        "    for edge_type in network_data:\n",
        "        node1, node2 = zip(*network_data[edge_type])\n",
        "        index2word = index2word + list(node1) + list(node2)\n",
        "\n",
        "    index2word = list(set(index2word))\n",
        "    vocab = {}\n",
        "    i = 0\n",
        "    for word in index2word:\n",
        "        vocab[word] = i\n",
        "        i = i + 1\n",
        "\n",
        "    for edge_type in network_data:\n",
        "        node1, node2 = zip(*network_data[edge_type])\n",
        "        tmp_nodes = list(set(list(node1) + list(node2)))\n",
        "        tmp_nodes = [vocab[word] for word in tmp_nodes]\n",
        "        nodes.append(tmp_nodes)\n",
        "\n",
        "    return index2word, vocab, nodes\n",
        "\n",
        "\n",
        "def get_score(local_model, edge):\n",
        "    node1, node2 = str(edge[0]), str(edge[1])\n",
        "    try:\n",
        "        vector1 = local_model[node1]\n",
        "        vector2 = local_model[node2]\n",
        "        return np.dot(vector1, vector2) / (\n",
        "            np.linalg.norm(vector1) * np.linalg.norm(vector2)\n",
        "        )\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "\n",
        "def evaluate(model, true_edges, false_edges, num_workers):\n",
        "    true_list = list()\n",
        "    prediction_list = list()\n",
        "    true_num = 0\n",
        "\n",
        "    # Start all worker processes\n",
        "    pool = multiprocessing.Pool(processes=num_workers)\n",
        "    tmp_true_score_list = pool.map(partial(get_score, model), true_edges)\n",
        "    tmp_false_score_list = pool.map(partial(get_score, model), false_edges)\n",
        "    pool.close()\n",
        "\n",
        "    prediction_list += [\n",
        "        tmp_score for tmp_score in tmp_true_score_list if tmp_score is not None\n",
        "    ]\n",
        "    true_num = len(prediction_list)\n",
        "    true_list += [1] * true_num\n",
        "\n",
        "    prediction_list += [\n",
        "        tmp_score for tmp_score in tmp_false_score_list if tmp_score is not None\n",
        "    ]\n",
        "    true_list += [0] * (len(prediction_list) - true_num)\n",
        "\n",
        "    sorted_pred = prediction_list[:]\n",
        "    sorted_pred.sort()\n",
        "    threshold = sorted_pred[-true_num]\n",
        "\n",
        "    y_pred = np.zeros(len(prediction_list), dtype=np.int32)\n",
        "    for i in range(len(prediction_list)):\n",
        "        if prediction_list[i] >= threshold:\n",
        "            y_pred[i] = 1\n",
        "\n",
        "    y_true = np.array(true_list)\n",
        "    y_scores = np.array(prediction_list)\n",
        "    ps, rs, _ = precision_recall_curve(y_true, y_scores)\n",
        "    return (\n",
        "        roc_auc_score(y_true, y_scores),\n",
        "        f1_score(y_true, y_pred),\n",
        "        auc(rs, ps),\n",
        "    )"
      ],
      "metadata": {
        "id": "Lfm106Nr-tmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def walk(args):\n",
        "    walk_length, start, schema = args\n",
        "    # Simulate a random walk starting from start node.\n",
        "    rand = random.Random()\n",
        "\n",
        "    if schema:\n",
        "        schema_items = schema.split('-')\n",
        "        assert schema_items[0] == schema_items[-1]\n",
        "\n",
        "    walk = [start]\n",
        "    while len(walk) < walk_length:\n",
        "        cur = walk[-1]\n",
        "        candidates = []\n",
        "        for node in G[cur]:\n",
        "            if schema == '' or node_type[node] == schema_items[len(walk) % (len(schema_items) - 1)]:\n",
        "                candidates.append(node)\n",
        "        if candidates:\n",
        "            walk.append(rand.choice(candidates))\n",
        "        else:\n",
        "            break\n",
        "    return [str(node) for node in walk]\n",
        "\n",
        "def initializer(init_G, init_node_type):\n",
        "    global G\n",
        "    G = init_G\n",
        "    global node_type\n",
        "    node_type = init_node_type\n",
        "\n",
        "class RWGraph():\n",
        "    def __init__(self, nx_G, node_type_arr=None, num_workers=16):\n",
        "        self.G = nx_G\n",
        "        self.node_type = node_type_arr\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "    def node_list(self, nodes, num_walks):\n",
        "        for loop in range(num_walks):\n",
        "            for node in nodes:\n",
        "                yield node\n",
        "\n",
        "    def simulate_walks(self, num_walks, walk_length, schema=None):\n",
        "        all_walks = []\n",
        "        nodes = list(self.G.keys())\n",
        "        random.shuffle(nodes)\n",
        "\n",
        "        if schema is None:\n",
        "            with multiprocessing.Pool(self.num_workers, initializer=initializer, initargs=(self.G, self.node_type)) as pool:\n",
        "                all_walks = list(pool.imap(walk, ((walk_length, node, '') for node in tqdm(self.node_list(nodes, num_walks))), chunksize=256))\n",
        "        else:\n",
        "            schema_list = schema.split(',')\n",
        "            for schema_iter in schema_list:\n",
        "                with multiprocessing.Pool(self.num_workers, initializer=initializer, initargs=(self.G, self.node_type)) as pool:\n",
        "                    walks = list(pool.imap(walk, ((walk_length, node, schema_iter) for node in tqdm(self.node_list(nodes, num_walks)) if schema_iter.split('-')[0] == self.node_type[node]), chunksize=512))\n",
        "                all_walks.extend(walks)\n",
        "\n",
        "        return all_walks"
      ],
      "metadata": {
        "id": "HwR0J4w5dK6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_graph(network_data, vocab):\n",
        "    \"\"\"Build graph, treat all nodes as the same type\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    network_data: a dict\n",
        "        keys describing the edge types, values representing edges\n",
        "    vocab: a dict\n",
        "        mapping node IDs to node indices\n",
        "    Output\n",
        "    ------\n",
        "    DGLGraph\n",
        "        a heterogenous graph, with one node type and different edge types\n",
        "    \"\"\"\n",
        "    graphs = []\n",
        "\n",
        "    node_type = \"_N\"  # '_N' can be replaced by an arbitrary name\n",
        "    data_dict = dict()\n",
        "    num_nodes_dict = {node_type: len(vocab)}\n",
        "\n",
        "    for edge_type in network_data:\n",
        "        tmp_data = network_data[edge_type]\n",
        "        src = []\n",
        "        dst = []\n",
        "        for edge in tmp_data:\n",
        "            src.extend([vocab[edge[0]], vocab[edge[1]]])\n",
        "            dst.extend([vocab[edge[1]], vocab[edge[0]]])\n",
        "        data_dict[(node_type, edge_type, node_type)] = (src, dst)\n",
        "    graph = dgl.heterograph(data_dict, num_nodes_dict)\n",
        "\n",
        "    return graph"
      ],
      "metadata": {
        "id": "DF6lrezn7ZuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeighborSampler(object):\n",
        "    def __init__(self, g, num_fanouts):\n",
        "        self.g = g\n",
        "        self.num_fanouts = num_fanouts\n",
        "\n",
        "    def sample(self, pairs):\n",
        "        heads, tails, types = zip(*pairs)\n",
        "        seeds, head_invmap = torch.unique(\n",
        "            torch.LongTensor(heads), return_inverse=True\n",
        "        )\n",
        "        blocks = []\n",
        "        for fanout in reversed(self.num_fanouts):\n",
        "            sampled_graph = dgl.sampling.sample_neighbors(self.g, seeds, fanout)\n",
        "            sampled_block = dgl.to_block(sampled_graph, seeds)\n",
        "            seeds = sampled_block.srcdata[dgl.NID]\n",
        "            blocks.insert(0, sampled_block)\n",
        "        return (\n",
        "            blocks,\n",
        "            torch.LongTensor(head_invmap),\n",
        "            torch.LongTensor(tails),\n",
        "            torch.LongTensor(types),\n",
        "        )"
      ],
      "metadata": {
        "id": "WVPZCFlY8NHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DGLGATNE(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_nodes,\n",
        "        embedding_size,\n",
        "        embedding_u_size,\n",
        "        edge_types,\n",
        "        edge_type_count,\n",
        "        dim_a,\n",
        "    ):\n",
        "        super(DGLGATNE, self).__init__()\n",
        "        self.num_nodes = num_nodes\n",
        "        self.embedding_size = embedding_size\n",
        "        self.embedding_u_size = embedding_u_size\n",
        "        self.edge_types = edge_types\n",
        "        self.edge_type_count = edge_type_count\n",
        "        self.dim_a = dim_a\n",
        "\n",
        "        self.node_embeddings = nn.parameter.Parameter(\n",
        "            torch.FloatTensor(num_nodes, embedding_size)\n",
        "        )\n",
        "        self.node_type_embeddings = nn.parameter.Parameter(\n",
        "            torch.FloatTensor(num_nodes, edge_type_count, embedding_u_size)\n",
        "        )\n",
        "        self.trans_weights = nn.parameter.Parameter(\n",
        "            torch.FloatTensor(edge_type_count, embedding_u_size, embedding_size)\n",
        "        )\n",
        "        self.trans_weights_s1 = nn.parameter.Parameter(\n",
        "            torch.FloatTensor(edge_type_count, embedding_u_size, dim_a)\n",
        "        )\n",
        "        self.trans_weights_s2 = nn.parameter.Parameter(\n",
        "            torch.FloatTensor(edge_type_count, dim_a, 1)\n",
        "        )\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.node_embeddings.data.uniform_(-1.0, 1.0)\n",
        "        self.node_type_embeddings.data.uniform_(-1.0, 1.0)\n",
        "        self.trans_weights.data.normal_(\n",
        "            std=1.0 / math.sqrt(self.embedding_size)\n",
        "        )\n",
        "        self.trans_weights_s1.data.normal_(\n",
        "            std=1.0 / math.sqrt(self.embedding_size)\n",
        "        )\n",
        "        self.trans_weights_s2.data.normal_(\n",
        "            std=1.0 / math.sqrt(self.embedding_size)\n",
        "        )\n",
        "\n",
        "    # embs: [batch_size, embedding_size]\n",
        "    def forward(self, block):\n",
        "        input_nodes = block.srcdata[dgl.NID]\n",
        "        output_nodes = block.dstdata[dgl.NID]\n",
        "        batch_size = block.number_of_dst_nodes()\n",
        "        node_embed = self.node_embeddings\n",
        "        node_type_embed = []\n",
        "\n",
        "        with block.local_scope():\n",
        "            for i in range(self.edge_type_count):\n",
        "                edge_type = self.edge_types[i]\n",
        "                block.srcdata[edge_type] = self.node_type_embeddings[\n",
        "                    input_nodes, i\n",
        "                ]\n",
        "                block.dstdata[edge_type] = self.node_type_embeddings[\n",
        "                    output_nodes, i\n",
        "                ]\n",
        "                block.update_all(\n",
        "                    fn.copy_u(edge_type, \"m\"),\n",
        "                    fn.sum(\"m\", edge_type),\n",
        "                    etype=edge_type,\n",
        "                )\n",
        "                node_type_embed.append(block.dstdata[edge_type])\n",
        "\n",
        "            node_type_embed = torch.stack(node_type_embed, 1)\n",
        "            tmp_node_type_embed = node_type_embed.unsqueeze(2).view(\n",
        "                -1, 1, self.embedding_u_size\n",
        "            )\n",
        "            trans_w = (\n",
        "                self.trans_weights.unsqueeze(0)\n",
        "                .repeat(batch_size, 1, 1, 1)\n",
        "                .view(-1, self.embedding_u_size, self.embedding_size)\n",
        "            )\n",
        "            trans_w_s1 = (\n",
        "                self.trans_weights_s1.unsqueeze(0)\n",
        "                .repeat(batch_size, 1, 1, 1)\n",
        "                .view(-1, self.embedding_u_size, self.dim_a)\n",
        "            )\n",
        "            trans_w_s2 = (\n",
        "                self.trans_weights_s2.unsqueeze(0)\n",
        "                .repeat(batch_size, 1, 1, 1)\n",
        "                .view(-1, self.dim_a, 1)\n",
        "            )\n",
        "\n",
        "            attention = (\n",
        "                func.softmax(\n",
        "                    torch.matmul(\n",
        "                        torch.tanh(\n",
        "                            torch.matmul(tmp_node_type_embed, trans_w_s1)\n",
        "                        ),\n",
        "                        trans_w_s2,\n",
        "                    )\n",
        "                    .squeeze(2)\n",
        "                    .view(-1, self.edge_type_count),\n",
        "                    dim=1,\n",
        "                )\n",
        "                .unsqueeze(1)\n",
        "                .repeat(1, self.edge_type_count, 1)\n",
        "            )\n",
        "\n",
        "            node_type_embed = torch.matmul(attention, node_type_embed).view(\n",
        "                -1, 1, self.embedding_u_size\n",
        "            )\n",
        "            node_embed = node_embed[output_nodes].unsqueeze(1).repeat(\n",
        "                1, self.edge_type_count, 1\n",
        "            ) + torch.matmul(node_type_embed, trans_w).view(\n",
        "                -1, self.edge_type_count, self.embedding_size\n",
        "            )\n",
        "            last_node_embed = func.normalize(node_embed, dim=2)\n",
        "\n",
        "            return (\n",
        "                last_node_embed  # [batch_size, edge_type_count, embedding_size]\n",
        "            )"
      ],
      "metadata": {
        "id": "qr_oY38n7Z_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NSLoss(nn.Module):\n",
        "    def __init__(self, num_nodes, num_sampled, embedding_size):\n",
        "        super(NSLoss, self).__init__()\n",
        "        self.num_nodes = num_nodes\n",
        "        self.num_sampled = num_sampled\n",
        "        self.embedding_size = embedding_size\n",
        "        self.weights = nn.parameter.Parameter(torch.FloatTensor(num_nodes, embedding_size))\n",
        "        # [ (log(i+2) - log(i+1)) / log(num_nodes + 1)]\n",
        "        self.sample_weights = func.normalize(\n",
        "            torch.Tensor(\n",
        "                [\n",
        "                    (math.log(k + 2) - math.log(k + 1))\n",
        "                    / math.log(num_nodes + 1)\n",
        "                    for k in range(num_nodes)\n",
        "                ]\n",
        "            ),\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.weights.data.normal_(std=1.0 / math.sqrt(self.embedding_size))\n",
        "\n",
        "    def forward(self, input, embs, label):\n",
        "        n = input.shape[0]\n",
        "        log_target = torch.log(\n",
        "            torch.sigmoid(torch.sum(torch.mul(embs, self.weights[label]), 1))\n",
        "        )\n",
        "        negs = torch.multinomial(\n",
        "            self.sample_weights, self.num_sampled * n, replacement=True\n",
        "        ).view(n, self.num_sampled)\n",
        "        noise = torch.neg(self.weights[negs])\n",
        "        sum_log_sampled = torch.sum(\n",
        "            torch.log(torch.sigmoid(torch.bmm(noise, embs.unsqueeze(2)))), 1\n",
        "        ).squeeze()\n",
        "\n",
        "        loss = log_target + sum_log_sampled\n",
        "        return -loss.sum() / n"
      ],
      "metadata": {
        "id": "Fm45fqpD8y7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(network_data):\n",
        "    index2word, vocab, type_nodes = generate_vocab(network_data)\n",
        "    edge_types = list(network_data.keys())\n",
        "    num_nodes = len(index2word)\n",
        "    edge_type_count = len(edge_types)\n",
        "    embedding_size = dimensions\n",
        "    embedding_u_size = edge_dim\n",
        "    u_num = edge_type_count\n",
        "    num_sampled = negative_samples\n",
        "    dim_a = att_dim\n",
        "    att_head = 1\n",
        "    epochs = num_epochs\n",
        "    batch_size = batch_sze\n",
        "    neighbor_samples = neigh_samples\n",
        "    num_workers = number_workers\n",
        "\n",
        "    device = torch.device(\n",
        "        \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    )\n",
        "\n",
        "    g = get_graph(network_data, vocab)\n",
        "    all_walks = []\n",
        "    for i in range(edge_type_count):\n",
        "        nodes = torch.LongTensor(type_nodes[i] * num_walks)\n",
        "        traces, types = dgl.sampling.random_walk(\n",
        "            g, nodes, metapath=[edge_types[i]] * (neighbor_samples - 1)\n",
        "        )\n",
        "        all_walks.append(traces)\n",
        "\n",
        "    train_pairs = generate_pairs(all_walks, window_size, num_workers)\n",
        "    neighbor_sampler = NeighborSampler(g, [neighbor_samples])\n",
        "    train_dataloader = torch.utils.data.DataLoader(\n",
        "        train_pairs,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=neighbor_sampler.sample,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    model = DGLGATNE(\n",
        "        num_nodes,\n",
        "        embedding_size,\n",
        "        embedding_u_size,\n",
        "        edge_types,\n",
        "        edge_type_count,\n",
        "        dim_a,\n",
        "    )\n",
        "    nsloss = NSLoss(num_nodes, num_sampled, embedding_size)\n",
        "    model.to(device)\n",
        "    nsloss.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(\n",
        "        [{\"params\": model.parameters()}, {\"params\": nsloss.parameters()}],\n",
        "        lr=1e-3,\n",
        "    )\n",
        "\n",
        "    best_score = 0\n",
        "    patience = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        np.random.shuffle(train_pairs)\n",
        "\n",
        "        data_iter = tqdm(\n",
        "            train_dataloader,\n",
        "            desc=\"epoch %d\" % (epoch),\n",
        "            total=(len(train_pairs) + (batch_size - 1)) // batch_size,\n",
        "        )\n",
        "        avg_loss = 0.0\n",
        "\n",
        "        for i, (block, head_invmap, tails, block_types) in enumerate(data_iter):\n",
        "            optimizer.zero_grad()\n",
        "            # embs: [batch_size, edge_type_count, embedding_size]\n",
        "            block_types = block_types.to(device)\n",
        "            embs = model(block[0].to(device))[head_invmap]\n",
        "            embs = embs.gather(\n",
        "                1,\n",
        "                block_types.view(-1, 1, 1).expand(\n",
        "                    embs.shape[0], 1, embs.shape[2]\n",
        "                ),\n",
        "            )[:, 0]\n",
        "            loss = nsloss(\n",
        "                block[0].dstdata[dgl.NID][head_invmap].to(device),\n",
        "                embs,\n",
        "                tails.to(device),\n",
        "            )\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            avg_loss += loss.item()\n",
        "\n",
        "            post_fix = {\n",
        "                \"epoch\": epoch,\n",
        "                \"iter\": i,\n",
        "                \"avg_loss\": avg_loss / (i + 1),\n",
        "                \"loss\": loss.item(),\n",
        "            }\n",
        "            data_iter.set_postfix(post_fix)\n",
        "\n",
        "        model.eval()\n",
        "        # {'1': {}, '2': {}}\n",
        "        final_model = dict(\n",
        "            zip(edge_types, [dict() for _ in range(edge_type_count)])\n",
        "        )\n",
        "        for i in range(num_nodes):\n",
        "            train_inputs = (\n",
        "                torch.tensor([i for _ in range(edge_type_count)])\n",
        "                .unsqueeze(1)\n",
        "                .to(device)\n",
        "            )  # [i, i]\n",
        "            train_types = (\n",
        "                torch.tensor(list(range(edge_type_count)))\n",
        "                .unsqueeze(1)\n",
        "                .to(device)\n",
        "            )  # [0, 1]\n",
        "            pairs = torch.cat(\n",
        "                (train_inputs, train_inputs, train_types), dim=1\n",
        "            )  # (2, 3)\n",
        "            (\n",
        "                train_blocks,\n",
        "                train_invmap,\n",
        "                fake_tails,\n",
        "                train_types,\n",
        "            ) = neighbor_sampler.sample(pairs)\n",
        "\n",
        "            node_emb = model(train_blocks[0].to(device))[train_invmap]\n",
        "            node_emb = node_emb.gather(\n",
        "                1,\n",
        "                train_types.to(device)\n",
        "                .view(-1, 1, 1)\n",
        "                .expand(node_emb.shape[0], 1, node_emb.shape[2]),\n",
        "            )[:, 0]\n",
        "\n",
        "            for j in range(edge_type_count):\n",
        "                final_model[edge_types[j]][index2word[i]] = (\n",
        "                    node_emb[j].cpu().detach().numpy()\n",
        "                )\n",
        "\n",
        "        valid_aucs, valid_f1s, valid_prs = [], [], []\n",
        "        test_aucs, test_f1s, test_prs = [], [], []\n",
        "        for i in range(edge_type_count):\n",
        "            if eval_type == \"all\" or edge_types[i] in eval_type.split(\n",
        "                \",\"\n",
        "            ):\n",
        "                tmp_auc, tmp_f1, tmp_pr = evaluate(\n",
        "                    final_model[edge_types[i]],\n",
        "                    valid_true_data_by_edge[edge_types[i]],\n",
        "                    valid_false_data_by_edge[edge_types[i]],\n",
        "                    num_workers,\n",
        "                )\n",
        "                valid_aucs.append(tmp_auc)\n",
        "                valid_f1s.append(tmp_f1)\n",
        "                valid_prs.append(tmp_pr)\n",
        "\n",
        "                tmp_auc, tmp_f1, tmp_pr = evaluate(\n",
        "                    final_model[edge_types[i]],\n",
        "                    testing_true_data_by_edge[edge_types[i]],\n",
        "                    testing_false_data_by_edge[edge_types[i]],\n",
        "                    num_workers,\n",
        "                )\n",
        "                test_aucs.append(tmp_auc)\n",
        "                test_f1s.append(tmp_f1)\n",
        "                test_prs.append(tmp_pr)\n",
        "        print(\"valid auc:\", np.mean(valid_aucs))\n",
        "        print(\"valid pr:\", np.mean(valid_prs))\n",
        "        print(\"valid f1:\", np.mean(valid_f1s))\n",
        "\n",
        "        average_auc = np.mean(test_aucs)\n",
        "        average_f1 = np.mean(test_f1s)\n",
        "        average_pr = np.mean(test_prs)\n",
        "\n",
        "        cur_score = np.mean(valid_aucs)\n",
        "        if cur_score > best_score:\n",
        "            best_score = cur_score\n",
        "            patience = 0\n",
        "        else:\n",
        "            patience += 1\n",
        "            if patience > patience:\n",
        "                print(\"Early Stopping\")\n",
        "                break\n",
        "    return average_auc, average_f1, average_pr"
      ],
      "metadata": {
        "id": "sJH1Futq8NXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "working_dir = '/content/drive/MyDrive/DataSets'\n",
        "os.chdir(working_dir)"
      ],
      "metadata": {
        "id": "JS07oFInwarH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbEeWtP7xNqo",
        "outputId": "3ebdf72a-e752-41ee-8055-90f26fb63e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amazon\t     arff_files    fashion\t handwritten_text  maps\t\t      secom\t    youtube\n",
            "animals      dogs-vs-cats  forest_fires  jena_climate\t   Multi_Digit_Mnist  support2.csv\n",
            "anomaly.csv  employee\t   GE.csv\t LaEterna\t   Sandstone\t      walmart\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"youtube\"\n",
        "training_data_by_type = load_training_data(file_name + \"/train.txt\")\n",
        "valid_true_data_by_edge, valid_false_data_by_edge = load_testing_data(file_name + \"/valid.txt\")\n",
        "testing_true_data_by_edge, testing_false_data_by_edge = load_testing_data(file_name + \"/test.txt\")\n",
        "start = time.time()\n",
        "average_auc, average_f1, average_pr = train_model(training_data_by_type)\n",
        "end = time.time()\n",
        "print(\"Overall ROC-AUC:\", average_auc)\n",
        "print(\"Overall PR-AUC\", average_pr)\n",
        "print(\"Overall F1:\", average_f1)\n",
        "print(\"Training Time\", end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNjxwrCt7aHo",
        "outputId": "61c8974b-2891-47e8-d89c-5e7fd101945c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are loading data from: youtube/train.txt\n",
            "Total training nodes: 2000\n",
            "We are loading data from: youtube/valid.txt\n",
            "We are loading data from: youtube/test.txt\n",
            "We are generating pairs with 16 cores.\n",
            "Generate pairs end, use 10.164549827575684s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "epoch 0: 100%|██████████| 44828/44828 [34:02<00:00, 21.95it/s, epoch=0, iter=44827, avg_loss=1.66, loss=1.35]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid auc: 0.7875263089050607\n",
            "valid pr: 0.7585290158824863\n",
            "valid f1: 0.7179444187411399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\repoch 1:   0%|          | 0/44828 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "epoch 1: 100%|██████████| 44828/44828 [35:52<00:00, 20.82it/s, epoch=1, iter=44827, avg_loss=1.59, loss=1.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid auc: 0.8097461411140277\n",
            "valid pr: 0.7761392534689376\n",
            "valid f1: 0.7362409908231483\n",
            "Overall ROC-AUC: 0.8057477127273025\n",
            "Overall PR-AUC 0.7732871171073578\n",
            "Overall F1: 0.7320678050860484\n",
            "Training Time 4356.247588157654\n"
          ]
        }
      ]
    }
  ]
}