{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ariahosseini/DeepML/blob/main/023_ALIGNN_Proj_TwentyThree_ForceField_Si.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mBEu5u74u8A",
        "outputId": "9397bae7-d9c3-473b-8247-c1b4f5ba3bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TGGMrH211yd"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIpCD6oo149B"
      },
      "outputs": [],
      "source": [
        "working_dir = \"Alignn-Run-00-ForceField-Si\"\n",
        "os.mkdir(working_dir)\n",
        "os.chdir(working_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJNMmk4m1xIJ"
      },
      "source": [
        "\n",
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u1MnIqjbcVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37315af3-091d-4d87-980c-b2e27ff2c356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m976.2/976.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.7/807.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for paginate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/211.6 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.0/161.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -U jarvis-tools --quiet\n",
        "!pip install xformers==v0.0.22 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80vKAOOH1SeK",
        "outputId": "39b3f89f-bfe4-4f1e-ac3e-ebc563a84298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'jarvis_leaderboard'...\n",
            "remote: Enumerating objects: 63478, done.\u001b[K\n",
            "remote: Counting objects: 100% (3496/3496), done.\u001b[K\n",
            "remote: Compressing objects: 100% (306/306), done.\u001b[K\n",
            "remote: Total 63478 (delta 1711), reused 3446 (delta 1689), pack-reused 59982\u001b[K\n",
            "Receiving objects: 100% (63478/63478), 392.16 MiB | 14.18 MiB/s, done.\n",
            "Resolving deltas: 100% (33128/33128), done.\n",
            "Updating files: 100% (3655/3655), done.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "CPU times: user 748 ms, sys: 82.3 ms, total: 830 ms\n",
            "Wall time: 55.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if not os.path.exists('jarvis_leaderboard'):\n",
        "  !git clone https://github.com/usnistgov/jarvis_leaderboard.git\n",
        "os.chdir('jarvis_leaderboard')\n",
        "!pip install -q -e .\n",
        "os.chdir('../')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VFPM30N22lo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "718079b0-fe01-4e61-86cd-5ea771054d1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for phonopy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q dgl==1.0.1+cu117 -f https://data.dgl.ai/wheels/cu117/repo.html\n",
        "!pip install -q alignn phonopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOPky5CCQ1rH",
        "outputId": "bc2f80a7-4ab2-447b-dd4d-8707a3716149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://gitlab.com/ase/ase.git@master\n",
            "  Cloning https://gitlab.com/ase/ase.git (to revision master) to /tmp/pip-req-build-uvwuqqj5\n",
            "  Running command git clone --filter=blob:none --quiet https://gitlab.com/ase/ase.git /tmp/pip-req-build-uvwuqqj5\n",
            "  Resolved https://gitlab.com/ase/ase.git to commit 28a0a1f1988e3f06c2c887139103c573b74a066c\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from ase==3.23.0b1) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ase==3.23.0b1) (1.11.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.10/dist-packages (from ase==3.23.0b1) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase==3.23.0b1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase==3.23.0b1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase==3.23.0b1) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase==3.23.0b1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase==3.23.0b1) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase==3.23.0b1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase==3.23.0b1) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->ase==3.23.0b1) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.4->ase==3.23.0b1) (1.16.0)\n",
            "Building wheels for collected packages: ase\n",
            "  Building wheel for ase (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ase: filename=ase-3.23.0b1-py3-none-any.whl size=2699941 sha256=89cbd2b9d9f5eb832b5d3f1ed7d18fa8808bb26a95a233b30866988772c8aeff\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i4_dokc9/wheels/01/fc/60/e6134958a4ba6921161034c849be512a068712df0013719724\n",
            "Successfully built ase\n",
            "Installing collected packages: ase\n",
            "  Attempting uninstall: ase\n",
            "    Found existing installation: ase 3.22.1\n",
            "    Uninstalling ase-3.22.1:\n",
            "      Successfully uninstalled ase-3.22.1\n",
            "Successfully installed ase-3.23.0b1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade git+https://gitlab.com/ase/ase.git@master"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwbW3rjp1yC6"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEn-RFCL3RlT",
        "outputId": "9eb68057-6034-4204-e7f3-a377280a4686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-31 16:40:33--  https://gist.githubusercontent.com/knc6/eb04b911cd5428bb2ac79b7622c0da26/raw/ffdcbbccc9488d536890a3a5ffd69313a2a458bd/config_mlearn_cu.json\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2034 (2.0K) [text/plain]\n",
            "Saving to: ‘config_mlearn_cu.json’\n",
            "\n",
            "\rconfig_mlearn_cu.js   0%[                    ]       0  --.-KB/s               \rconfig_mlearn_cu.js 100%[===================>]   1.99K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-31 16:40:33 (35.0 MB/s) - ‘config_mlearn_cu.json’ saved [2034/2034]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://gist.githubusercontent.com/knc6/eb04b911cd5428bb2ac79b7622c0da26/raw/ffdcbbccc9488d536890a3a5ffd69313a2a458bd/config_mlearn_cu.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5CsocF53Tv2",
        "outputId": "287a0650-01de-4f05-d1b5-4b790819bb90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-31 16:40:33--  https://figshare.com/ndownloader/files/40357663\n",
            "Resolving figshare.com (figshare.com)... 52.214.199.34, 52.210.98.158, 2a05:d018:1f4:d003:5b82:9bb9:fa8:ed62, ...\n",
            "Connecting to figshare.com (figshare.com)|52.214.199.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/40357663/mlearn.json.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20240331/eu-west-1/s3/aws4_request&X-Amz-Date=20240331T164033Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=4d2859c21db627e9aa87ffd5ec46aecee42233cd310a8f4acac73f5febfa1381 [following]\n",
            "--2024-03-31 16:40:33--  https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/40357663/mlearn.json.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20240331/eu-west-1/s3/aws4_request&X-Amz-Date=20240331T164033Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=4d2859c21db627e9aa87ffd5ec46aecee42233cd310a8f4acac73f5febfa1381\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.92.34.88, 52.92.0.248, 52.218.105.162, ...\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.92.34.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2542319 (2.4M) [application/zip]\n",
            "Saving to: ‘mlearn.json.zip’\n",
            "\n",
            "mlearn.json.zip     100%[===================>]   2.42M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-03-31 16:40:34 (18.8 MB/s) - ‘mlearn.json.zip’ saved [2542319/2542319]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://figshare.com/ndownloader/files/40357663 -O mlearn.json.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVt3laVA3i4c"
      },
      "source": [
        "## Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbQEA1an3jZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16755418-b6ad-4e21-9978-87f67af951bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ],
      "source": [
        "# libs\n",
        "import sys, glob, json, zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from subprocess import Popen, PIPE, call\n",
        "# sklearn\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "# torch\n",
        "import torch\n",
        "# jarvis\n",
        "from jarvis.core.atoms import Atoms, ase_to_atoms\n",
        "from jarvis.db.jsonutils import loadjson, dumpjson\n",
        "from jarvis.db.figshare import data, get_jid_data\n",
        "# alignn\n",
        "from alignn.ff.ff import (phonons, ForceField, AlignnAtomwiseCalculator,\n",
        "                          default_path, wt10_path,fd_path, alignnff_fmult)\n",
        "# ase\n",
        "from ase import units, Atom, Atoms as AseAtoms\n",
        "from ase.build import bulk\n",
        "from ase.stress import full_3x3_to_voigt_6_stress, voigt_6_to_full_3x3_stress\n",
        "from ase.optimize import QuasiNewton, fire, gpmin, mdmin, LBFGS, BFGS, FIRE\n",
        "from ase.io.trajectory import Trajectory, TrajectoryReader\n",
        "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
        "from ase.md.verlet import VelocityVerlet\n",
        "from ase.md.nvtberendsen import NVTBerendsen\n",
        "from ase.md.npt import NPT\n",
        "# vis\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbydfTFGIYgp"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOEXZ5w33d7A"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn140mw-3dF3",
        "outputId": "76a35a1c-5076-4cbe-bd85-beab055064d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jarvis_leaderboard/jarvis_leaderboard/benchmarks/AI/MLFF/mlearn_Si_energy.json.zip\n",
            "CPU times: user 638 ms, sys: 32.2 ms, total: 670 ms\n",
            "Wall time: 679 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "run_dir='./'\n",
        "# elements = [\"Cu\",\"Mo\",\"Ni\",\"Ge\",\"Mo\",\"Li\"]\n",
        "elements = [\"Si\"]\n",
        "mlearn = json.loads(zipfile.ZipFile(\"mlearn.json.zip\").read(\"mlearn.json\"))\n",
        "example_config = loadjson(\"config_mlearn_cu.json\")\n",
        "mem = []\n",
        "for element in elements:\n",
        "    os.chdir(run_dir)\n",
        "    dir_name = \"alff2_wt_1_determ\" + element\n",
        "    cmd = 'rm -rf ' + dir_name\n",
        "    os.system(cmd)\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.makedirs(dir_name)\n",
        "    benchmark_energies = (\n",
        "        \"jarvis_leaderboard/jarvis_leaderboard/benchmarks/AI/MLFF/mlearn_\"\n",
        "        + element\n",
        "        + \"_energy.json.zip\"\n",
        "    )\n",
        "    print(benchmark_energies)\n",
        "    temp_energies = benchmark_energies.split(\"/\")[-1].split(\".zip\")[0]\n",
        "    energies = json.loads(zipfile.ZipFile(benchmark_energies).read(temp_energies))\n",
        "    train_ids = list(energies[\"train\"].keys())\n",
        "    test_ids = list(energies[\"test\"].keys())\n",
        "    example_config[\"n_train\"] = len(train_ids)\n",
        "    example_config[\"n_val\"] = len(test_ids)\n",
        "    example_config[\"n_test\"] = len(test_ids)\n",
        "    example_config[\"model\"][\"graphwise_weight\"] = 1\n",
        "    example_config[\"model\"][\"gradwise_weight\"] = 1\n",
        "    example_config[\"model\"][\"add_reverse_forces\"] = True\n",
        "    example_config[\"model\"][\"lg_on_fly\"] = True\n",
        "    example_config[\"model\"][\"alignn_layers\"] = 4\n",
        "    example_config[\"epochs\"] = 200\n",
        "    example_config[\"batch_size\"] = 32\n",
        "    example_config[\"keep_data_order\"] = True\n",
        "    config_name = dir_name + \"/config_\" + element + \".json\"\n",
        "    dumpjson(data=example_config, filename=config_name)\n",
        "    train_energies = []\n",
        "    train_forces = []\n",
        "    train_stresses = []\n",
        "    train_structures = []\n",
        "    for i in mlearn:\n",
        "        if i[\"jid\"] in train_ids:\n",
        "            train_energies.append(i[\"energy\"])\n",
        "            train_forces.append(i[\"forces\"])\n",
        "            train_stresses.append(i[\"stresses\"])\n",
        "            atoms = Atoms.from_dict(i[\"atoms\"])\n",
        "            info = {}\n",
        "            info[\"jid\"] = i[\"jid\"]\n",
        "            info[\"atoms\"] = i[\"atoms\"]\n",
        "            # alignn uses intensive/energy over atom quanitity\n",
        "            info[\"total_energy\"] = i[\"energy\"] / atoms.num_atoms\n",
        "            info[\"forces\"] = i[\"forces\"]\n",
        "            info[\"stresses\"] = i[\"stresses\"]\n",
        "            mem.append(info)\n",
        "    # val same as test\n",
        "    test_energies = []\n",
        "    test_forces = []\n",
        "    test_stresses = []\n",
        "    test_structures = []\n",
        "    for i in mlearn:\n",
        "        if i[\"jid\"] in test_ids:\n",
        "            test_energies.append(i[\"energy\"])\n",
        "            test_forces.append(i[\"forces\"])\n",
        "            test_stresses.append(i[\"stresses\"])\n",
        "            atoms = Atoms.from_dict(i[\"atoms\"])\n",
        "            info = {}\n",
        "            info[\"jid\"] = i[\"jid\"]\n",
        "            info[\"atoms\"] = i[\"atoms\"]\n",
        "            info[\"total_energy\"] = i[\"energy\"] / atoms.num_atoms\n",
        "            info[\"forces\"] = i[\"forces\"]\n",
        "            info[\"stresses\"] = i[\"stresses\"]\n",
        "            mem.append(info)\n",
        "    test_energies = []\n",
        "    test_forces = []\n",
        "    test_stresses = []\n",
        "    test_structures = []\n",
        "    for i in mlearn:\n",
        "        if i[\"jid\"] in test_ids:\n",
        "            test_energies.append(i[\"energy\"])\n",
        "            test_forces.append(i[\"forces\"])\n",
        "            test_stresses.append(i[\"stresses\"])\n",
        "            atoms = Atoms.from_dict(i[\"atoms\"])\n",
        "            # test_structures.append(atoms.pymatgen_converter())\n",
        "            info = {}\n",
        "            info[\"jid\"] = i[\"jid\"]\n",
        "            info[\"atoms\"] = i[\"atoms\"]\n",
        "            info[\"total_energy\"] = i[\"energy\"] / atoms.num_atoms\n",
        "            info[\"forces\"] = i[\"forces\"]\n",
        "            info[\"stresses\"] = i[\"stresses\"]\n",
        "            info[\"store_outputs\"] = True\n",
        "            mem.append(info)\n",
        "    filename = dir_name + \"/id_prop.json\"\n",
        "    dumpjson(data=mem, filename=filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjCnYlA4hRzv",
        "outputId": "2695a99d-57ce-408f-9743-28d6b8f02101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_alignn.py --root_dir alff2_wt_1_determSi --config alff2_wt_1_determSi/config_Si.json --output_dir alff2_wt_1_determSi\n"
          ]
        }
      ],
      "source": [
        "cmd = (\"train_alignn.py --root_dir \" + dir_name + \" --config \" + config_name + \" --output_dir \" + dir_name)\n",
        "print(cmd)\n",
        "# os.system(cmd)\n",
        "# subprocess.call(cmd, stdout=PIPE,shell=True)\n",
        "# output = Popen(cmd, stdout=PIPE, shell=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo4kOCJX3_de",
        "outputId": "0a4a6119-bd6e-497b-c83b-e085f99560eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "len dataset 264\n",
            "MAX val: -4.5603584190625\n",
            "MIN val: -5.4253234771875\n",
            "MAD: 0.2771504487888568\n",
            "Baseline MAE: 0.2861611033805039\n",
            "data range -4.56655198359375 -5.4253234771875\n",
            "Converting to graphs!\n",
            "214it [00:19, 11.21it/s]\n",
            "df        target  ...                                      atomwise_grad\n",
            "0   -4.690437  ...  [[-2.98187262, 0.6069187, 3.48143607], [1.0296...\n",
            "1   -4.706461  ...  [[0.99880939, -0.7519403, -0.01394214], [0.773...\n",
            "2   -4.779050  ...  [[-2.18603536, -1.21455866, -0.02436766], [-0....\n",
            "3   -4.668139  ...  [[-0.05824923, 0.28047602, -0.5598585], [2.230...\n",
            "4   -4.719795  ...  [[0.05038001, 0.06106767, -0.11780916], [0.769...\n",
            "..        ...  ...                                                ...\n",
            "209 -5.384299  ...  [[0.73816684, 0.0, -0.0], [0.73816684, -0.0, 0...\n",
            "210 -5.331588  ...  [[1.1447622, -0.0, 0.0], [1.1447622, 0.0, 0.0]...\n",
            "211 -5.255275  ...  [[1.59809444, 0.0, 0.0], [1.59809444, -0.0, 0....\n",
            "212 -5.153435  ...  [[2.1379772, 0.0, 0.0], [2.1379772, -0.0, 0.0]...\n",
            "213 -5.425323  ...  [[0.0, -0.0, 0.0], [0.0, -0.0, 0.0], [0.0, -0....\n",
            "\n",
            "[214 rows x 4 columns]\n",
            "warning: could not load CGCNN features for 103\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 101\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 102\n",
            "Setting it to max atomic number available here, 103\n",
            "building line graphs\n",
            "100% 214/214 [00:01<00:00, 138.98it/s]\n",
            "data range -4.5603584190625 -5.3883693821875\n",
            "Converting to graphs!\n",
            "25it [00:02, 12.35it/s]\n",
            "df       target  ...                                      atomwise_grad\n",
            "0  -4.724250  ...  [[-0.05394626, 0.05113266, 0.18121306], [0.266...\n",
            "1  -4.694789  ...  [[3.30282396, -1.05803218, 0.22431344], [0.305...\n",
            "2  -4.623644  ...  [[0.40295226, 0.92358416, 0.05267631], [1.9204...\n",
            "3  -4.702236  ...  [[-0.97261346, -0.16676844, -1.20511235], [-0....\n",
            "4  -4.673232  ...  [[-0.91219868, 0.41237799, 1.15301928], [0.158...\n",
            "5  -5.313537  ...  [[-0.05608486, 0.22205158, 0.76935161], [-0.01...\n",
            "6  -5.312574  ...  [[-0.99485517, 0.48253845, -0.19532324], [0.46...\n",
            "7  -5.131058  ...  [[0.00684328, 0.01878958, 0.01564654], [-0.008...\n",
            "8  -5.058825  ...  [[-0.00309968, -0.00311653, -0.0031407], [-0.0...\n",
            "9  -5.295922  ...  [[0.10803849, 1.5201289, -1.43824908], [-1.608...\n",
            "10 -5.294306  ...  [[0.91448851, -1.09437286, -0.00344895], [1.61...\n",
            "11 -5.245141  ...  [[0.02527078, -0.62806301, -0.2229749], [-0.75...\n",
            "12 -5.214164  ...  [[0.00995144, -1.16831526, 1.45085777], [1.016...\n",
            "13 -5.388369  ...  [[-0.20717037, -0.37315105, -0.62300221], [0.7...\n",
            "14 -5.387673  ...  [[-0.88379159, -0.87350648, 1.62210639], [-0.2...\n",
            "15 -4.669254  ...  [[1.9104226, 2.27558322, 1.53211371], [-0.1918...\n",
            "16 -4.671328  ...  [[0.47738134, 1.44069956, 0.33205219], [0.5412...\n",
            "17 -4.612647  ...  [[-0.61196745, 0.20739327, 2.37155302], [1.290...\n",
            "18 -4.560358  ...  [[1.58924009, -1.32676264, 1.70069606], [0.146...\n",
            "19 -5.386575  ...  [[-0.0, -0.0, 0.0], [-0.0, -0.0, 0.0], [0.0, -...\n",
            "20 -5.386575  ...  [[-0.0, -0.0, -0.0], [-0.0, 0.0, 0.0], [-0.0, ...\n",
            "21 -5.386575  ...  [[0.0, -0.0, 0.0], [-0.0, -0.0, -0.0], [0.0, 0...\n",
            "22 -5.331588  ...  [[0.0, -0.0, -1.14476094], [-0.0, -0.0, -1.144...\n",
            "23 -5.331588  ...  [[-0.0, -1.14476111, -0.0], [-0.0, -1.14476111...\n",
            "24 -5.331588  ...  [[-1.14476008, 0.0, -0.0], [-1.14476008, 0.0, ...\n",
            "\n",
            "[25 rows x 4 columns]\n",
            "building line graphs\n",
            "100% 25/25 [00:00<00:00, 148.70it/s]\n",
            "data range -4.5603584190625 -5.3883693821875\n",
            "Converting to graphs!\n",
            "25it [00:02, 11.76it/s]\n",
            "df       target  ...                                      atomwise_grad\n",
            "0  -4.724250  ...  [[-0.05394626, 0.05113266, 0.18121306], [0.266...\n",
            "1  -4.694789  ...  [[3.30282396, -1.05803218, 0.22431344], [0.305...\n",
            "2  -4.623644  ...  [[0.40295226, 0.92358416, 0.05267631], [1.9204...\n",
            "3  -4.702236  ...  [[-0.97261346, -0.16676844, -1.20511235], [-0....\n",
            "4  -4.673232  ...  [[-0.91219868, 0.41237799, 1.15301928], [0.158...\n",
            "5  -5.313537  ...  [[-0.05608486, 0.22205158, 0.76935161], [-0.01...\n",
            "6  -5.312574  ...  [[-0.99485517, 0.48253845, -0.19532324], [0.46...\n",
            "7  -5.131058  ...  [[0.00684328, 0.01878958, 0.01564654], [-0.008...\n",
            "8  -5.058825  ...  [[-0.00309968, -0.00311653, -0.0031407], [-0.0...\n",
            "9  -5.295922  ...  [[0.10803849, 1.5201289, -1.43824908], [-1.608...\n",
            "10 -5.294306  ...  [[0.91448851, -1.09437286, -0.00344895], [1.61...\n",
            "11 -5.245141  ...  [[0.02527078, -0.62806301, -0.2229749], [-0.75...\n",
            "12 -5.214164  ...  [[0.00995144, -1.16831526, 1.45085777], [1.016...\n",
            "13 -5.388369  ...  [[-0.20717037, -0.37315105, -0.62300221], [0.7...\n",
            "14 -5.387673  ...  [[-0.88379159, -0.87350648, 1.62210639], [-0.2...\n",
            "15 -4.669254  ...  [[1.9104226, 2.27558322, 1.53211371], [-0.1918...\n",
            "16 -4.671328  ...  [[0.47738134, 1.44069956, 0.33205219], [0.5412...\n",
            "17 -4.612647  ...  [[-0.61196745, 0.20739327, 2.37155302], [1.290...\n",
            "18 -4.560358  ...  [[1.58924009, -1.32676264, 1.70069606], [0.146...\n",
            "19 -5.386575  ...  [[-0.0, -0.0, 0.0], [-0.0, -0.0, 0.0], [0.0, -...\n",
            "20 -5.386575  ...  [[-0.0, -0.0, -0.0], [-0.0, 0.0, 0.0], [-0.0, ...\n",
            "21 -5.386575  ...  [[0.0, -0.0, 0.0], [-0.0, -0.0, -0.0], [0.0, 0...\n",
            "22 -5.331588  ...  [[0.0, -0.0, -1.14476094], [-0.0, -0.0, -1.144...\n",
            "23 -5.331588  ...  [[-0.0, -1.14476111, -0.0], [-0.0, -1.14476111...\n",
            "24 -5.331588  ...  [[-1.14476008, 0.0, -0.0], [-1.14476008, 0.0, ...\n",
            "\n",
            "[25 rows x 4 columns]\n",
            "building line graphs\n",
            "100% 25/25 [00:00<00:00, 148.22it/s]\n",
            "n_train: 214\n",
            "n_val  : 25\n",
            "n_test : 25\n",
            "version='112bbedebdaecf59fb18e11c929080fb2f358246' dataset='user_data' target='target' atom_features='cgcnn' neighbor_strategy='k-nearest' id_tag='jid' random_seed=123 classification_threshold=None n_val=25 n_test=25 n_train=214 train_ratio=0.9 val_ratio=0.05 test_ratio=0.05 target_multiplication_factor=None epochs=200 batch_size=32 weight_decay=1e-05 learning_rate=0.001 filename='sample' warmup_steps=2000 criterion='l1' optimizer='adamw' scheduler='onecycle' pin_memory=False save_dataloader=False write_checkpoint=True write_predictions=True store_outputs=False progress=True log_tensorboard=False standard_scalar_and_pca=False use_canonize=False num_workers=0 cutoff=8.0 cutoff_extra=3.0 max_neighbors=12 keep_data_order=True normalize_graph_level_loss=False distributed=False data_parallel=False n_early_stopping=None output_dir='alff2_wt_1_determSi' model=ALIGNNAtomWiseConfig(name='alignn_atomwise', alignn_layers=4, gcn_layers=4, atom_input_features=92, edge_input_features=80, triplet_input_features=40, embedding_features=64, hidden_features=300, output_features=1, grad_multiplier=-1, calculate_gradient=True, atomwise_output_features=0, graphwise_weight=1.0, gradwise_weight=1.0, stresswise_weight=0.0, atomwise_weight=0.0, link='identity', zero_inflated=False, classification=False, force_mult_natoms=True, energy_mult_natoms=False, include_pos_deriv=False, use_cutoff_function=False, inner_cutoff=6.0, stress_multiplier=1.0, add_reverse_forces=True, lg_on_fly=True, batch_stress=True, extra_features=0)\n",
            "config:\n",
            "{'atom_features': 'cgcnn',\n",
            " 'batch_size': 32,\n",
            " 'classification_threshold': None,\n",
            " 'criterion': 'l1',\n",
            " 'cutoff': 8.0,\n",
            " 'cutoff_extra': 3.0,\n",
            " 'data_parallel': False,\n",
            " 'dataset': 'user_data',\n",
            " 'distributed': False,\n",
            " 'epochs': 200,\n",
            " 'filename': 'sample',\n",
            " 'id_tag': 'jid',\n",
            " 'keep_data_order': True,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_tensorboard': False,\n",
            " 'max_neighbors': 12,\n",
            " 'model': {'add_reverse_forces': True,\n",
            "           'alignn_layers': 4,\n",
            "           'atom_input_features': 92,\n",
            "           'atomwise_output_features': 0,\n",
            "           'atomwise_weight': 0.0,\n",
            "           'batch_stress': True,\n",
            "           'calculate_gradient': True,\n",
            "           'classification': False,\n",
            "           'edge_input_features': 80,\n",
            "           'embedding_features': 64,\n",
            "           'energy_mult_natoms': False,\n",
            "           'extra_features': 0,\n",
            "           'force_mult_natoms': True,\n",
            "           'gcn_layers': 4,\n",
            "           'grad_multiplier': -1,\n",
            "           'gradwise_weight': 1.0,\n",
            "           'graphwise_weight': 1.0,\n",
            "           'hidden_features': 300,\n",
            "           'include_pos_deriv': False,\n",
            "           'inner_cutoff': 6.0,\n",
            "           'lg_on_fly': True,\n",
            "           'link': 'identity',\n",
            "           'name': 'alignn_atomwise',\n",
            "           'output_features': 1,\n",
            "           'stress_multiplier': 1.0,\n",
            "           'stresswise_weight': 0.0,\n",
            "           'triplet_input_features': 40,\n",
            "           'use_cutoff_function': False,\n",
            "           'zero_inflated': False},\n",
            " 'n_early_stopping': None,\n",
            " 'n_test': 25,\n",
            " 'n_train': 214,\n",
            " 'n_val': 25,\n",
            " 'neighbor_strategy': 'k-nearest',\n",
            " 'normalize_graph_level_loss': False,\n",
            " 'num_workers': 0,\n",
            " 'optimizer': 'adamw',\n",
            " 'output_dir': 'alff2_wt_1_determSi',\n",
            " 'pin_memory': False,\n",
            " 'progress': True,\n",
            " 'random_seed': 123,\n",
            " 'save_dataloader': False,\n",
            " 'scheduler': 'onecycle',\n",
            " 'standard_scalar_and_pca': False,\n",
            " 'store_outputs': False,\n",
            " 'target': 'target',\n",
            " 'target_multiplication_factor': None,\n",
            " 'test_ratio': 0.05,\n",
            " 'train_ratio': 0.9,\n",
            " 'use_canonize': False,\n",
            " 'val_ratio': 0.05,\n",
            " 'version': '112bbedebdaecf59fb18e11c929080fb2f358246',\n",
            " 'warmup_steps': 2000,\n",
            " 'weight_decay': 1e-05,\n",
            " 'write_checkpoint': True,\n",
            " 'write_predictions': True}\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  assert input.numel() == input.storage().size(), (\n",
            "^C\n",
            "CPU times: user 864 ms, sys: 111 ms, total: 975 ms\n",
            "Wall time: 1min 10s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!train_alignn.py --root_dir alff2_wt_1_determSi --config alff2_wt_1_determSi/config_Si.json --output_dir alff2_wt_1_determSi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TA9wN6JOuRMD",
        "outputId": "6bc8adeb-e4ef-412a-e233-ac2501ea03b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'alff2_wt_1_determSi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrf0AuyQdjAP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "d6bd739a-10c6-46f1-e610-2c785d6e7cb3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'alff2_wt_1_determSi/best_model.pt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-86075ddb37b1>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdir_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m calc = AlignnAtomwiseCalculator(\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mforce_mult_natoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/alignn/ff/ff.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, restart, ignore_bad_restart_file, label, include_stress, atoms, directory, device, path, model_filename, config_filename, keep_data_order, classification_threshold, batch_size, epochs, output_dir, stress_wt, force_multiplier, force_mult_natoms, batch_stress, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         model.load_state_dict(\n\u001b[0;32m--> 294\u001b[0;31m             torch.load(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'alff2_wt_1_determSi/best_model.pt'"
          ]
        }
      ],
      "source": [
        "def get_alignn_forces(atoms):\n",
        "    energy = 0.0\n",
        "    forces = np.zeros((atoms.num_atoms, 3))\n",
        "    stress = np.zeros((3, 3))\n",
        "    ase_atoms = atoms.ase_converter()\n",
        "    ase_atoms.calc = calc\n",
        "    forces = np.array(ase_atoms.get_forces())\n",
        "    energy = ase_atoms.get_potential_energy()\n",
        "    stress = voigt_6_to_full_3x3_stress(ase_atoms.get_stress())\n",
        "    return energy, forces, stress\n",
        "\n",
        "model_path = dir_name\n",
        "calc = AlignnAtomwiseCalculator(\n",
        "    path=model_path,\n",
        "    force_mult_natoms=False,\n",
        "    force_multiplier=2,\n",
        "    stress_wt=-4800)\n",
        "\n",
        "df = pd.DataFrame(json.loads(zipfile.ZipFile(\"mlearn.json.zip\").read(\"mlearn.json\")))\n",
        "for i in glob.glob(\"jarvis_leaderboard/jarvis_leaderboard/benchmarks/AI/MLFF/*energy*.zip\"):\n",
        "    if \"mlearn\" in i and element in i:\n",
        "        fname_e = (\n",
        "            \"AI-MLFF-energy-\"\n",
        "            + i.split(\"/\")[-1].split(\"_energy.json.zip\")[0]\n",
        "            + \"-test-mae.csv\"\n",
        "        )\n",
        "        fname_f = (\n",
        "            \"AI-MLFF-forces-\"\n",
        "            + i.split(\"/\")[-1].split(\"_energy.json.zip\")[0]\n",
        "            + \"-test-multimae.csv\"\n",
        "        )\n",
        "        fname_s = (\n",
        "            \"AI-MLFF-stresses-\"\n",
        "            + i.split(\"/\")[-1].split(\"_energy.json.zip\")[0]\n",
        "            + \"-test-multimae.csv\"\n",
        "        )\n",
        "        f_e = open(fname_e, \"w\")\n",
        "        f_f = open(fname_f, \"w\")\n",
        "        f_e.write(\"id,target,prediction\\n\")\n",
        "        f_f.write(\"id,target,prediction\\n\")\n",
        "        print(i)\n",
        "        dat = json.loads(zipfile.ZipFile(i).read(i.split(\"/\")[-1].split(\".zip\")[0]))\n",
        "        print(dat[\"test\"])\n",
        "        for key, val in dat[\"test\"].items():\n",
        "            entry = df[df[\"jid\"] == key]\n",
        "            atoms = Atoms.from_dict(entry.atoms.values[0])\n",
        "            # energy,forces = get_alignn_forces(atoms)\n",
        "            energy, forces, stress = get_alignn_forces(atoms=atoms)\n",
        "            print(key, val, energy, atoms.num_atoms)\n",
        "            line = (key + \",\" + str(entry.energy.values[0]) + \",\" + str(energy) + \"\\n\")\n",
        "            f_e.write(line)\n",
        "            line = (key + \",\" + str(\";\".join(map(str, np.array(entry.forces.values[0]).flatten(),))) +\n",
        "                    \",\" + str(\";\".join(map(str, np.array(forces).flatten()))) + \"\\n\")\n",
        "            f_f.write(line)\n",
        "        f_e.close()\n",
        "        f_f.close()\n",
        "        zname = fname_e + \".zip\"\n",
        "        with zipfile.ZipFile(zname, \"w\") as myzip:\n",
        "            myzip.write(fname_e)\n",
        "        zname = fname_f + \".zip\"\n",
        "        with zipfile.ZipFile(zname, \"w\") as myzip:\n",
        "            myzip.write(fname_f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V-A2PPqebFF"
      },
      "outputs": [],
      "source": [
        "en_df = pd.read_csv('AI-MLFF-energy-mlearn_Si-test-mae.csv.zip')\n",
        "print(mean_absolute_error(en_df['target'],en_df['prediction']))\n",
        "plt.plot(en_df['target'],en_df['prediction'],'.')\n",
        "plt.xlabel('DFT energy(eV)')\n",
        "plt.ylabel('FF energy(eV)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkaAmOXdfAqb"
      },
      "outputs": [],
      "source": [
        "f_df = pd.read_csv('AI-MLFF-forces-mlearn_Si-test-multimae.csv.zip')\n",
        "target = np.concatenate([np.array(i.split(';'),dtype='float') for i in f_df['target'].values])\n",
        "pred= np.concatenate([np.array(i.split(';'),dtype='float') for i in f_df['prediction'].values])\n",
        "print(mean_absolute_error(target,pred))\n",
        "plt.plot(target,pred,'.')\n",
        "plt.xlabel('DFT forces(eV/A)')\n",
        "plt.ylabel('FF forces(eV/A)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FiRsNEgfBRO"
      },
      "outputs": [],
      "source": [
        "json_path = os.path.join(dir_name, \"history_val.json\")\n",
        "v = loadjson(json_path)\n",
        "ens = []\n",
        "fs = []\n",
        "for i in v:\n",
        "    ens.append(i[0])\n",
        "    fs.append(i[2])\n",
        "the_grid = GridSpec(1, 2)\n",
        "plt.rcParams.update({\"font.size\": 18})\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(the_grid[0])\n",
        "plt.title(\"(a) Energy\")\n",
        "plt.plot(ens)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"eV\")\n",
        "plt.subplot(the_grid[1])\n",
        "plt.title(\"(b) Forces\")\n",
        "plt.plot(fs)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"eV/A\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lgNyvdVfFNB"
      },
      "outputs": [],
      "source": [
        "the_grid = GridSpec(1, 2)\n",
        "json_path = os.path.join(dir_name, \"Val_results.json\")\n",
        "test = loadjson(json_path)\n",
        "plt.rcParams.update({\"font.size\": 18})\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(the_grid[0])\n",
        "xx = []\n",
        "yy = []\n",
        "factor = 1\n",
        "for i in test:\n",
        "    for j, k in zip(i[\"target_out\"], i[\"pred_out\"]):\n",
        "        xx.append(j)\n",
        "        yy.append(k)\n",
        "xx = np.array(xx) * factor\n",
        "yy = np.array(yy) * factor\n",
        "\n",
        "x_bar = np.mean(xx)\n",
        "baseline_mae = mean_absolute_error(\n",
        "    np.array(xx),\n",
        "    np.array([x_bar for i in range(len(xx))]),\n",
        ")\n",
        "print(\"Val\")\n",
        "print(\"Baseline MAE: eV\", baseline_mae)\n",
        "print(\"MAE eV\", mean_absolute_error(xx, yy))\n",
        "plt.plot(xx, yy, \".\")\n",
        "plt.ylabel(\"ALIGNN Energy (eV)\")\n",
        "plt.xlabel(\"DFT Energy (eV)\")\n",
        "plt.subplot(the_grid[1])\n",
        "xx = []\n",
        "yy = []\n",
        "for i in test:\n",
        "    for j, k in zip(i[\"target_grad\"], i[\"pred_grad\"]):\n",
        "        for m, n in zip(j, k):\n",
        "            xx.append(m)\n",
        "            yy.append(n)\n",
        "xx = np.array(xx) * factor\n",
        "yy = np.array(yy) * factor\n",
        "\n",
        "x_bar = np.mean(xx)\n",
        "baseline_mae = mean_absolute_error(\n",
        "    np.array(xx),\n",
        "    np.array([x_bar for i in range(len(xx))]),\n",
        ")\n",
        "print(\"Test\")\n",
        "print(\"Baseline MAE: eV/A\", baseline_mae)\n",
        "print(\"MAE eV/A\", mean_absolute_error(xx, yy))\n",
        "plt.scatter(xx, yy, c=\"blueviolet\", s=10, alpha=0.5)\n",
        "plt.ylabel(\"ALIGNN Force (eV/A)\")\n",
        "plt.xlabel(\"DFT Force (eV/A)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# plt.savefig(\"val.png\")\n",
        "# plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Equation of State"
      ],
      "metadata": {
        "id": "DDZ2dA0WfNro"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGtGjNoKfJuD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "d9595da6-afde-499b-f070-ab3fabbc02fb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'alff2_wt_1_determSi/best_model.pt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-308e09c75497>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdir_name\u001b[0m \u001b[0;31m# \"alff2_wt_1_determSi\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m calc = AlignnAtomwiseCalculator(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mforce_mult_natoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mforce_multiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/alignn/ff/ff.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, restart, ignore_bad_restart_file, label, include_stress, atoms, directory, device, path, model_filename, config_filename, keep_data_order, classification_threshold, batch_size, epochs, output_dir, stress_wt, force_multiplier, force_mult_natoms, batch_stress, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         model.load_state_dict(\n\u001b[0;32m--> 294\u001b[0;31m             torch.load(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'alff2_wt_1_determSi/best_model.pt'"
          ]
        }
      ],
      "source": [
        "model_path = dir_name # \"alff2_wt_1_determSi\"\n",
        "calc = AlignnAtomwiseCalculator(\n",
        "    path=model_path,\n",
        "    force_mult_natoms=False,\n",
        "    force_multiplier=2,\n",
        "    stress_wt=-4800) # si crystal (diamond cubic lattice)\n",
        "# equilibrium constant 5.49 from https://www.ctcms.nist.gov/~knc6/static/JARVIS-DFT/JVASP-1002.xml\n",
        "lattice_params = np.linspace(4.5, 6.5)\n",
        "fcc_energies = []\n",
        "ready = True\n",
        "for a in lattice_params:\n",
        "    atoms = bulk('Si', 'diamond', a=a)\n",
        "    atoms.set_tags(np.ones(len(atoms)))\n",
        "    atoms.calc = calc\n",
        "    e = atoms.get_potential_energy()\n",
        "    fcc_energies.append(e)\n",
        "plt.plot(lattice_params, fcc_energies)\n",
        "plt.xlabel('Lattice constant ($\\AA$)')\n",
        "plt.ylabel('Total energy (eV)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXOygV30fNim"
      },
      "source": [
        "## Molecular Dynamics Using ASE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jeq0x35wfJxN"
      },
      "outputs": [],
      "source": [
        "a = Atoms.from_dict(get_jid_data(jid='JVASP-1002',dataset='dft_3d')['atoms'])\n",
        "sup_a = a.get_conventional_atoms.make_supercell_matrix([2,2,2]) # 2x2x2 supercell\n",
        "sup_a.write_poscar('POSCAR-SC')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BH5fw_PZjYUM"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# https://gist.github.com/leelasd/aaa517ac03d2f03bc1e181833e3a70fd\n",
        "# https://mattermodeling.stackexchange.com/questions/11354/basic-md-in-ase\n",
        "model_path = dir_name # \"alff2_wt_1_determSi\"\n",
        "atoms = Atoms.from_poscar(\"POSCAR-SC\").ase_converter()\n",
        "traj_file = \"traj.traj\"\n",
        "traj = Trajectory(traj_file, \"w\", atoms)\n",
        "calc = AlignnAtomwiseCalculator(\n",
        "    path=model_path,\n",
        "    force_mult_natoms=False,\n",
        "    force_multiplier=2,\n",
        "    stress_wt=-4800)\n",
        "atoms.set_calculator(calc)\n",
        "def printenergy(a=atoms):  # store a reference to atoms in the definition.\n",
        "    \"\"\"Function to print the potential, kinetic and total energy.\"\"\"\n",
        "    epot = a.get_potential_energy() / len(a)\n",
        "    ekin = a.get_kinetic_energy() / len(a)\n",
        "    print(\n",
        "        \"Energy per atom: Epot = %.3feV  Ekin = %.3feV (T=%3.0fK)  \"\n",
        "        \"Etot = %.3feV\" % (epot, ekin, ekin / (1.5 * units.kB), epot + ekin)\n",
        "    )\n",
        "\"\"\"Equilibration\"\"\"\n",
        "print(\"Running Equilibration\")\n",
        "dyn =  FIRE(atoms) # dyn = BFGS(atoms)\n",
        "dyn.attach(traj.write, interval=10)\n",
        "dyn.attach(printenergy, interval=10)\n",
        "dyn.run(fmax=1)\n",
        "print(\"Equilibration finished\")\n",
        "\"\"\"Guess Velocities, NVE\"\"\"\n",
        "print(\"Running NVE\")\n",
        "# determine the momenta corresponding to T=300K\n",
        "MaxwellBoltzmannDistribution(atoms, temperature_K=300)\n",
        "# run MD with constant energy using the VelocityVerlet algorithm\n",
        "dyn = VelocityVerlet(atoms, 5*units.fs)  # 5 fs time step\n",
        "dyn.attach(traj.write, interval=10)\n",
        "dyn.attach(printenergy, interval=10)\n",
        "dyn.run(100)\n",
        "print(\"NVE Finished\")\n",
        "\"\"\"NVT\"\"\"\n",
        "print(\"Running NVT\")\n",
        "temperature = 300  # K\n",
        "timestep = 1.0  # fs\n",
        "total_time = 100  # ps\n",
        "nsteps = int(total_time / timestep)\n",
        "taut = 100 * timestep\n",
        "dyn = VelocityVerlet(atoms, timestep)\n",
        "dyn = NVTBerendsen(atoms, timestep, temperature_K=temperature, taut=taut)\n",
        "for step in range(nsteps):\n",
        "    dyn.attach(traj.write, interval=10)\n",
        "    dyn.attach(printenergy, interval=10)\n",
        "    dyn.run(1)\n",
        "print(\"NVT finished\")\n",
        "\"\"\"NPT\"\"\"\n",
        "print(\"Running NPT\")\n",
        "pressure = 1.0  # bar\n",
        "dyn = NPT(atoms, timestep, temperature_K=temperature, externalstress=pressure)\n",
        "for step in range(nsteps):\n",
        "    dyn.attach(traj.write, interval=10)\n",
        "    dyn.attach(printenergy, interval=10)\n",
        "    dyn.run(1)\n",
        "print(\"NPT finished\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVYVF_9LjYYE"
      },
      "outputs": [],
      "source": [
        "ph_path=dir_name\n",
        "atoms=Atoms.from_dict(get_jid_data(jid='JVASP-1002',dataset='dft_3d')['atoms'])\n",
        "ph=phonons(model_path=ph_path,atoms=atoms)\n",
        "plt.axis('off')\n",
        "plt.imshow(plt.imread(\"phonopy_bands.png\"))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6iwv3hOjYcI"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/jarvis_leaderboard/jarvis_leaderboard/contributions/')\n",
        "os.makedirs('alignnff_su')\n",
        "os.chdir('alignnff_su')\n",
        "!wget https://figshare.com/ndownloader/files/40357663 -O mlearn.json.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEwFmiLnjkI7"
      },
      "outputs": [],
      "source": [
        "def get_alignn_forces(atoms):\n",
        "    energy = 0.0\n",
        "    forces = np.zeros((atoms.num_atoms, 3))\n",
        "    stress = np.zeros((3, 3))\n",
        "    ase_atoms = atoms.ase_converter()\n",
        "    ase_atoms.calc = calc  # M3GNetCalculator(potential=potential)\n",
        "    forces = np.array(ase_atoms.get_forces())\n",
        "    energy = ase_atoms.get_potential_energy()\n",
        "    stress = voigt_6_to_full_3x3_stress(ase_atoms.get_stress())\n",
        "    return energy, forces, stress\n",
        "\n",
        "model_path = '/content/'+dir_name\n",
        "calc = AlignnAtomwiseCalculator(\n",
        "    path=model_path,\n",
        "    force_mult_natoms=False,\n",
        "    force_multiplier=2,\n",
        "    stress_wt=-4800)\n",
        "\n",
        "df = pd.DataFrame(json.loads(zipfile.ZipFile(\"mlearn.json.zip\").read(\"mlearn.json\")))\n",
        "print(df)\n",
        "\n",
        "for i in glob.glob(\"../../benchmarks/AI/MLFF/*energy*.zip\"):\n",
        "    if \"mlearn\" in i and \"Si\" in i:\n",
        "        fname_e = (\n",
        "            \"AI-MLFF-energy-\"\n",
        "            + i.split(\"/\")[-1].split(\"_energy.json.zip\")[0]\n",
        "            + \"-test-mae.csv\"\n",
        "            )\n",
        "        fname_f = (\n",
        "            \"AI-MLFF-forces-\"\n",
        "            + i.split(\"/\")[-1].split(\"_energy.json.zip\")[0]\n",
        "            + \"-test-multimae.csv\"\n",
        "            )\n",
        "        fname_s = (\n",
        "            \"AI-MLFF-stresses-\"\n",
        "            + i.split(\"/\")[-1].split(\"_energy.json.zip\")[0]\n",
        "            + \"-test-multimae.csv\"\n",
        "            )\n",
        "        f_e = open(fname_e, \"w\")\n",
        "        f_f = open(fname_f, \"w\")\n",
        "        f_s = open(fname_s, \"w\")\n",
        "        f_e.write(\"id,prediction\\n\")\n",
        "        f_f.write(\"id,prediction\\n\")\n",
        "        f_s.write(\"id,prediction\\n\")\n",
        "        print(i)\n",
        "        dat = json.loads(zipfile.ZipFile(i).read(i.split(\"/\")[-1].split(\".zip\")[0]))\n",
        "        print(dat[\"test\"])\n",
        "        for key, val in dat[\"test\"].items():\n",
        "            entry = df[df[\"jid\"] == key]\n",
        "            atoms = Atoms.from_dict(entry.atoms.values[0])\n",
        "            # print(key, val, df[df['jid']==key], atoms)\n",
        "            energy, forces, stress = get_alignn_forces(atoms)\n",
        "            print(key, val, energy, atoms.num_atoms)\n",
        "            line = key + \",\" + str(energy) + \"\\n\"\n",
        "            f_e.write(line)\n",
        "            line = (key + \",\" + str(\";\".join(map(str, np.array(forces).flatten()))) + \"\\n\")\n",
        "            f_f.write(line)\n",
        "            line = (key + \",\" + str(\";\".join(map(str, np.array(stress).flatten()))) + \"\\n\")\n",
        "            f_s.write(line)\n",
        "        f_e.close()\n",
        "        f_f.close()\n",
        "        f_s.close()\n",
        "        zname = fname_e + \".zip\"\n",
        "        with zipfile.ZipFile(zname, \"w\") as myzip:\n",
        "            myzip.write(fname_e)\n",
        "        zname = fname_f + \".zip\"\n",
        "        with zipfile.ZipFile(zname, \"w\") as myzip:\n",
        "            myzip.write(fname_f)\n",
        "        zname = fname_s + \".zip\"\n",
        "        with zipfile.ZipFile(zname, \"w\") as myzip:\n",
        "            myzip.write(fname_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBPa51jZjkRW"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/usnistgov/jarvis_leaderboard/main/jarvis_leaderboard/contributions/alignnff_mlearn_all_wt1/metadata.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfS5mMzwjkUt"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "atoms = Atoms.from_dict(get_jid_data(jid='JVASP-952',dataset='dft_3d')['atoms'])\n",
        "ph_path = fd_path()\n",
        "ph = phonons(model_path=ph_path,atoms=(atoms))\n",
        "plt.axis('off')\n",
        "plt.imshow(plt.imread(\"phonopy_bands.png\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mWPqC6e-rDFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ce = \"\"\"Ce\n",
        "1.0\n",
        "2.883577080372866 -0.0 1.6648337892833467\n",
        "0.9611923601242888 2.7186624460117796 1.6648337892833467\n",
        "0.0 -0.0 3.3296675785666934\n",
        "Ce\n",
        "1\n",
        "Cartesian\n",
        "0.0 0.0 0.0\n",
        "\"\"\"\n",
        "pos = Poscar.from_string(Ce)\n",
        "ph = phonons(model_path=ph_path,atoms=(pos.atoms))\n",
        "plt.axis('off')\n",
        "plt.imshow(plt.imread(\"phonopy_bands.png\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OLxY36s6rKS-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "EJNMmk4m1xIJ",
        "WwbW3rjp1yC6"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOL5sv98i2pqgXgtyegE+DK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}