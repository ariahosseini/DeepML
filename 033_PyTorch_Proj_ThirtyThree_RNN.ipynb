{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "10zugHntyc88",
        "7pc6oY_CynC0",
        "LYayT8BrEI3C",
        "jzeEp2QB0B_O",
        "qbyOWTMM0IGg",
        "XWez82VlGOOc"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMxNDTykLXivmw0DrYEShSr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ariahosseini/DeepML/blob/main/033_PyTorch_Proj_ThirtyThree_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "LT8uU2AyrUHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**RNN:**\n",
        "*   The input tensor of shape (seq_len, batch, input_size) if batch_first=False or (batch, seq_len, input_size) if batch_first=True\n",
        "\n",
        "*   The term hx (Tensor, optional): Initial hidden state for each element in the batch. Defaults to zero if not provided. It should have the shape (num_layers * num_directions, batch, hidden_size)\n",
        "\n",
        "\n",
        "*   The output (Tensor): Output features from the last layer of the RNN for each time step. Shape is (seq_len, batch, num_directions * hidden_size) if batch_first=False or (batch, seq_len, num_directions * hidden_size) if batch_first=True\n",
        "\n",
        "*   The term hn (Tensor): Hidden state for t=seq_len. Shape is (num_layers * num_directions, batch, hidden_size)"
      ],
      "metadata": {
        "id": "xXT8Ll_p5pWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN One to One"
      ],
      "metadata": {
        "id": "10zugHntyc88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_OnetoOne(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN_OnetoOne, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hx = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        out, _ = self.rnn(x, hx)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "rs-xpjQLrIXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "input_size = 1\n",
        "hidden_size = 20\n",
        "output_size = 1\n",
        "num_epochs = 21\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "HrEULr3vyjlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# synthetic data\n",
        "time_steps = torch.linspace(0, 10, 100)\n",
        "data = torch.sin(time_steps).unsqueeze(1).unsqueeze(1)  # shape: (100, 1, 1)\n",
        "data.shape, data[0], data[1], data[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIE9sN0NyrLu",
        "outputId": "500d3fc1-72f0-4816-b778-c89e575bfb5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([100, 1, 1]),\n",
              " tensor([[0.]]),\n",
              " tensor([[0.1008]]),\n",
              " tensor([[-0.5440]]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model, loss function, optimizer\n",
        "model = RNN_OnetoOne(input_size, hidden_size, output_size)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "FXwotTkPyyRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:-1].shape, data[1:].shape, data[:-1].size(), data[:-1].size(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty0-BOCj1ua0",
        "outputId": "eb061488-52d1-4528-bbca-f19b0b361a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([99, 1, 1]), torch.Size([99, 1, 1]), torch.Size([99, 1, 1]), 99)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(data[:-1])\n",
        "    loss = criterion(outputs, data[1:])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRQXRQdNyrRF",
        "outputId": "1d2a59c0-632c-4156-970c-ba89681b64e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/21], Loss: 0.4471\n",
            "Epoch [20/21], Loss: 0.4463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([99, 1, 1])) that is different to the input size (torch.Size([99, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model\n",
        "test_input = torch.tensor([0.1]).unsqueeze(-1).unsqueeze(-1)  # shape: (1, 1, 1)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predicted = model(test_input)\n",
        "    print(f'Predicted value: {predicted.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rTGFLxRyrVT",
        "outputId": "a90bc403-9cef-4c57-c5c1-53b9b741554f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted value: 0.1619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN One to Many"
      ],
      "metadata": {
        "id": "7pc6oY_CynC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_OnetoMany(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, seq_length):\n",
        "        super(RNN_OnetoMany, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_length = seq_length\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hx = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        out, _ = self.rnn(x, hx)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "rLwH6eybrIbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "input_size = 1\n",
        "hidden_size = 20\n",
        "output_size = 1\n",
        "seq_length = 10\n",
        "num_epochs = 21\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "UFnVCbpZ3eDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# synthetic data\n",
        "time_steps = torch.linspace(0, 10, 100)\n",
        "data = torch.sin(time_steps).unsqueeze(1)  # shape: (100, 1)\n",
        "input_data = data[:-seq_length]\n",
        "target_data = torch.stack([data[i:i+seq_length] for i in range(len(data)-seq_length)])"
      ],
      "metadata": {
        "id": "u2QmNiAf3eGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape, input_data.shape, target_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un_DZy_734pR",
        "outputId": "7ea6ac44-5dfc-4f50-edf2-414cfefd1a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([100, 1]), torch.Size([90, 1]), torch.Size([90, 10, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model, loss function, optimizer\n",
        "model = RNN_OnetoMany(input_size, hidden_size, output_size, seq_length)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "9PJsi-Ce3eJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(input_data.unsqueeze(1))\n",
        "    loss = criterion(outputs, target_data)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2LtUVa93eNh",
        "outputId": "d4a94848-74b0-46f0-a701-d3331a267484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/21], Loss: 0.2778\n",
            "Epoch [20/21], Loss: 0.1272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([90, 10, 1])) that is different to the input size (torch.Size([90, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model\n",
        "test_input = torch.tensor([0.20, 0.20, 0.5]).unsqueeze(-1).unsqueeze(0)  # shape: (1, 3, 1)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predicted = model(test_input)\n",
        "    print(f'Predicted sequence: {predicted.squeeze().numpy()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA9vsoHt3eQ_",
        "outputId": "11a8da39-25ce-45e4-ecad-06a33cafc51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted sequence: [0.22378036 0.12255333 0.45099804]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN Many to One"
      ],
      "metadata": {
        "id": "LYayT8BrEI3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the RNN model\n",
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(SentimentRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hx = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        out, hn = self.rnn(x, hx)\n",
        "        out = self.fc(out[:, -1, :])  # take the output of the last time step\n",
        "        return out"
      ],
      "metadata": {
        "id": "NzsKel3FEYFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "input_size = 50   # example: size of word embeddings\n",
        "hidden_size = 100\n",
        "output_size = 1   # sentiment score (e.g., positive or negative)\n",
        "num_layers = 1\n",
        "seq_length = 10   # example: length of the sentence\n",
        "batch_size = 16\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "mcv3wmX1FNm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# synthetic data\n",
        "x = torch.randn(batch_size, seq_length, input_size)\n",
        "y = torch.randn(batch_size, output_size)"
      ],
      "metadata": {
        "id": "5kpLXsjlEYLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model, loss function, and optimizer\n",
        "model = SentimentRNN(input_size, hidden_size, output_size, num_layers)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "GQqWpMbTEYQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QmTB3jWEYUo",
        "outputId": "7a404153-0472-40b1-c97e-661f52e2230d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.0078\n",
            "Epoch [20/100], Loss: 0.0064\n",
            "Epoch [30/100], Loss: 0.0027\n",
            "Epoch [40/100], Loss: 0.0005\n",
            "Epoch [50/100], Loss: 0.0001\n",
            "Epoch [60/100], Loss: 0.0001\n",
            "Epoch [70/100], Loss: 0.0000\n",
            "Epoch [80/100], Loss: 0.0000\n",
            "Epoch [90/100], Loss: 0.0000\n",
            "Epoch [100/100], Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_input = torch.randn(batch_size, seq_length, input_size)\n",
        "    test_output = model(test_input)\n",
        "    print(f'Test output: {test_output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTGUiFNxEYZR",
        "outputId": "bad604bf-c2dc-461f-9c89-7e89237d64c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test output: tensor([[ 0.1488],\n",
            "        [-0.0536],\n",
            "        [-0.0390],\n",
            "        [-0.3128],\n",
            "        [-0.1177],\n",
            "        [ 0.4725],\n",
            "        [-0.6706],\n",
            "        [-0.0905],\n",
            "        [-0.1791],\n",
            "        [ 0.8394],\n",
            "        [-0.7296],\n",
            "        [-0.7030],\n",
            "        [-0.2583],\n",
            "        [-0.7808],\n",
            "        [-0.2949],\n",
            "        [-0.8092]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN Many to Many Aligned"
      ],
      "metadata": {
        "id": "jzeEp2QB0B_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_ManyToManyAligned(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN_ManyToManyAligned, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hx = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        out, _ = self.rnn(x, hx)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "LaL0de1YrIee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "input_size = 50  # example: word embedding size\n",
        "hidden_size = 100\n",
        "output_size = 10  # example: number of POS tags\n",
        "seq_length = 7  # example: sentence length\n",
        "num_epochs = 2\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "eMmRuyoo0PT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# synthetic data\n",
        "x = torch.randn(20, seq_length, input_size)  # 20 sentences, each of length 7 with 50 features\n",
        "y = torch.randint(0, output_size, (20, seq_length))  # POS tags for each word\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW-nVyGp0GTO",
        "outputId": "c27c1a4d-6500-4eda-bf8b-cabadcd073a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([20, 7, 50]), torch.Size([20, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHmRqAdLpKfc",
        "outputId": "69169034-1974-4c1e-db67-ebfab203a712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6, 8, 6, 8, 1, 7, 3],\n",
              "        [4, 1, 6, 5, 6, 2, 7],\n",
              "        [4, 2, 5, 1, 3, 2, 1],\n",
              "        [9, 0, 8, 9, 4, 0, 7],\n",
              "        [0, 8, 4, 8, 6, 9, 3],\n",
              "        [2, 5, 6, 2, 1, 5, 7],\n",
              "        [5, 7, 8, 9, 6, 9, 0],\n",
              "        [5, 4, 8, 7, 0, 8, 5],\n",
              "        [6, 7, 3, 0, 3, 1, 9],\n",
              "        [3, 8, 0, 6, 4, 1, 5],\n",
              "        [7, 9, 4, 9, 7, 9, 5],\n",
              "        [2, 0, 9, 7, 6, 4, 9],\n",
              "        [3, 8, 3, 6, 5, 6, 9],\n",
              "        [4, 3, 1, 1, 5, 4, 2],\n",
              "        [1, 1, 0, 2, 0, 7, 1],\n",
              "        [8, 2, 4, 8, 8, 5, 8],\n",
              "        [5, 3, 4, 8, 0, 3, 8],\n",
              "        [7, 8, 5, 3, 5, 8, 8],\n",
              "        [7, 6, 0, 8, 8, 1, 8],\n",
              "        [2, 6, 2, 9, 4, 4, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.view(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG-2YsEBpaus",
        "outputId": "c2192fda-e0d6-4c0c-c592-fcb4754f2dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 8, 6, 8, 1, 7, 3, 4, 1, 6, 5, 6, 2, 7, 4, 2, 5, 1, 3, 2, 1, 9, 0, 8,\n",
              "        9, 4, 0, 7, 0, 8, 4, 8, 6, 9, 3, 2, 5, 6, 2, 1, 5, 7, 5, 7, 8, 9, 6, 9,\n",
              "        0, 5, 4, 8, 7, 0, 8, 5, 6, 7, 3, 0, 3, 1, 9, 3, 8, 0, 6, 4, 1, 5, 7, 9,\n",
              "        4, 9, 7, 9, 5, 2, 0, 9, 7, 6, 4, 9, 3, 8, 3, 6, 5, 6, 9, 4, 3, 1, 1, 5,\n",
              "        4, 2, 1, 1, 0, 2, 0, 7, 1, 8, 2, 4, 8, 8, 5, 8, 5, 3, 4, 8, 0, 3, 8, 7,\n",
              "        8, 5, 3, 5, 8, 8, 7, 6, 0, 8, 8, 1, 8, 2, 6, 2, 9, 4, 4, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model, loss function, optimizer\n",
        "model = RNN_ManyToManyAligned(input_size, hidden_size, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "6D4u1Z080GW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs.view(-1, output_size), y.view(-1))\n",
        "    print(outputs.shape, outputs.view(-1, output_size).shape, y.view(-1).shape)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq7HrwlD0Gac",
        "outputId": "27dcc6ba-5e0b-427b-c4e4-2deabbcd1ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 7, 10]) torch.Size([140, 10]) torch.Size([140])\n",
            "torch.Size([20, 7, 10]) torch.Size([140, 10]) torch.Size([140])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model\n",
        "test_input = torch.randn(1, seq_length, input_size)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predicted = model(test_input)\n",
        "    predicted_tags = torch.argmax(predicted, dim=2)\n",
        "    print(f'Predicted POS tags: {predicted_tags}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQrO-t6r0GgS",
        "outputId": "5b53455f-f1d3-4202-923d-83d6c7504d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted POS tags: tensor([[3, 5, 8, 5, 8, 0, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN Many to Many Non-Aligned"
      ],
      "metadata": {
        "id": "qbyOWTMM0IGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hx = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        out, hidden = self.rnn(x, hx)\n",
        "        return out, hidden\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(output_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        out = self.fc(out)\n",
        "        return out, hidden"
      ],
      "metadata": {
        "id": "0u4IvBJKrIiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "input_size = 50  # example: word embedding size for source language\n",
        "hidden_size = 100\n",
        "output_size = 50  # example: word embedding size for target language\n",
        "seq_length_in = 7  # example: source sentence length\n",
        "seq_length_out = 5  # example: target sentence length\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "rrGKms-H0uIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate synthetic data\n",
        "encoder_input = torch.randn(20, seq_length_in, input_size)  # 20 source sentences\n",
        "decoder_input = torch.randn(20, seq_length_out, output_size)  # 20 target sentences\n",
        "encoder_input.shape, decoder_input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHO0zfBc0uL0",
        "outputId": "78d2969d-0947-4edc-a0ef-7cecf4941035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([20, 7, 50]), torch.Size([20, 5, 50]))"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model, loss function, optimizer\n",
        "encoder = EncoderRNN(input_size, hidden_size)\n",
        "decoder = DecoderRNN(hidden_size, output_size)\n",
        "criterion = nn.MSELoss()\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "ehGJiwS00uPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "    encoder_output, encoder_hidden = encoder(encoder_input)\n",
        "    decoder_output, _ = decoder(decoder_input, encoder_hidden)\n",
        "    loss = criterion(decoder_output, decoder_input)\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEU6BZi00o1a",
        "outputId": "8f47f4c1-882c-4f72-ea17-c83a07572420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.1496\n",
            "Epoch [20/100], Loss: 0.0415\n",
            "Epoch [30/100], Loss: 0.0135\n",
            "Epoch [40/100], Loss: 0.0046\n",
            "Epoch [50/100], Loss: 0.0016\n",
            "Epoch [60/100], Loss: 0.0006\n",
            "Epoch [70/100], Loss: 0.0002\n",
            "Epoch [80/100], Loss: 0.0001\n",
            "Epoch [90/100], Loss: 0.0000\n",
            "Epoch [100/100], Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model\n",
        "test_input = torch.randn(1, seq_length_in, input_size)\n",
        "test_decoder_input = torch.randn(1, seq_length_out, output_size)\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "with torch.no_grad():\n",
        "    test_encoder_output, test_encoder_hidden = encoder(test_input)\n",
        "    predicted, _ = decoder(test_decoder_input, test_encoder_hidden)\n",
        "    print(f'Predicted sequence: {predicted.squeeze().numpy()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSwkuI-o0o48",
        "outputId": "e3156115-21ea-4eac-f9ca-ba57def17902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted sequence: [[-9.58063245e-01 -2.45522428e+00 -4.06330258e-01  7.63738394e-01\n",
            "  -3.15582603e-01 -1.42913544e+00  1.24821448e+00  8.91585469e-01\n",
            "   6.63285077e-01  3.54497463e-01  2.33842790e-01 -1.31666267e+00\n",
            "  -1.44796324e+00 -1.48879087e+00  1.47157431e+00  2.63503581e-01\n",
            "  -8.45830142e-01 -1.11829735e-01  1.10252976e+00 -8.63244653e-01\n",
            "  -3.97329498e-03  7.90493309e-01  1.13649726e+00 -1.30242378e-01\n",
            "   1.17026579e+00 -1.25789240e-01 -1.34844527e-01 -7.98585340e-02\n",
            "  -5.54546192e-02 -4.72856045e-01  4.10403386e-02 -7.20104337e-01\n",
            "  -3.84937853e-01  1.38411522e+00 -3.14527124e-01  1.72361463e-01\n",
            "   2.28510022e-01  7.45017529e-01 -1.89043653e+00  1.33439553e+00\n",
            "  -8.93124491e-02 -6.20789409e-01  4.37665552e-01  5.19401908e-01\n",
            "  -1.94509768e+00  3.64615321e-01 -6.85808420e-01 -9.45431590e-01\n",
            "  -4.51202363e-01 -1.25475675e-01]\n",
            " [ 2.09453776e-01 -3.06074679e-01 -1.46475032e-01 -4.80144560e-01\n",
            "   2.64177561e-01 -4.76834893e-01  5.97176373e-01 -7.20708430e-01\n",
            "  -4.89589155e-01 -1.13245547e-01  1.27753186e+00 -1.43457711e+00\n",
            "  -1.71248627e+00 -2.23946884e-01 -1.93106294e-01 -1.04809165e+00\n",
            "   4.85988379e-01 -2.37595272e+00 -6.77984357e-01  1.31995276e-01\n",
            "  -8.86625588e-01 -7.97380865e-01 -5.26606321e-01  2.91219831e-01\n",
            "   6.61980659e-02  6.15611672e-04 -4.46925253e-01  1.54245719e-01\n",
            "   4.31268185e-01 -3.76507103e-01  2.36328825e-01 -1.27500331e+00\n",
            "   4.68642592e-01  4.89237398e-01 -8.90261471e-01  8.78805161e-01\n",
            "   1.48572934e+00 -2.97988415e-01 -1.48526978e+00  1.51682682e-02\n",
            "   3.52219969e-01 -9.05667663e-01 -1.38691425e+00 -3.31550032e-01\n",
            "   3.06930393e-03 -9.33553159e-01  1.63235307e-01  6.19153380e-01\n",
            "  -4.35318977e-01  8.25415850e-01]\n",
            " [-5.35423994e-01  6.04645073e-01 -1.05733776e+00  1.00338781e+00\n",
            "   5.23655303e-02 -1.01355553e-01  2.52693385e-01 -1.35113382e+00\n",
            "  -1.70597363e+00 -1.01093709e+00 -1.54821205e+00  2.19734001e+00\n",
            "  -1.56364053e-01  9.65899348e-01 -7.55660236e-01  2.12784410e-02\n",
            "  -2.84416056e+00  1.67576335e-02  9.98277903e-01 -9.33655024e-01\n",
            "   3.28553431e-02  7.07347631e-01 -5.64972758e-01  1.96420670e+00\n",
            "   1.59508324e+00  1.29696846e+00  2.02044988e+00 -1.17416143e+00\n",
            "  -5.70123017e-01  6.16405830e-02  6.31859422e-01 -1.35355353e+00\n",
            "  -1.00025749e+00 -1.05635822e+00 -2.76241302e+00 -1.03209220e-01\n",
            "  -7.37336755e-01  1.87025952e+00  3.27119455e-02  9.01382446e-01\n",
            "  -1.26272869e+00 -1.96698546e-01 -7.31089830e-01 -1.05101597e+00\n",
            "   2.06333980e-01 -4.21327144e-01  1.32737076e+00 -7.83194602e-02\n",
            "   5.69215178e-01  3.42796177e-01]\n",
            " [-8.03976417e-01  5.63978493e-01  1.54955912e+00  2.00940990e+00\n",
            "   1.36088943e+00 -2.29184955e-01 -7.28064775e-01 -7.73443699e-01\n",
            "  -8.55885029e-01 -6.83492064e-01  9.93545532e-01  5.03324091e-01\n",
            "   1.90245286e-01  6.15912020e-01  3.46886635e-01  7.68022686e-02\n",
            "   1.02753282e-01 -2.59494990e-01 -2.42407113e-01 -2.81075001e-01\n",
            "   1.54627633e+00 -1.66372550e+00 -1.74421716e+00  4.88562316e-01\n",
            "   4.07178789e-01  1.15906847e+00 -1.91050708e-01  1.83161306e+00\n",
            "   2.46349722e-01 -2.20237300e-02 -4.13390666e-01  1.58615112e-01\n",
            "  -1.07873678e-01  5.10552824e-01  4.09605324e-01  9.36688304e-01\n",
            "  -1.79141283e-01  1.01082242e+00 -8.69906425e-01 -2.74902046e-01\n",
            "   5.26672482e-01  1.29213095e+00 -7.67846644e-01  2.91720629e-01\n",
            "  -1.03413284e+00 -2.87275004e+00  1.22876179e+00 -1.18365777e+00\n",
            "  -1.30378187e+00  9.61459398e-01]\n",
            " [-1.91450462e-01 -1.51117575e+00  7.43157506e-01 -7.36803055e-01\n",
            "  -7.63550937e-01 -6.63600683e-01 -2.84756064e-01  6.06836200e-01\n",
            "   6.34920597e-01 -5.42941928e-01  1.58575773e+00  7.74816871e-01\n",
            "   8.82377386e-01  2.06433926e-02 -3.62640023e-01  5.48358262e-01\n",
            "  -1.09174669e+00  8.16475034e-01 -2.92595327e-01 -9.53123510e-01\n",
            "   8.66418242e-01  6.15623057e-01  1.43614328e+00 -2.14551210e-01\n",
            "   1.66174936e+00 -8.26726973e-01 -1.73798704e+00 -1.56841481e+00\n",
            "   1.17790425e+00  4.42185938e-01  1.88368237e+00  5.77829778e-01\n",
            "   1.35764277e+00 -3.20994228e-01 -3.39257330e-01  1.64500058e-01\n",
            "  -4.98297513e-01  1.59065574e-02 -4.59531933e-01  4.03502494e-01\n",
            "  -7.66137719e-01  9.58593488e-01 -1.46244693e+00 -4.58624035e-01\n",
            "  -6.35016501e-01  8.16683918e-02  9.84165132e-01 -2.02261925e-01\n",
            "   6.76018596e-01  1.17345834e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN Multi Layer"
      ],
      "metadata": {
        "id": "XWez82VlGOOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=2):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        out, hidden = self.rnn(x, h0)\n",
        "        return out, hidden\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, num_layers=2):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(output_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        out = self.fc(out)\n",
        "        return out, hidden"
      ],
      "metadata": {
        "id": "dh_pwAGTGSSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "input_size = 50   # example: size of word embeddings for the input sequence\n",
        "hidden_size = 100\n",
        "output_size = 50  # example: size of word embeddings for the output sequence\n",
        "num_layers = 2    # multi-layer RNN\n",
        "seq_length_in = 7  # length of the input sequence\n",
        "seq_length_out = 5  # length of the output sequence\n",
        "batch_size = 16\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "fwHi70-AGktS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# synthetic data\n",
        "encoder_input = torch.randn(batch_size, seq_length_in, input_size)  # batch of input sequences\n",
        "decoder_input = torch.randn(batch_size, seq_length_out, output_size)  # batch of output sequences"
      ],
      "metadata": {
        "id": "27CSF6LFGkw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the encoder and decoder\n",
        "encoder = EncoderRNN(input_size, hidden_size, num_layers)\n",
        "decoder = DecoderRNN(hidden_size, output_size, num_layers)"
      ],
      "metadata": {
        "id": "7Os1Mmq3GY4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Zo9VojqlGY9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "    # forward pass through the encoder\n",
        "    encoder_output, encoder_hidden = encoder(encoder_input)\n",
        "    # use the encoder's final hidden state from all layers as the decoder's initial hidden state\n",
        "    decoder_output, _ = decoder(decoder_input, encoder_hidden)\n",
        "    # compute loss\n",
        "    loss = criterion(decoder_output, decoder_input)\n",
        "    loss.backward()\n",
        "    # update parameters\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR4LbmnHGZBR",
        "outputId": "fb4d1135-9d37-4551-e455-0d6241bca1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.1439\n",
            "Epoch [20/100], Loss: 0.0334\n",
            "Epoch [30/100], Loss: 0.0096\n",
            "Epoch [40/100], Loss: 0.0034\n",
            "Epoch [50/100], Loss: 0.0011\n",
            "Epoch [60/100], Loss: 0.0004\n",
            "Epoch [70/100], Loss: 0.0002\n",
            "Epoch [80/100], Loss: 0.0001\n",
            "Epoch [90/100], Loss: 0.0002\n",
            "Epoch [100/100], Loss: 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model\n",
        "test_input = torch.randn(1, seq_length_in, input_size)\n",
        "test_decoder_input = torch.randn(1, seq_length_out, output_size)\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "with torch.no_grad():\n",
        "    test_encoder_output, test_encoder_hidden = encoder(test_input)\n",
        "    test_decoder_output, _ = decoder(test_decoder_input, test_encoder_hidden)\n",
        "    print(f'Test output: {test_decoder_output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMCPZAVSGZE7",
        "outputId": "1c370ab6-c515-437c-dc04-76991754623f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test output: tensor([[[ 0.0783, -1.2449,  0.5573,  0.3132,  0.6333, -0.1096,  0.3452,\n",
            "          -0.8341, -1.2519, -0.2495, -1.5950, -0.2431,  0.8112,  0.3485,\n",
            "          -0.9840,  1.1266,  0.7343, -0.1157, -1.4637,  0.2465,  0.2509,\n",
            "          -0.5281,  0.4140, -1.0209, -0.0131, -1.4702,  0.8495,  0.6432,\n",
            "          -0.3199,  0.5975, -0.0654,  0.3880,  1.6320,  0.4710, -0.0626,\n",
            "           0.0529,  3.1643,  0.8532, -1.3011, -0.5377,  0.7130, -1.0162,\n",
            "          -0.0842, -0.8379, -1.2955, -1.2935, -0.8112, -2.0623, -0.0325,\n",
            "          -0.9914],\n",
            "         [ 0.0707, -0.3950, -1.1536,  0.6344,  0.3251, -1.3754,  0.2431,\n",
            "          -0.3241,  0.6557, -1.5561,  0.5470,  0.5343,  1.8054, -0.4889,\n",
            "           0.1326, -0.2897, -0.1422, -0.7454,  1.7426, -0.7533,  1.0297,\n",
            "          -0.1369,  0.1271, -0.9549,  1.4835,  1.0893, -1.6190,  0.2928,\n",
            "          -0.8291, -0.1619,  0.1448, -1.0044,  1.0291,  0.2951,  2.0484,\n",
            "           1.9221, -0.2311,  0.0637,  0.3052, -0.1799, -0.3693, -1.4337,\n",
            "           0.4723,  0.6566,  1.0505,  1.0088, -0.4317, -0.7899,  0.3260,\n",
            "          -0.6719],\n",
            "         [-0.3725,  0.6545, -0.5153,  0.5400,  0.0333,  0.3784, -0.0980,\n",
            "           0.4381, -1.4227,  1.1033, -0.0290, -0.0754,  1.2737, -1.1251,\n",
            "          -0.1937, -0.0043,  1.6745, -1.2853,  0.3909, -0.4781,  0.6308,\n",
            "          -1.4869, -0.1155, -0.2882, -0.8763,  0.8454, -0.1063,  0.0497,\n",
            "           0.5547, -0.8607,  1.3685,  0.5737,  1.9676,  0.3107,  0.8476,\n",
            "          -0.8705,  0.2109, -0.1770,  0.8740,  0.6149,  1.5222, -1.4075,\n",
            "          -1.8085, -2.1766,  0.3058,  0.1277, -2.3271,  0.1549, -0.0993,\n",
            "           0.6870],\n",
            "         [-0.2276,  0.9893, -0.1742,  0.5393, -0.4989, -0.3009,  0.1429,\n",
            "          -1.0081,  1.0460,  0.4418,  1.5705, -2.7117,  0.7849, -2.1744,\n",
            "          -0.4094,  0.5625, -0.6056,  1.2983,  0.7300, -1.2401,  0.4846,\n",
            "           0.2452,  0.9475, -0.5107,  0.0274, -0.6550, -1.0263, -0.9263,\n",
            "          -0.9951, -0.1013,  0.9084,  0.7375,  0.9506,  0.4669, -0.3485,\n",
            "           1.0744,  0.1948, -0.2404, -1.7731,  1.8654,  1.1242,  0.1552,\n",
            "           0.1994, -1.0666,  0.1547,  0.1560, -0.1058, -0.6991, -0.8286,\n",
            "           0.9785],\n",
            "         [ 0.2788, -0.1110, -0.7492, -0.6276,  1.2211, -0.2092, -0.3253,\n",
            "          -0.4188,  0.4554,  1.1356,  0.5647,  0.2679, -0.2305, -0.5656,\n",
            "          -0.6371,  0.7445,  1.2432,  0.9964,  0.2400,  2.4386, -0.3445,\n",
            "          -0.0977,  1.1708, -0.4780,  0.6656, -0.7786, -0.0826,  1.7716,\n",
            "          -0.3264, -0.8872, -0.1338,  1.0155,  1.9282, -0.0621,  0.1833,\n",
            "          -1.0829, -0.5764, -0.3167, -1.2952, -1.5641, -0.4593,  0.3630,\n",
            "           1.7666,  0.7944,  0.8134, -0.5927,  0.2442,  0.7824,  0.5454,\n",
            "          -0.5256]]])\n"
          ]
        }
      ]
    }
  ]
}