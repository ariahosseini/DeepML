{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IklHudBIi8hY"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOg/CXm9N+14e8+OvX8u2PE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ariahosseini/DeepML/blob/main/035_PyTorch_Proj_ThirtyFive_DiffusionProbabilisticModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9eSY6-Fb8wP"
      },
      "outputs": [],
      "source": [
        "# utils\n",
        "import copy\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "# torch\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "# vis\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Denoising Diffusion Probabilistic Models for CIFAR10"
      ],
      "metadata": {
        "id": "IklHudBIi8hY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(images, title=\"\"):\n",
        "    \"\"\"Shows the provided images as sub-pictures in a square\"\"\"\n",
        "    images = [np.clip(im.permute(1,2,0).numpy(),0,1) for im in images]\n",
        "\n",
        "    # defining number of rows and columns\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    rows = int(len(images) ** (1 / 2))\n",
        "    cols = round(len(images) / rows)\n",
        "\n",
        "    # populating figure with sub-plots\n",
        "    idx = 0\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            fig.add_subplot(rows, cols, idx + 1)\n",
        "\n",
        "            if idx < len(images):\n",
        "                plt.imshow(images[idx])\n",
        "                plt.axis('off')\n",
        "                idx += 1\n",
        "    fig.suptitle(title, fontsize=30)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "urme9qKCjObq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Ct-7bHNPjOeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sinusoidal_embedding(n, d):\n",
        "    # returns the standard positional embedding\n",
        "    embedding = torch.tensor([[i / 10_000 ** (2 * j / d) for j in range(d)] for i in range(n)])\n",
        "    sin_mask = torch.arange(0, n, 2)\n",
        "    embedding[sin_mask] = torch.sin(embedding[sin_mask])\n",
        "    embedding[1 - sin_mask] = torch.cos(embedding[sin_mask])\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "Nn_pZzVMjOhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class double_conv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class down_layer(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down_layer, self).__init__()\n",
        "        self.pool = nn.MaxPool2d(2, stride=2, padding=0)\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(self.pool(x))\n",
        "        return x\n",
        "\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(up, self).__init__()\n",
        "        self.up_scale = nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2)\n",
        "\n",
        "    def forward(self, x1, x2): # x1 (bs,out_ch,w1,h1) x2 (bs,in_ch,w2,h2)\n",
        "        x2 = self.up_scale(x2) # (bs,out_ch,2*w2,2*h2)\n",
        "        diffY = x1.size()[2] - x2.size()[2]\n",
        "        diffX = x1.size()[3] - x2.size()[3]\n",
        "\n",
        "        x2 = F.pad(x2, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2]) # (bs, out_ch, w1, h1)\n",
        "        x = torch.cat([x2, x1], dim=1) # (bs, 2*out_ch, w1, h1)\n",
        "        return x\n",
        "\n",
        "class up_layer(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch): # 2*out_ch = in_ch\n",
        "        super(up_layer, self).__init__()\n",
        "        self.up = up(in_ch, out_ch)\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2): # x1 (bs, out_ch, w1, h1) x2 (bs, in_ch, w2, h2)\n",
        "        a = self.up(x1, x2) # (bs, 2*out_ch,w1,h1)\n",
        "        x = self.conv(a) # (bs, out_ch, w1, h1) because 2*out_ch = in_ch\n",
        "        return x\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, n_steps=1000, time_emb_dim=100):\n",
        "        super(UNet, self).__init__()\n",
        "        self.conv1 = double_conv(in_channels, 64)\n",
        "        self.down1 = down_layer(64, 128)\n",
        "        self.down2 = down_layer(128, 256)\n",
        "        self.down3 = down_layer(256, 512)\n",
        "        self.down4 = down_layer(512, 1024)\n",
        "        self.up1 = up_layer(1024, 512)\n",
        "        self.up2 = up_layer(512, 256)\n",
        "        self.up3 = up_layer(256, 128)\n",
        "        self.up4 = up_layer(128, 64)\n",
        "        self.last_conv = nn.Conv2d(64, in_channels, 1)\n",
        "\n",
        "        # time embedding\n",
        "        self.time_embed = nn.Embedding(n_steps, time_emb_dim)\n",
        "        self.time_embed.weight.data = sinusoidal_embedding(n_steps, time_emb_dim)\n",
        "        self.time_embed.requires_grad_(False)\n",
        "        self.te1 = self._make_te(time_emb_dim, in_channels)\n",
        "        self.te2 = self._make_te(time_emb_dim, 64)\n",
        "        self.te3 = self._make_te(time_emb_dim, 128)\n",
        "        self.te4 = self._make_te(time_emb_dim, 256)\n",
        "        self.te5 = self._make_te(time_emb_dim, 512)\n",
        "        self.te1_up = self._make_te(time_emb_dim, 1024)\n",
        "        self.te2_up = self._make_te(time_emb_dim, 512)\n",
        "        self.te3_up = self._make_te(time_emb_dim, 256)\n",
        "        self.te4_up = self._make_te(time_emb_dim, 128)\n",
        "\n",
        "    def _make_te(self, dim_in, dim_out):\n",
        "        return nn.Sequential(nn.Linear(dim_in, dim_out), nn.SiLU(), nn.Linear(dim_out, dim_out))\n",
        "\n",
        "    def forward(self, x , t): # x (bs,in_channels,w,d)\n",
        "        bs = x.shape[0]\n",
        "        t = self.time_embed(t)\n",
        "        x1 = self.conv1(x+self.te1(t).reshape(bs, -1, 1, 1)) # (bs,64,w,d)\n",
        "        x2 = self.down1(x1+self.te2(t).reshape(bs, -1, 1, 1)) # (bs,128,w/2,d/2)\n",
        "        x3 = self.down2(x2+self.te3(t).reshape(bs, -1, 1, 1)) # (bs,256,w/4,d/4)\n",
        "        x4 = self.down3(x3+self.te4(t).reshape(bs, -1, 1, 1)) # (bs,512,w/8,h/8)\n",
        "        x5 = self.down4(x4+self.te5(t).reshape(bs, -1, 1, 1)) # (bs,1024,w/16,h/16)\n",
        "        x1_up = self.up1(x4, x5+self.te1_up(t).reshape(bs, -1, 1, 1)) # (bs,512,w/8,h/8)\n",
        "        x2_up = self.up2(x3, x1_up+self.te2_up(t).reshape(bs, -1, 1, 1)) # (bs,256,w/4,h/4)\n",
        "        x3_up = self.up3(x2, x2_up+self.te3_up(t).reshape(bs, -1, 1, 1)) # (bs,128,w/2,h/2)\n",
        "        x4_up = self.up4(x1, x3_up+self.te4_up(t).reshape(bs, -1, 1, 1)) # (bs,64,w,h)\n",
        "        output = self.last_conv(x4_up) # (bs,in_channels,w,h)\n",
        "        return output\n",
        "\n",
        "bs = 3\n",
        "x = torch.randn(bs,1,32,32)\n",
        "n_steps=1000\n",
        "timesteps = torch.randint(0, n_steps, (bs,)).long()\n",
        "unet = UNet()\n",
        "\n",
        "y = unet(x,timesteps)\n",
        "y.shape\n",
        "\n",
        "class DDPM(nn.Module):\n",
        "    def __init__(self, network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device) -> None:\n",
        "        super(DDPM, self).__init__()\n",
        "        self.num_timesteps = num_timesteps\n",
        "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps, dtype=torch.float32).to(device)\n",
        "        self.alphas = 1.0 - self.betas\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
        "        self.network = network\n",
        "        self.device = device\n",
        "        self.sqrt_alphas_cumprod = self.alphas_cumprod ** 0.5 # used in add_noise\n",
        "        self.sqrt_one_minus_alphas_cumprod = (1 - self.alphas_cumprod) ** 0.5 # used in add_noise and step\n",
        "\n",
        "    def add_noise(self, x_start, x_noise, timesteps):\n",
        "        # forward process\n",
        "        # x_start and x_noise (bs, n_c, w, d)\n",
        "        # timesteps (bs)\n",
        "        s1 = self.sqrt_alphas_cumprod[timesteps] # bs\n",
        "        s2 = self.sqrt_one_minus_alphas_cumprod[timesteps] # bs\n",
        "        s1 = s1.reshape(-1,1,1,1) # (bs, 1, 1, 1) for broadcasting\n",
        "        s2 = s2.reshape(-1,1,1,1) # (bs, 1, 1, 1)\n",
        "        return s1 * x_start + s2 * x_noise\n",
        "\n",
        "    def reverse(self, x, t):\n",
        "        # network return the estimation of the noise we added\n",
        "        return self.network(x, t)\n",
        "\n",
        "    def step(self, model_output, timestep, sample):\n",
        "        # one step of sampling\n",
        "        # timestep (1)\n",
        "        t = timestep\n",
        "        coef_epsilon = (1-self.alphas)/self.sqrt_one_minus_alphas_cumprod\n",
        "        coef_eps_t = coef_epsilon[t].reshape(-1,1,1,1)\n",
        "        coef_first = 1/self.alphas ** 0.5\n",
        "        coef_first_t = coef_first[t].reshape(-1,1,1,1)\n",
        "        pred_prev_sample = coef_first_t*(sample-coef_eps_t*model_output)\n",
        "\n",
        "        variance = 0\n",
        "        if t > 0:\n",
        "            noise = torch.randn_like(model_output).to(self.device)\n",
        "            variance = ((self.betas[t] ** 0.5) * noise)\n",
        "\n",
        "        pred_prev_sample = pred_prev_sample + variance\n",
        "\n",
        "        return pred_prev_sample\n",
        "\n",
        "def training_loop(model, dataloader, optimizer, num_epochs, num_timesteps, device=device):\n",
        "    \"\"\"Training loop for DDPM\"\"\"\n",
        "\n",
        "    global_step = 0\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        progress_bar = tqdm(total=len(dataloader))\n",
        "        progress_bar.set_description(f\"Epoch {epoch}\")\n",
        "        for step, batch in enumerate(dataloader):\n",
        "            batch = batch[0].to(device)\n",
        "            noise = torch.randn(batch.shape).to(device)\n",
        "            timesteps = torch.randint(0, num_timesteps, (batch.shape[0],)).long().to(device)\n",
        "\n",
        "            noisy = model.add_noise(batch, noise, timesteps)\n",
        "            noise_pred = model.reverse(noisy, timesteps)\n",
        "            loss = F.mse_loss(noise_pred, noise)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            progress_bar.update(1)\n",
        "            logs = {\"loss\": loss.detach().item(), \"step\": global_step}\n",
        "            losses.append(loss.detach().item())\n",
        "            progress_bar.set_postfix(**logs)\n",
        "            global_step += 1\n",
        "\n",
        "        progress_bar.close()\n",
        "\n",
        "root_dir = './data/'\n",
        "transforms01 = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        # torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "dataset = torchvision.datasets.CIFAR10(root=root_dir, train=True, transform=transforms01, download=True)\n",
        "dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=512, shuffle=True,num_workers=10)\n",
        "\n",
        "for b in dataloader:\n",
        "    batch = b[0]\n",
        "    break\n",
        "\n",
        "bn = [b for b in batch[:100]]\n",
        "show_images(bn, \"origin\")\n",
        "\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 15\n",
        "num_timesteps = 1000\n",
        "network = UNet(in_channels=3)\n",
        "network.to(device)\n",
        "model = DDPM(network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device)\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "training_loop(model, dataloader, optimizer, num_epochs, num_timesteps, device=device)\n",
        "\n",
        "def generate_image(ddpm, sample_size, channel, size):\n",
        "    \"\"\"Generate the image from the Gaussian noise\"\"\"\n",
        "\n",
        "    frames = []\n",
        "    frames_mid = []\n",
        "    ddpm.eval()\n",
        "    with torch.no_grad():\n",
        "        timesteps = list(range(ddpm.num_timesteps))[::-1]\n",
        "        sample = torch.randn(sample_size, channel, size, size).to(device)\n",
        "\n",
        "        for i, t in enumerate(tqdm(timesteps)):\n",
        "            time_tensor = (torch.ones(sample_size) * t).long().to(device)\n",
        "            residual = ddpm.reverse(sample, time_tensor).to(device)\n",
        "            sample = ddpm.step(residual, time_tensor[0], sample)\n",
        "\n",
        "            if t==500:\n",
        "                # sample_squeezed = torch.squeeze(sample)\n",
        "                for i in range(sample_size):\n",
        "                    frames_mid.append(sample[i].detach().cpu())\n",
        "\n",
        "        # sample = torch.squeeze(sample)\n",
        "        for i in range(sample_size):\n",
        "            frames.append(sample[i].detach().cpu())\n",
        "    return frames, frames_mid\n",
        "\n",
        "generated, generated_mid = generate_image(model, 100, 3, 32)\n",
        "show_images(generated_mid, \"Mid result\")\n",
        "show_images(generated, \"Final result\")\n",
        "\n",
        "def make_dataloader(dataset, class_name ='ship'):\n",
        "    s_indices = []\n",
        "    s_idx = dataset.class_to_idx[class_name]\n",
        "    for i in range(len(dataset)):\n",
        "        current_class = dataset[i][1]\n",
        "        if current_class == s_idx:\n",
        "            s_indices.append(i)\n",
        "    s_dataset = Subset(dataset, s_indices)\n",
        "    return torch.utils.data.DataLoader(dataset=s_dataset, batch_size=512, shuffle=True)\n",
        "\n",
        "ship_dataloader = make_dataloader(dataset)\n",
        "ship_network = copy.deepcopy(network)\n",
        "ship_model = DDPM(ship_network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device)\n",
        "num_epochs = 10\n",
        "num_timesteps = model.num_timesteps\n",
        "learning_rate = 1e-3\n",
        "ship_model.train()\n",
        "optimizer = torch.optim.Adam(ship_model.parameters(), lr=learning_rate)\n",
        "training_loop(ship_model, ship_dataloader, optimizer, num_epochs, num_timesteps, device=device)\n",
        "generated, generated_mid = generate_image(ship_model, 100, 3, 32)\n",
        "show_images(generated, \"Generated ships\")\n",
        "horse_dataloader = make_dataloader(dataset, 'horse')\n",
        "horse_network = copy.deepcopy(network)\n",
        "horse_model = DDPM(horse_network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device)\n",
        "num_epochs = 10\n",
        "num_timesteps = model.num_timesteps\n",
        "learning_rate = 1e-3\n",
        "horse_model.train()\n",
        "optimizer = torch.optim.Adam(horse_model.parameters(), lr=learning_rate)\n",
        "training_loop(horse_model, horse_dataloader, optimizer, num_epochs, num_timesteps, device=device)\n",
        "generated, generated_mid = generate_image(horse_model, 100, 3, 32)\n",
        "show_images(generated, \"Generated horses\")\n",
        "truck_dataloader = make_dataloader(dataset, 'truck')\n",
        "truck_network = copy.deepcopy(network)\n",
        "truck_model = DDPM(truck_network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device)\n",
        "num_epochs = 10\n",
        "num_timesteps = model.num_timesteps\n",
        "learning_rate = 1e-3\n",
        "truck_model.train()\n",
        "optimizer = torch.optim.Adam(truck_model.parameters(), lr=learning_rate)\n",
        "training_loop(truck_model, truck_dataloader, optimizer, num_epochs, num_timesteps, device=device)\n",
        "generated, generated_mid = generate_image(truck_model, 100, 3, 32)\n",
        "show_images(generated, \"Generated trucks\")"
      ],
      "metadata": {
        "id": "pK-mmfz0jOkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Denoising Diffusion Probabilistic Models for MNIST"
      ],
      "metadata": {
        "id": "99EpQVAqj5Ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(images, title=\"\"):\n",
        "    \"\"\"Shows the provided images as sub-pictures in a square\"\"\"\n",
        "    images = [im.permute(1,2,0).numpy() for im in images]\n",
        "\n",
        "    # defining number of rows and columns\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    rows = int(len(images) ** (1 / 2))\n",
        "    cols = round(len(images) / rows)\n",
        "\n",
        "    # populating figure with sub-plots\n",
        "    idx = 0\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            fig.add_subplot(rows, cols, idx + 1)\n",
        "\n",
        "            if idx < len(images):\n",
        "                plt.imshow(images[idx], cmap=\"gray\")\n",
        "                plt.axis('off')\n",
        "                idx += 1\n",
        "    fig.suptitle(title, fontsize=30)\n",
        "    plt.show()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def sinusoidal_embedding(n, d):\n",
        "    # returns the standard positional embedding\n",
        "    embedding = torch.tensor([[i / 10_000 ** (2 * j / d) for j in range(d)] for i in range(n)])\n",
        "    sin_mask = torch.arange(0, n, 2)\n",
        "\n",
        "    embedding[sin_mask] = torch.sin(embedding[sin_mask])\n",
        "    embedding[1 - sin_mask] = torch.cos(embedding[sin_mask])\n",
        "\n",
        "    return embedding\n",
        "\n",
        "class MyConv(nn.Module):\n",
        "    def __init__(self, shape, in_c, out_c, kernel_size=3, stride=1, padding=1, activation=None, normalize=True):\n",
        "        super(MyConv, self).__init__()\n",
        "        self.ln = nn.LayerNorm(shape)\n",
        "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size, stride, padding)\n",
        "        self.activation = nn.SiLU() if activation is None else activation\n",
        "        self.normalize = normalize\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.ln(x) if self.normalize else x\n",
        "        out = self.conv1(out)\n",
        "        out = self.activation(out)\n",
        "        return out\n",
        "\n",
        "def MyTinyBlock(size, in_c, out_c):\n",
        "    return nn.Sequential(MyConv((in_c, size, size), in_c, out_c),\n",
        "                         MyConv((out_c, size, size), out_c, out_c),\n",
        "                         MyConv((out_c, size, size), out_c, out_c))\n",
        "\n",
        "def MyTinyUp(size, in_c):\n",
        "    return nn.Sequential(MyConv((in_c, size, size), in_c, in_c//2),\n",
        "                         MyConv((in_c//2, size, size), in_c//2, in_c//4),\n",
        "                         MyConv((in_c//4, size, size), in_c//4, in_c//4))\n",
        "\n",
        "class MyTinyUNet(nn.Module):\n",
        "  # a network with 3 down and 3 up with the tiny block\n",
        "    def __init__(self, in_c=1, out_c=1, size=32, n_steps=1000, time_emb_dim=100):\n",
        "        super(MyTinyUNet, self).__init__()\n",
        "\n",
        "        # sinusoidal embedding\n",
        "        self.time_embed = nn.Embedding(n_steps, time_emb_dim)\n",
        "        self.time_embed.weight.data = sinusoidal_embedding(n_steps, time_emb_dim)\n",
        "        self.time_embed.requires_grad_(False)\n",
        "\n",
        "        # first half\n",
        "        self.te1 = self._make_te(time_emb_dim, 1)\n",
        "        self.b1 = MyTinyBlock(size, in_c, 10)\n",
        "        self.down1 = nn.Conv2d(10, 10, 4, 2, 1)\n",
        "        self.te2 = self._make_te(time_emb_dim, 10)\n",
        "        self.b2 = MyTinyBlock(size//2, 10, 20)\n",
        "        self.down2 = nn.Conv2d(20, 20, 4, 2, 1)\n",
        "        self.te3 = self._make_te(time_emb_dim, 20)\n",
        "        self.b3 = MyTinyBlock(size//4, 20, 40)\n",
        "        self.down3 = nn.Conv2d(40, 40, 4, 2, 1)\n",
        "\n",
        "        # bottleneck\n",
        "        self.te_mid = self._make_te(time_emb_dim, 40)\n",
        "        self.b_mid = nn.Sequential(\n",
        "            MyConv((40, size//8, size//8), 40, 20),\n",
        "            MyConv((20, size//8, size//8), 20, 20),\n",
        "            MyConv((20, size//8, size//8), 20, 40)\n",
        "        )\n",
        "\n",
        "        # second half\n",
        "        self.up1 = nn.ConvTranspose2d(40, 40, 4, 2, 1)\n",
        "        self.te4 = self._make_te(time_emb_dim, 80)\n",
        "        self.b4 = MyTinyUp(size//4, 80)\n",
        "        self.up2 = nn.ConvTranspose2d(20, 20, 4, 2, 1)\n",
        "        self.te5 = self._make_te(time_emb_dim, 40)\n",
        "        self.b5 = MyTinyUp(size//2, 40)\n",
        "        self.up3 = nn.ConvTranspose2d(10, 10, 4, 2, 1)\n",
        "        self.te_out = self._make_te(time_emb_dim, 20)\n",
        "        self.b_out = MyTinyBlock(size, 20, 10)\n",
        "        self.conv_out = nn.Conv2d(10, out_c, 3, 1, 1)\n",
        "\n",
        "    def forward(self, x, t): # x is (bs, in_c, size, size) t is (bs)\n",
        "        t = self.time_embed(t)\n",
        "        n = len(x)\n",
        "        out1 = self.b1(x + self.te1(t).reshape(n, -1, 1, 1))  # (bs, 10, size/2, size/2)\n",
        "        out2 = self.b2(self.down1(out1) + self.te2(t).reshape(n, -1, 1, 1))  # (bs, 20, size/4, size/4)\n",
        "        out3 = self.b3(self.down2(out2) + self.te3(t).reshape(n, -1, 1, 1))  # (bs, 40, size/8, size/8)\n",
        "\n",
        "        out_mid = self.b_mid(self.down3(out3) + self.te_mid(t).reshape(n, -1, 1, 1))  # (bs, 40, size/8, size/8)\n",
        "\n",
        "        out4 = torch.cat((out3, self.up1(out_mid)), dim=1)  # (bs, 80, size/8, size/8)\n",
        "        out4 = self.b4(out4 + self.te4(t).reshape(n, -1, 1, 1))  # (bs, 20, size/8, size/8)\n",
        "        out5 = torch.cat((out2, self.up2(out4)), dim=1)  # (bs, 40, size/4, size/4)\n",
        "        out5 = self.b5(out5 + self.te5(t).reshape(n, -1, 1, 1))  # (bs, 10, size/2, size/2)\n",
        "        out = torch.cat((out1, self.up3(out5)), dim=1)  # (bs, 20, size, size)\n",
        "        out = self.b_out(out + self.te_out(t).reshape(n, -1, 1, 1))  # (bs, 10, size, size)\n",
        "        out = self.conv_out(out) # (bs, out_c, size, size)\n",
        "        return out\n",
        "\n",
        "    def _make_te(self, dim_in, dim_out):\n",
        "        return nn.Sequential(nn.Linear(dim_in, dim_out), nn.SiLU(), nn.Linear(dim_out, dim_out))\n",
        "\n",
        "bs = 3\n",
        "x = torch.randn(bs,1,32,32)\n",
        "n_steps=1000\n",
        "timesteps = torch.randint(0, n_steps, (bs,)).long()\n",
        "unet = MyTinyUNet(in_c =1, out_c =1, size=32)\n",
        "\n",
        "y = unet(x,timesteps)\n",
        "y.shape\n",
        "\n",
        "class DDPM(nn.Module):\n",
        "    def __init__(self, network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device) -> None:\n",
        "        super(DDPM, self).__init__()\n",
        "        self.num_timesteps = num_timesteps\n",
        "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps, dtype=torch.float32).to(device)\n",
        "        self.alphas = 1.0 - self.betas\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
        "        self.network = network\n",
        "        self.device = device\n",
        "        self.sqrt_alphas_cumprod = self.alphas_cumprod ** 0.5 # used in add_noise\n",
        "        self.sqrt_one_minus_alphas_cumprod = (1 - self.alphas_cumprod) ** 0.5 # used in add_noise and step\n",
        "\n",
        "    def add_noise(self, x_start, x_noise, timesteps):\n",
        "        # the forward process\n",
        "        # x_start and x_noise (bs, n_c, w, d)\n",
        "        # timesteps (bs)\n",
        "        s1 = self.sqrt_alphas_cumprod[timesteps] # bs\n",
        "        s2 = self.sqrt_one_minus_alphas_cumprod[timesteps] # bs\n",
        "        s1 = s1.reshape(-1,1,1,1) # (bs, 1, 1, 1) for broadcasting\n",
        "        s2 = s2.reshape(-1,1,1,1) # (bs, 1, 1, 1)\n",
        "        return s1 * x_start + s2 * x_noise\n",
        "\n",
        "    def reverse(self, x, t):\n",
        "        # the network return the estimation of the noise we added\n",
        "        return self.network(x, t)\n",
        "\n",
        "    def step(self, model_output, timestep, sample):\n",
        "        # one step of sampling\n",
        "        # timestep (1)\n",
        "        t = timestep\n",
        "        coef_epsilon = (1-self.alphas)/self.sqrt_one_minus_alphas_cumprod\n",
        "        coef_eps_t = coef_epsilon[t].reshape(-1,1,1,1)\n",
        "        coef_first = 1/self.alphas ** 0.5\n",
        "        coef_first_t = coef_first[t].reshape(-1,1,1,1)\n",
        "        pred_prev_sample = coef_first_t*(sample-coef_eps_t*model_output)\n",
        "\n",
        "        variance = 0\n",
        "        if t > 0:\n",
        "            noise = torch.randn_like(model_output).to(self.device)\n",
        "            variance = ((self.betas[t] ** 0.5) * noise)\n",
        "\n",
        "        pred_prev_sample = pred_prev_sample + variance\n",
        "\n",
        "        return pred_prev_sample\n",
        "\n",
        "num_timesteps = 1000\n",
        "betas = torch.linspace(0.0001, 0.02, num_timesteps, dtype=torch.float32).to(device)\n",
        "\n",
        "betas[timesteps]\n",
        "\n",
        "betas[10]\n",
        "\n",
        "betas[timesteps].reshape(-1,1,1,1).shape\n",
        "\n",
        "network = MyTinyUNet(in_c =1, out_c =1, size=32)\n",
        "model = DDPM(network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device)\n",
        "\n",
        "bs = 5\n",
        "x = torch.randn(bs,1,32,32).to(device)\n",
        "timesteps = 10*torch.ones(bs,).long().long().to(device)\n",
        "\n",
        "timesteps.shape\n",
        "\n",
        "y = model.add_noise(x,x,timesteps)\n",
        "y.shape\n",
        "\n",
        "y = model.step(x,timesteps[0],x)\n",
        "y.shape\n",
        "\n",
        "You can check that all the parameters of the UNet network are indeed parameters of the DDPM model like this:\n",
        "\n",
        "for n, p in model.named_parameters():\n",
        "    print(n, p.shape)\n",
        "\n",
        "def training_loop(model, dataloader, optimizer, num_epochs, num_timesteps, device=device):\n",
        "    \"\"\"Training loop for DDPM\"\"\"\n",
        "\n",
        "    global_step = 0\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        progress_bar = tqdm(total=len(dataloader))\n",
        "        progress_bar.set_description(f\"Epoch {epoch}\")\n",
        "        for step, batch in enumerate(dataloader):\n",
        "            batch = batch[0].to(device)\n",
        "            noise = torch.randn(batch.shape).to(device)\n",
        "            timesteps = torch.randint(0, num_timesteps, (batch.shape[0],)).long().to(device)\n",
        "\n",
        "            noisy = model.add_noise(batch, noise, timesteps)\n",
        "            noise_pred = model.reverse(noisy, timesteps)\n",
        "            loss = F.mse_loss(noise_pred, noise)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            progress_bar.update(1)\n",
        "            logs = {\"loss\": loss.detach().item(), \"step\": global_step}\n",
        "            losses.append(loss.detach().item())\n",
        "            progress_bar.set_postfix(**logs)\n",
        "            global_step += 1\n",
        "\n",
        "        progress_bar.close()\n",
        "\n",
        "root_dir = './data/'\n",
        "transform01 = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize(32),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize((0.5), (0.5))\n",
        "    ])\n",
        "dataset = torchvision.datasets.MNIST(root=root_dir, train=True, transform=transform01, download=True)\n",
        "dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=4096, shuffle=True, num_workers=10)\n",
        "\n",
        "for b in dataloader:\n",
        "    batch = b[0]\n",
        "    break\n",
        "\n",
        "bn = [b for b in batch[:100]]\n",
        "show_images(bn, \"origin\")\n",
        "\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 50\n",
        "num_timesteps = 1000\n",
        "network = MyTinyUNet()\n",
        "network = network.to(device)\n",
        "model = DDPM(network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device)\n",
        "optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
        "training_loop(model, dataloader, optimizer, num_epochs, num_timesteps, device=device)\n",
        "\n",
        "def generate_image(ddpm, sample_size, channel, size):\n",
        "    \"\"\"Generate the image from the Gaussian noise\"\"\"\n",
        "\n",
        "    frames = []\n",
        "    frames_mid = []\n",
        "    ddpm.eval()\n",
        "    with torch.no_grad():\n",
        "        timesteps = list(range(ddpm.num_timesteps))[::-1]\n",
        "        sample = torch.randn(sample_size, channel, size, size).to(device)\n",
        "\n",
        "        for i, t in enumerate(tqdm(timesteps)):\n",
        "            time_tensor = (torch.ones(sample_size,1) * t).long().to(device)\n",
        "            residual = ddpm.reverse(sample, time_tensor)\n",
        "            sample = ddpm.step(residual, time_tensor[0], sample)\n",
        "\n",
        "            if t==500:\n",
        "                for i in range(sample_size):\n",
        "                    frames_mid.append(sample[i].detach().cpu())\n",
        "\n",
        "        for i in range(sample_size):\n",
        "            frames.append(sample[i].detach().cpu())\n",
        "    return frames, frames_mid\n",
        "\n",
        "generated, generated_mid = generate_image(model, 100, 1, 32)\n",
        "\n",
        "show_images(generated_mid, \"Mid result\")\n",
        "show_images(generated, \"Final result\")\n",
        "\n",
        "def rescale(x):\n",
        "    return (x+1)/2\n",
        "\n",
        "def show_images_rescale(images, title=\"\"):\n",
        "    \"\"\"Shows the provided images as sub-pictures in a square\"\"\"\n",
        "    images = [rescale((im.permute(1,2,0)).numpy()) for im in images]\n",
        "\n",
        "    # defining number of rows and columns\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    rows = int(len(images) ** (1 / 2))\n",
        "    cols = round(len(images) / rows)\n",
        "\n",
        "    # populating figure with sub-plots\n",
        "    idx = 0\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            fig.add_subplot(rows, cols, idx + 1)\n",
        "\n",
        "            if idx < len(images):\n",
        "                # plt.imshow(images[idx].reshape(pixel, pixel, n_channels), cmap=\"gray\")\n",
        "                plt.imshow(images[idx])\n",
        "                plt.axis('off')\n",
        "                idx += 1\n",
        "    fig.suptitle(title, fontsize=30)\n",
        "    plt.show()\n",
        "\n",
        "show_images_rescale(generated, \"Final result\")"
      ],
      "metadata": {
        "id": "SzIGWpjtjOnW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}