{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "Lbsu9SaE4ozu",
        "j1TFIA5TETnh",
        "6x1DDRElr4B9",
        "PMrXDjBuslmw",
        "8cJ_J0icxplt",
        "PbKOG5XuNeO2",
        "1i8RMJYbRgjW",
        "wxpuoCBvRhK2"
      ],
      "authorship_tag": "ABX9TyPAKN+4s7ICbeLhGJQ7lg9m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ariahosseini/DeepML/blob/main/013_TensorFlow_Proj_Thirteen_GNN_Spektral_NodeLevel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install\n",
        "!pip install spektral\n",
        "!pip install ogb"
      ],
      "metadata": {
        "id": "hFna3sxRN1ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utils\n",
        "import numpy as np\n",
        "from ogb.nodeproppred import Evaluator, NodePropPredDataset\n",
        "# tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout, Input, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_accuracy\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.random import set_seed\n",
        "# spektral\n",
        "from spektral.data.loaders import SingleLoader\n",
        "from spektral.datasets.citation import Citation, Cora\n",
        "from spektral.datasets.ogb import OGB\n",
        "from spektral.layers import GCNConv, ChebConv, GATConv, ARMAConv\n",
        "from spektral.models.gcn import GCN\n",
        "from spektral.transforms import LayerPreprocess, AdjToSpTensor, GCNFilter\n",
        "from spektral.utils import tic, toc\n",
        "# vis\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "92pfaQgy1bAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Citation Data Using GCN"
      ],
      "metadata": {
        "id": "Lbsu9SaE4ozu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# params\n",
        "learning_rate = 1e-2\n",
        "seed = 0\n",
        "epochs = 200\n",
        "patience = 10\n",
        "data = \"cora\""
      ],
      "metadata": {
        "id": "1X28Mw8S1g8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(seed=seed)"
      ],
      "metadata": {
        "id": "jXA1j78E5eJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "dataset = Citation(data, normalize_x=True, transforms=[LayerPreprocess(GCNConv)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8cloLmUhq8R",
        "outputId": "a343c77a-d029-4acf-a96a-970870c64b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-processing node features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Data set name: {dataset.name}\")\n",
        "print(f\"Data set type: {type(dataset)}\")\n",
        "print(f\"No. of graphs: {dataset.n_graphs}\")\n",
        "print(f\"No. of nodes: {dataset.n_nodes}\")\n",
        "print(f\"No. of classes: {dataset.n_labels}\")\n",
        "print(f\"No. of edge features: {dataset.n_edge_features}\")\n",
        "print(f\"No. of node features: {dataset.n_node_features}\")\n",
        "print(f\"Recap: {dataset.graphs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "Oonq0o13Z2lb",
        "outputId": "3ff7ac8f-be3f-4bd5-ccd9-710aff7d1203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c2152cbc7c80>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data set name: {dataset.name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data set type: {type(dataset)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No. of graphs: {dataset.n_graphs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No. of nodes: {dataset.n_nodes}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No. of classes: {dataset.n_labels}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Graph nodes' features:\\n{dataset[0].x}\")\n",
        "print(f\"Graph nodes' size:\\n{np.shape(dataset[0].x)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpVPRzAPe_Np",
        "outputId": "d3fd908d-50fc-4b84-e804-1a27a2b598b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph nodes' features:\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "Graph nodes' size:\n",
            "(2708, 1433)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Graph edges' features:\\n{dataset[0].e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxPmEYUwcKxe",
        "outputId": "501aa832-2d99-43a1-da68-f7bbc4311366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph edges' features:\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Graph adjacency matrix:\\n{dataset[0].a}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcrCJ6uJdQYU",
        "outputId": "693554d0-25e3-48ea-ba29-73587d862c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph adjacency matrix:\n",
            "  (0, 0)\t0.25\n",
            "  (0, 633)\t0.25\n",
            "  (0, 1862)\t0.2236068\n",
            "  (0, 2582)\t0.25\n",
            "  (1, 1)\t0.25\n",
            "  (1, 2)\t0.20412415\n",
            "  (1, 652)\t0.28867513\n",
            "  (1, 654)\t0.35355338\n",
            "  (2, 1)\t0.20412415\n",
            "  (2, 2)\t0.16666667\n",
            "  (2, 332)\t0.16666667\n",
            "  (2, 1454)\t0.28867513\n",
            "  (2, 1666)\t0.15430336\n",
            "  (2, 1986)\t0.05025189\n",
            "  (3, 3)\t0.49999997\n",
            "  (3, 2544)\t0.49999997\n",
            "  (4, 4)\t0.16666667\n",
            "  (4, 1016)\t0.16666667\n",
            "  (4, 1256)\t0.13608277\n",
            "  (4, 1761)\t0.14433756\n",
            "  (4, 2175)\t0.16666667\n",
            "  (4, 2176)\t0.13608277\n",
            "  (5, 5)\t0.25\n",
            "  (5, 1629)\t0.25\n",
            "  (5, 1659)\t0.28867513\n",
            "  :\t:\n",
            "  (2699, 2699)\t0.49999997\n",
            "  (2700, 1151)\t0.40824828\n",
            "  (2700, 2700)\t0.49999997\n",
            "  (2701, 44)\t0.28867513\n",
            "  (2701, 2624)\t0.3333333\n",
            "  (2701, 2701)\t0.3333333\n",
            "  (2702, 186)\t0.21821788\n",
            "  (2702, 1536)\t0.2581989\n",
            "  (2702, 2702)\t0.3333333\n",
            "  (2703, 1298)\t0.49999997\n",
            "  (2703, 2703)\t0.49999997\n",
            "  (2704, 641)\t0.49999997\n",
            "  (2704, 2704)\t0.49999997\n",
            "  (2705, 287)\t0.49999997\n",
            "  (2705, 2705)\t0.49999997\n",
            "  (2706, 165)\t0.19999999\n",
            "  (2706, 169)\t0.2581989\n",
            "  (2706, 1473)\t0.19999999\n",
            "  (2706, 2706)\t0.19999999\n",
            "  (2706, 2707)\t0.19999999\n",
            "  (2707, 165)\t0.19999999\n",
            "  (2707, 598)\t0.07669649\n",
            "  (2707, 1473)\t0.19999999\n",
            "  (2707, 2706)\t0.19999999\n",
            "  (2707, 2707)\t0.19999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Graph labels:\\n{dataset[0].y}\")\n",
        "print(f\"Graph labels size:\\n{np.shape(dataset[0].y)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TwkN6_rgP-3",
        "outputId": "f96c0be1-d657-4610-89f8-ab43cd80a9f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph labels:\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "Graph labels size:\n",
            "(2708, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the binary masks to sample weights so that one can compute the average loss over the nodes (following original implementation by Kipf & Welling)\n",
        "def mask_to_weights(mask):\n",
        "    return mask.astype(np.float32) / np.count_nonzero(mask)\n",
        "weights_tr, weights_va, weights_te = (mask_to_weights(mask) for mask in (dataset.mask_tr, dataset.mask_va, dataset.mask_te))"
      ],
      "metadata": {
        "id": "5nQCUPnBEvPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(n_labels=dataset.n_labels, channels=16, activation='relu',\n",
        "            output_activation='softmax', use_bias=False,\n",
        "            dropout_rate=0.5, l2_reg=0.00025)\n",
        "model.compile(optimizer=Adam(learning_rate),\n",
        "              loss=CategoricalCrossentropy(reduction=\"sum\"),\n",
        "              weighted_metrics=[\"acc\"])"
      ],
      "metadata": {
        "id": "LdNNXDXT5eVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "loader_tr = SingleLoader(dataset, sample_weights=weights_tr)\n",
        "loader_va = SingleLoader(dataset, sample_weights=weights_va)\n",
        "model.fit(\n",
        "    loader_tr.load(),\n",
        "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
        "    validation_data=loader_va.load(),\n",
        "    validation_steps=loader_va.steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)],\n",
        "    verbose=0\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq6V5Gst5eYu",
        "outputId": "c5ec1c2a-fac1-4a76-c55e-bdaa3c5e8962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fdc39f025c0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D03Af5KU4wTH",
        "outputId": "01f3e997-bc05-49d2-b2ba-2bb4ddef094e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"gcn_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout_2 (Dropout)         multiple                  0         \n",
            "                                                                 \n",
            " gcn_conv_2 (GCNConv)        multiple                  22928     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         multiple                  0         \n",
            "                                                                 \n",
            " gcn_conv_3 (GCNConv)        multiple                  112       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23040 (90.00 KB)\n",
            "Trainable params: 23040 (90.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "print(\"Evaluating model.\")\n",
        "loader_va = SingleLoader(dataset, sample_weights=weights_va)\n",
        "eval_results = model.evaluate(loader_va.load(), steps=loader_va.steps_per_epoch)\n",
        "print(\"Done.\\n\" \"Val loss: {}\\n\" \"Val accuracy: {}\".format(*eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMcOPdCu6Nw0",
        "outputId": "ed5019ed-92b3-4272-c8f5-3a7df43db47d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model.\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.0540 - acc: 0.7880\n",
            "Done.\n",
            "Val loss: 1.0539989471435547\n",
            "Val accuracy: 0.7879999876022339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pred\n",
        "print(\"Prediction.\")\n",
        "loader_te = SingleLoader(dataset, sample_weights=weights_te)\n",
        "eval_results = model.predict(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
        "output = [np.argmax(_) for _ in eval_results]\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjnrdzCS84Sr",
        "outputId": "22a7b1c6-d831-4a58-8857-52d2ad898682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "[3, 4, 4, 0, 3, 2, 0, 3, 3, 2, 0, 0, 4, 3, 3, 3, 2, 3, 1, 3, 5, 3, 4, 6, 3, 3, 6, 3, 2, 4, 3, 6, 0, 4, 2, 0, 1, 5, 4, 4, 3, 6, 6, 4, 3, 3, 2, 5, 3, 4, 5, 3, 0, 2, 1, 4, 6, 3, 2, 2, 0, 0, 0, 4, 2, 0, 4, 5, 2, 6, 5, 2, 2, 2, 0, 4, 5, 6, 4, 0, 0, 0, 4, 2, 4, 1, 4, 6, 0, 4, 2, 4, 6, 6, 0, 0, 6, 5, 0, 6, 0, 2, 1, 1, 1, 2, 6, 5, 6, 1, 2, 2, 1, 5, 5, 5, 6, 5, 6, 5, 5, 1, 6, 6, 1, 5, 1, 6, 5, 5, 5, 1, 5, 1, 1, 1, 1, 1, 1, 1, 4, 4, 0, 3, 6, 6, 0, 6, 4, 0, 3, 4, 4, 1, 2, 2, 2, 3, 3, 3, 3, 6, 0, 5, 0, 3, 4, 0, 0, 3, 2, 3, 4, 2, 2, 6, 1, 4, 3, 3, 3, 6, 3, 3, 1, 3, 3, 4, 2, 2, 6, 1, 2, 5, 4, 0, 4, 3, 4, 4, 3, 3, 2, 4, 0, 3, 2, 3, 3, 4, 3, 0, 3, 6, 0, 3, 3, 4, 3, 3, 5, 2, 1, 2, 3, 6, 3, 2, 2, 3, 3, 3, 3, 5, 1, 3, 1, 3, 5, 0, 4, 5, 0, 4, 2, 4, 2, 4, 4, 5, 1, 3, 6, 3, 4, 6, 4, 0, 4, 5, 2, 3, 6, 2, 5, 5, 0, 2, 2, 3, 0, 4, 0, 3, 0, 4, 0, 0, 4, 0, 6, 3, 5, 4, 4, 6, 4, 1, 3, 2, 2, 4, 3, 4, 1, 3, 2, 3, 3, 4, 0, 2, 1, 1, 0, 0, 1, 6, 1, 4, 3, 3, 2, 3, 1, 0, 3, 1, 1, 2, 3, 3, 2, 0, 0, 0, 2, 3, 2, 1, 4, 6, 4, 2, 0, 3, 3, 2, 3, 4, 4, 2, 1, 3, 5, 3, 2, 0, 4, 5, 1, 3, 3, 2, 6, 2, 0, 2, 2, 2, 5, 4, 4, 2, 2, 2, 3, 2, 4, 4, 5, 5, 1, 0, 3, 4, 5, 4, 4, 5, 2, 4, 3, 4, 1, 4, 3, 3, 6, 2, 3, 2, 5, 5, 4, 3, 3, 1, 0, 1, 5, 1, 3, 2, 5, 0, 1, 3, 0, 1, 5, 3, 6, 3, 6, 0, 3, 1, 3, 5, 4, 3, 4, 0, 5, 2, 1, 2, 4, 4, 4, 4, 3, 4, 0, 3, 5, 0, 4, 2, 0, 5, 4, 4, 4, 3, 6, 6, 5, 2, 4, 5, 1, 3, 6, 3, 0, 3, 5, 1, 3, 0, 2, 4, 2, 0, 2, 0, 5, 3, 4, 0, 5, 4, 1, 0, 0, 2, 5, 5, 3, 3, 3, 5, 1, 0, 3, 1, 4, 2, 0, 6, 4, 2, 2, 6, 6, 0, 0, 6, 3, 2, 6, 4, 0, 1, 0, 3, 1, 3, 3, 3, 4, 2, 5, 4, 0, 0, 0, 1, 1, 3, 0, 4, 2, 0, 2, 0, 5, 4, 1, 3, 3, 2, 2, 2, 2, 6, 4, 6, 5, 5, 1, 0, 0, 4, 3, 3, 1, 3, 6, 6, 2, 6, 1, 0, 1, 2, 2, 5, 4, 3, 2, 1, 2, 2, 3, 2, 3, 2, 3, 0, 0, 1, 4, 3, 4, 3, 0, 3, 2, 1, 4, 4, 4, 4, 0, 5, 4, 1, 5, 2, 0, 0, 6, 3, 6, 0, 3, 3, 0, 3, 4, 3, 6, 3, 3, 3, 1, 2, 5, 3, 5, 2, 2, 2, 2, 4, 3, 0, 3, 5, 3, 4, 0, 3, 2, 4, 2, 2, 5, 2, 2, 3, 5, 2, 0, 3, 4, 3, 3, 2, 0, 5, 6, 6, 5, 5, 5, 3, 2, 0, 4, 3, 4, 1, 1, 2, 3, 6, 1, 5, 6, 6, 3, 4, 0, 0, 5, 3, 2, 5, 2, 3, 4, 0, 5, 5, 4, 0, 1, 3, 5, 1, 2, 1, 2, 2, 4, 2, 3, 4, 3, 0, 5, 3, 0, 3, 4, 1, 3, 5, 0, 5, 2, 4, 4, 0, 3, 5, 3, 6, 6, 3, 4, 4, 3, 3, 0, 1, 5, 2, 3, 2, 3, 0, 4, 3, 6, 3, 0, 0, 2, 4, 0, 5, 0, 5, 3, 5, 4, 1, 2, 3, 2, 3, 3, 5, 2, 0, 5, 0, 2, 5, 2, 0, 4, 2, 2, 4, 3, 4, 2, 0, 2, 3, 3, 1, 2, 0, 3, 0, 5, 1, 4, 3, 3, 0, 6, 6, 3, 3, 4, 4, 3, 3, 4, 4, 3, 4, 3, 4, 3, 5, 4, 3, 2, 2, 5, 3, 2, 5, 1, 6, 4, 4, 2, 5, 4, 0, 4, 3, 3, 4, 4, 0, 5, 2, 0, 2, 2, 1, 0, 2, 2, 2, 5, 0, 4, 1, 6, 1, 0, 3, 1, 3, 3, 4, 0, 0, 5, 3, 6, 1, 5, 3, 3, 6, 2, 3, 6, 0, 1, 2, 5, 3, 4, 4, 0, 2, 2, 0, 4, 4, 1, 4, 3, 2, 0, 3, 3, 2, 0, 1, 3, 3, 2, 3, 5, 4, 0, 2, 2, 2, 4, 5, 3, 1, 0, 2, 5, 6, 3, 4, 3, 0, 0, 0, 6, 3, 3, 0, 2, 6, 5, 2, 4, 6, 0, 3, 1, 4, 4, 5, 3, 2, 3, 6, 3, 2, 3, 6, 4, 3, 4, 5, 3, 3, 3, 2, 2, 3, 6, 2, 0, 5, 2, 1, 3, 1, 5, 6, 3, 1, 3, 6, 4, 4, 3, 4, 6, 2, 2, 3, 4, 6, 4, 2, 1, 3, 3, 3, 3, 4, 0, 0, 0, 3, 3, 2, 2, 5, 3, 5, 6, 0, 2, 2, 2, 3, 1, 3, 3, 4, 4, 2, 3, 3, 3, 6, 3, 6, 6, 0, 3, 0, 4, 3, 2, 2, 3, 4, 3, 2, 2, 3, 0, 2, 0, 1, 4, 1, 4, 0, 3, 4, 3, 0, 4, 3, 3, 3, 5, 3, 3, 0, 3, 0, 5, 6, 2, 3, 5, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 3, 3, 1, 4, 0, 2, 3, 4, 4, 3, 3, 3, 3, 0, 3, 0, 4, 5, 4, 3, 4, 4, 1, 3, 2, 4, 0, 5, 4, 1, 3, 6, 3, 6, 2, 2, 0, 3, 4, 4, 3, 3, 6, 3, 4, 1, 1, 3, 3, 3, 3, 4, 3, 1, 4, 3, 3, 3, 3, 4, 2, 0, 0, 3, 3, 3, 4, 0, 3, 4, 5, 2, 4, 3, 0, 0, 3, 0, 3, 5, 2, 3, 0, 3, 3, 5, 4, 3, 0, 3, 5, 3, 4, 2, 0, 4, 0, 0, 4, 5, 4, 1, 2, 1, 3, 2, 2, 2, 3, 0, 4, 2, 2, 0, 4, 1, 3, 4, 2, 4, 6, 2, 6, 3, 5, 5, 2, 5, 3, 0, 2, 0, 3, 3, 3, 0, 5, 1, 1, 5, 5, 5, 3, 3, 0, 0, 2, 5, 3, 4, 1, 4, 0, 1, 1, 0, 2, 3, 3, 4, 0, 0, 2, 4, 4, 4, 2, 2, 4, 3, 3, 2, 0, 2, 3, 0, 4, 0, 3, 5, 3, 0, 3, 5, 5, 3, 2, 4, 3, 0, 1, 4, 3, 6, 5, 2, 0, 4, 3, 3, 2, 0, 1, 3, 3, 1, 1, 2, 1, 1, 1, 2, 4, 3, 4, 1, 0, 4, 4, 2, 2, 4, 4, 4, 5, 0, 5, 3, 3, 3, 3, 0, 0, 5, 3, 3, 0, 2, 2, 1, 1, 2, 0, 4, 2, 0, 1, 3, 0, 2, 0, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 1, 2, 2, 4, 2, 0, 6, 5, 5, 5, 5, 3, 3, 2, 4, 3, 4, 3, 4, 3, 4, 3, 3, 6, 6, 4, 0, 3, 5, 0, 3, 1, 4, 1, 0, 2, 0, 0, 4, 6, 3, 2, 1, 3, 3, 4, 4, 6, 0, 5, 5, 3, 3, 0, 2, 6, 5, 2, 6, 3, 3, 4, 4, 1, 0, 4, 6, 3, 6, 2, 0, 6, 0, 0, 2, 4, 4, 5, 3, 2, 2, 4, 3, 5, 0, 2, 4, 0, 3, 3, 0, 0, 6, 0, 2, 6, 3, 4, 6, 3, 5, 3, 4, 2, 5, 5, 0, 1, 2, 3, 5, 5, 0, 4, 4, 4, 6, 6, 4, 4, 4, 4, 3, 2, 4, 4, 2, 2, 3, 3, 3, 0, 4, 2, 1, 3, 3, 5, 3, 4, 2, 3, 3, 3, 1, 4, 3, 4, 4, 3, 4, 5, 3, 3, 3, 1, 3, 4, 3, 0, 6, 3, 2, 0, 0, 4, 5, 2, 4, 3, 4, 2, 5, 3, 5, 3, 2, 4, 6, 2, 4, 6, 2, 6, 3, 2, 1, 4, 2, 4, 0, 6, 6, 3, 1, 2, 5, 6, 3, 3, 6, 1, 1, 6, 3, 2, 4, 0, 1, 3, 4, 0, 2, 0, 4, 4, 2, 0, 4, 0, 0, 6, 0, 0, 2, 4, 4, 4, 4, 4, 4, 6, 3, 5, 5, 6, 0, 3, 3, 5, 2, 4, 2, 1, 3, 5, 2, 1, 1, 5, 3, 5, 0, 2, 3, 4, 1, 1, 2, 3, 1, 2, 2, 3, 2, 4, 3, 1, 1, 3, 3, 4, 3, 3, 5, 5, 0, 3, 3, 6, 1, 4, 2, 0, 0, 2, 4, 3, 6, 6, 6, 3, 2, 3, 3, 2, 4, 2, 0, 3, 2, 3, 2, 3, 3, 1, 2, 4, 2, 3, 3, 3, 6, 6, 4, 5, 2, 4, 1, 1, 1, 0, 4, 2, 0, 2, 5, 0, 2, 3, 4, 0, 3, 0, 1, 4, 1, 3, 2, 4, 0, 6, 2, 6, 2, 0, 5, 1, 0, 4, 3, 0, 1, 3, 0, 2, 0, 0, 3, 3, 3, 3, 3, 4, 2, 4, 1, 3, 0, 0, 6, 6, 6, 0, 3, 3, 0, 1, 3, 6, 3, 2, 4, 2, 4, 2, 6, 3, 4, 0, 2, 0, 0, 3, 6, 1, 5, 3, 4, 4, 3, 1, 2, 5, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 6, 5, 5, 4, 0, 1, 1, 3, 1, 1, 1, 6, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 2, 2, 2, 2, 2, 6, 6, 3, 0, 0, 0, 0, 5, 0, 0, 0, 3, 0, 0, 6, 0, 6, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 4, 4, 4, 4, 4, 3, 2, 5, 5, 5, 5, 6, 5, 5, 5, 5, 3, 4, 3, 0, 3, 1, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 5, 6, 6, 0, 5, 5, 5, 0, 5, 4, 4, 0, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 1, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 6, 3, 0, 0, 0, 0, 0, 5, 5, 5, 4, 0, 6, 6, 0, 0, 1, 3, 6, 5, 6, 6, 4, 4, 4, 4, 3, 3, 4, 4, 4, 3, 4, 4, 4, 1, 1, 1, 1, 0, 6, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 5, 5, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 0, 0, 0, 6, 6, 0, 0, 0, 0, 1, 1, 0, 6, 6, 6, 6, 2, 3, 3, 0, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 0, 6, 0, 6, 6, 0, 0, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 2, 6, 3, 0, 0, 0, 0, 6, 6, 6, 6, 6, 3, 3, 6, 6, 6, 1, 2, 1, 0, 0, 0, 1, 1, 3, 3, 6, 0, 0, 0, 0, 0, 0, 5, 5, 0, 4, 0, 0, 6, 3, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 6, 1, 0, 3, 3, 3, 3, 3, 6, 1, 0, 2, 2, 4, 4, 4, 4, 4, 5, 6, 3, 3, 4, 0, 0, 0, 5, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 1, 1, 3, 1, 6, 1, 1, 3, 4, 4, 4, 4, 0, 0, 4, 0, 0, 4, 5, 5, 5, 5, 5, 5, 5, 0, 0, 6, 2, 0, 5, 6, 3, 5, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4, 0, 3, 0, 4, 0, 1, 4, 4, 3, 3, 3, 3, 2, 3, 3, 3, 0, 0, 1, 1, 3, 6, 3, 1, 3, 3, 0, 1, 5, 1, 1, 5, 1, 1, 1, 0, 1, 0, 0, 2, 4, 4, 4, 3, 1, 3, 3, 0, 3, 3, 4, 4, 0, 4, 4, 4, 4, 4, 4, 3, 0, 0, 0, 3, 3, 3, 3, 4, 5, 0, 2, 2, 3, 3, 3, 3, 3, 3, 0, 5, 5, 4, 1, 4, 4, 4, 4, 4, 4, 0, 3, 4, 4, 6, 2, 2, 2, 2, 4, 0, 6, 6, 0, 3, 4, 4, 4, 3, 3, 0, 5, 4, 5, 0, 3, 3, 3, 3, 2, 3, 2, 4, 4, 0, 0, 3, 2, 6, 0, 0, 0, 3, 5, 5, 1, 3, 4, 4, 1, 4, 4, 6, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 6, 6, 2, 6, 6, 3, 2, 6, 3, 4, 4, 4, 2, 5, 5, 2, 2, 3, 0, 4, 4, 3, 2, 3, 1, 6, 6, 5, 0, 4, 4, 6, 3, 1, 1, 4, 0, 5, 2, 3, 3, 3, 0, 5, 5, 0, 3, 3, 0, 2, 1, 1, 5, 2, 3, 3, 1, 0, 2, 3, 2, 2, 5, 5, 4, 3, 4, 3, 2, 2, 4, 2, 4, 5, 5, 3, 2, 3, 1, 3, 3, 3, 4, 5, 4, 3, 3, 3, 1, 3, 0, 0, 2, 4, 4, 4, 3, 3, 3, 5, 2, 3, 2, 2, 2, 3, 2, 0, 3, 4, 4, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 2, 3, 4, 2, 2, 6, 4, 3, 3, 4, 1, 5, 3, 4, 3, 2, 2, 1, 3, 0, 3, 3, 3, 6, 3, 2, 2, 6, 3, 3, 0, 2, 3, 2, 3, 2, 5, 2, 2, 0, 5, 6, 4, 3, 3, 3, 2, 5, 3, 3, 4, 3, 3, 3, 3, 3, 4, 6, 6, 5, 2, 2, 2, 5, 4, 4, 4, 4, 6, 3, 2, 2, 3, 0, 3, 1, 2, 2, 3, 0, 4, 4, 3, 1, 4, 4, 3, 3, 0, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 3, 3, 2, 3, 2, 6, 3, 4, 4, 3, 3, 3, 3, 3, 3, 0, 3, 2, 1, 3, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cora Data Using GCN Custom Traing Loop"
      ],
      "metadata": {
        "id": "j1TFIA5TETnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(seed=0)"
      ],
      "metadata": {
        "id": "RZBbxhPeqxWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Cora(normalize_x=True, transforms=[LayerPreprocess(GCNConv), AdjToSpTensor()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnULeMEgqzo6",
        "outputId": "e8bc1c71-8d76-4853-ae19-a8eae2397219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-processing node features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Data set name: {dataset.name}\")\n",
        "print(f\"Data set type: {type(dataset)}\")\n",
        "print(f\"No. of graphs: {dataset.n_graphs}\")\n",
        "print(f\"No. of nodes: {dataset.n_nodes}\")\n",
        "print(f\"No. of classes: {dataset.n_labels}\")\n",
        "print(f\"No. of edge features: {dataset.n_edge_features}\")\n",
        "print(f\"No. of node features: {dataset.n_node_features}\")\n",
        "print(f\"Recap: {dataset.graphs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Nt4eLDiq1gT",
        "outputId": "7fd791fb-cd85-45de-f1bb-877615f2684c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data set name: cora\n",
            "Data set type: <class 'spektral.datasets.citation.Cora'>\n",
            "No. of graphs: 1\n",
            "No. of nodes: 2708\n",
            "No. of classes: 7\n",
            "No. of edge features: None\n",
            "No. of node features: 1433\n",
            "Recap: [Graph(n_nodes=2708, n_node_features=1433, n_edge_features=None, n_labels=7)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = dataset[0]\n",
        "nodes, adj_matrix, labels = graph.x, graph.a, graph.y"
      ],
      "metadata": {
        "id": "Dwl5CAeRq-kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_trian, mask_validation, mask_test = dataset.mask_tr, dataset.mask_va, dataset.mask_te"
      ],
      "metadata": {
        "id": "GYlV9FzCrJV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(n_labels=dataset.n_labels)\n",
        "optimizer = Adam(learning_rate=1e-2)\n",
        "loss_func = CategoricalCrossentropy()"
      ],
      "metadata": {
        "id": "5DQj2liQrPJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training step\n",
        "@tf.function\n",
        "def train():\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model([nodes, adj_matrix], training=True)\n",
        "        loss = loss_func(labels[mask_trian], predictions[mask_trian])\n",
        "        loss += sum(model.losses)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "train()  # warm up to ignore tracing times when timing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl-X_bQrrPly",
        "outputId": "73de2371-0014-41d7-a315-ef8026726e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=1.9543768>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# time the execution of 200 epochs of training\n",
        "tic()\n",
        "for epoch in range(1, 201):\n",
        "    loss = train()\n",
        "toc(\"Spektral - GCN (200 epochs)\")\n",
        "print(f\"Final loss = {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEhWgE684zWd",
        "outputId": "edd80a6d-a6e2-4171-dff6-404dd16c96d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spektral - GCN (200 epochs)\n",
            "Elapsed: 12.84s\n",
            "Final loss = 0.6075741648674011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cora Data Using ChebConv"
      ],
      "metadata": {
        "id": "6x1DDRElr4B9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "dataset = Citation(\"cora\", transforms=[LayerPreprocess(ChebConv)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gApgL14Sttom",
        "outputId": "a61cdcd4-9f6e-484d-a68b-4bdb519f424e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_to_weights(mask):\n",
        "    return mask / np.count_nonzero(mask)\n",
        "weights_train, weights_valid, weights_test = (mask_to_weights(mask) for mask in (dataset.mask_tr, dataset.mask_va, dataset.mask_te))"
      ],
      "metadata": {
        "id": "nhisIfdvt4Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parames\n",
        "channels = 16  # number of channels in the first layer\n",
        "cheb_deg = 2  # max degree of the Chebyshev polynomials\n",
        "dropout = 0.5  # dropout rate for the features\n",
        "l2_reg = 2.5e-4  # l2 regularization rate\n",
        "learning_rate = 1e-2  # learning rate\n",
        "epochs = 200  # number of training epochs\n",
        "patience = 10  # patience for early stopping"
      ],
      "metadata": {
        "id": "NH1uMlyJt9Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Data set name: {dataset.name}\")\n",
        "print(f\"Data set type: {type(dataset)}\")\n",
        "print(f\"No. of graphs: {dataset.n_graphs}\")\n",
        "print(f\"No. of nodes: {dataset.n_nodes}\")\n",
        "print(f\"No. of classes: {dataset.n_labels}\")\n",
        "print(f\"No. of edge features: {dataset.n_edge_features}\")\n",
        "print(f\"No. of node features: {dataset.n_node_features}\")\n",
        "print(f\"Recap: {dataset.graphs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_tlShiJt9gU",
        "outputId": "ae8df90b-4936-4651-bfa8-f8d59b952ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data set name: cora\n",
            "Data set type: <class 'spektral.datasets.citation.Citation'>\n",
            "No. of graphs: 1\n",
            "No. of nodes: 2708\n",
            "No. of classes: 7\n",
            "No. of edge features: None\n",
            "No. of node features: 1433\n",
            "Recap: [Graph(n_nodes=2708, n_node_features=1433, n_edge_features=None, n_labels=7)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vars\n",
        "adj_matrix_dtype = dataset[0].a.dtype  # only needed for TF 2.1\n",
        "num_nodes = dataset.n_nodes  # number of nodes in the graph\n",
        "num_feat = dataset.n_node_features  # original size of node features\n",
        "num_labels = dataset.n_labels  # number of classes"
      ],
      "metadata": {
        "id": "BxrkP-uevfKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "nodes_input = Input(shape=(num_feat,))\n",
        "adj_matrix_input = Input((num_nodes,), sparse=True, dtype=adj_matrix_dtype)\n",
        "x = Dropout(dropout)(nodes_input)\n",
        "x = ChebConv(channels, K=cheb_deg, activation=\"relu\", kernel_regularizer=l2(l2_reg), use_bias=False)([x, adj_matrix_input])\n",
        "x = Dropout(dropout)(x)\n",
        "outputs = ChebConv(num_labels, K=cheb_deg, activation=\"softmax\", use_bias=False)([x, adj_matrix_input])"
      ],
      "metadata": {
        "id": "l6yUgKTcvmK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "model = Model(inputs=[nodes_input, adj_matrix_input], outputs=outputs)\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss=CategoricalCrossentropy(reduction=\"sum\"), weighted_metrics=[\"acc\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSUiSjnJw3iX",
        "outputId": "c46ae9dd-e71e-42ee-ee58-4c4f34873b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 1433)]               0         []                            \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 1433)                 0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 2708)]               0         []                            \n",
            "                                                                                                  \n",
            " cheb_conv (ChebConv)        (None, 16)                   45856     ['dropout_6[0][0]',           \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 16)                   0         ['cheb_conv[0][0]']           \n",
            "                                                                                                  \n",
            " cheb_conv_1 (ChebConv)      (None, 7)                    224       ['dropout_7[0][0]',           \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 46080 (180.00 KB)\n",
            "Trainable params: 46080 (180.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "loader_train = SingleLoader(dataset, sample_weights=weights_train)\n",
        "loader_valid = SingleLoader(dataset, sample_weights=weights_valid)\n",
        "model.fit(\n",
        "    loader_train.load(),\n",
        "    steps_per_epoch=loader_train.steps_per_epoch,\n",
        "    validation_data=loader_valid.load(),\n",
        "    validation_steps=loader_valid.steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF9DxpAtvBev",
        "outputId": "d9844c3e-8568-4c6a-d7a0-372dd079fe5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 1.9632 - acc: 0.1286 - val_loss: 1.9147 - val_acc: 0.2940\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.8490 - acc: 0.3429 - val_loss: 1.8765 - val_acc: 0.3880\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 1.7146 - acc: 0.5357 - val_loss: 1.8185 - val_acc: 0.4320\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 1.5424 - acc: 0.6000 - val_loss: 1.7451 - val_acc: 0.4780\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 1.3844 - acc: 0.6929 - val_loss: 1.6660 - val_acc: 0.5200\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 1.1900 - acc: 0.7429 - val_loss: 1.5808 - val_acc: 0.5700\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 1.0213 - acc: 0.8071 - val_loss: 1.4939 - val_acc: 0.6000\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.9343 - acc: 0.8000 - val_loss: 1.4026 - val_acc: 0.6440\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.8040 - acc: 0.8429 - val_loss: 1.3136 - val_acc: 0.6860\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.6271 - acc: 0.9286 - val_loss: 1.2335 - val_acc: 0.7020\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.6056 - acc: 0.9000 - val_loss: 1.1640 - val_acc: 0.7260\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.4644 - acc: 0.9143 - val_loss: 1.1037 - val_acc: 0.7500\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.5241 - acc: 0.8929 - val_loss: 1.0522 - val_acc: 0.7560\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.3679 - acc: 0.9286 - val_loss: 1.0102 - val_acc: 0.7600\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.3241 - acc: 0.9571 - val_loss: 0.9752 - val_acc: 0.7620\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.3224 - acc: 0.9786 - val_loss: 0.9466 - val_acc: 0.7660\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.2656 - acc: 0.9500 - val_loss: 0.9244 - val_acc: 0.7660\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.2527 - acc: 0.9643 - val_loss: 0.9108 - val_acc: 0.7640\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.2391 - acc: 0.9643 - val_loss: 0.9022 - val_acc: 0.7620\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.2283 - acc: 0.9857 - val_loss: 0.9030 - val_acc: 0.7580\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.1949 - acc: 0.9643 - val_loss: 0.9087 - val_acc: 0.7580\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.2096 - acc: 0.9857 - val_loss: 0.9188 - val_acc: 0.7580\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.1933 - acc: 0.9786 - val_loss: 0.9308 - val_acc: 0.7520\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.2544 - acc: 0.9571 - val_loss: 0.9455 - val_acc: 0.7480\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1825 - acc: 0.9929 - val_loss: 0.9595 - val_acc: 0.7440\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1913 - acc: 0.9643 - val_loss: 0.9715 - val_acc: 0.7400\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.1422 - acc: 0.9929 - val_loss: 0.9829 - val_acc: 0.7380\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1780 - acc: 0.9786 - val_loss: 0.9917 - val_acc: 0.7400\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.1639 - acc: 0.9786 - val_loss: 0.9946 - val_acc: 0.7440\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fdc39e8c880>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "print(\"Evaluating model.\")\n",
        "loader_test = SingleLoader(dataset, sample_weights=weights_test)\n",
        "eval_results = model.evaluate(loader_test.load(), steps=loader_test.steps_per_epoch)\n",
        "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR0fDnflsmv8",
        "outputId": "d3d7a1d5-6849-4b60-d799-5ce5901fe1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model.\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.8185 - acc: 0.7770\n",
            "Done.\n",
            "Test loss: 0.8184532523155212\n",
            "Test accuracy: 0.7769999504089355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cora Data Using GAT"
      ],
      "metadata": {
        "id": "PMrXDjBuslmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(0)"
      ],
      "metadata": {
        "id": "X_C48R-eERGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "dataset = Citation(\"cora\", normalize_x=True, transforms=[LayerPreprocess(GATConv)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlmQn-M4Eonb",
        "outputId": "d40a8046-4264-4788-d071-a51c2cc31138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-processing node features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_to_weights(mask):\n",
        "    return mask.astype(np.float32) / np.count_nonzero(mask)\n",
        "weights_train, weights_validation, weights_test = (mask_to_weights(mask) for mask in (dataset.mask_tr, dataset.mask_va, dataset.mask_te))"
      ],
      "metadata": {
        "id": "KMWUD4mLERRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# params\n",
        "channels = 8  # number of channels in each head of the first GAT layer\n",
        "num_attn_heads = 8  # number of attention heads in first GAT layer\n",
        "dropout = 0.6  # dropout rate for the features and adjacency matrix\n",
        "l2_reg = 2.5e-4  # l2 regularization rate\n",
        "learning_rate = 5e-3  # learning rate\n",
        "epochs = 20  # number of training epochs\n",
        "patience = 100  # patience for early stopping"
      ],
      "metadata": {
        "id": "7xSTqYm9E6eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vars\n",
        "num_nodes = dataset.n_nodes  # number of nodes in the graph\n",
        "num_feat = dataset.n_node_features  # original size of node features\n",
        "num_labels = dataset.n_labels  # number of classes"
      ],
      "metadata": {
        "id": "EeRCDdU2E9X1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "input = Input(shape=(num_feat,))\n",
        "adj_mat = Input((num_nodes,), sparse=True)\n",
        "x = Dropout(dropout)(input)\n",
        "x = GATConv(\n",
        "    channels,\n",
        "    attn_heads=num_attn_heads,\n",
        "    concat_heads=True,\n",
        "    dropout_rate=dropout,\n",
        "    activation=\"elu\",\n",
        "    kernel_regularizer=l2(l2_reg),\n",
        "    attn_kernel_regularizer=l2(l2_reg),\n",
        "    bias_regularizer=l2(l2_reg)\n",
        "    )([x, adj_mat])\n",
        "x = Dropout(dropout)(x)\n",
        "output = GATConv(\n",
        "    num_labels,\n",
        "    attn_heads=1,\n",
        "    concat_heads=False,\n",
        "    dropout_rate=dropout,\n",
        "    activation=\"softmax\",\n",
        "    kernel_regularizer=l2(l2_reg),\n",
        "    attn_kernel_regularizer=l2(l2_reg),\n",
        "    bias_regularizer=l2(l2_reg)\n",
        "    )([x, adj_mat])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg2jNe22E9g6",
        "outputId": "094aa1eb-9da4-40b0-f1b7-524f4044e46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "model = Model(inputs=[input, adj_mat], outputs=output)\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=CategoricalCrossentropy(reduction=\"sum\"),\n",
        "    weighted_metrics=[\"acc\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq1uQhxfGdDL",
        "outputId": "8a78749c-a467-4017-c609-e8e4bddbdecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 1433)]               0         []                            \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, 1433)                 0         ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 2708)]               0         []                            \n",
            "                                                                                                  \n",
            " gat_conv (GATConv)          (None, 64)                   91904     ['dropout_10[0][0]',          \n",
            "                                                                     'input_4[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 64)                   0         ['gat_conv[0][0]']            \n",
            "                                                                                                  \n",
            " gat_conv_1 (GATConv)        (None, 7)                    469       ['dropout_11[0][0]',          \n",
            "                                                                     'input_4[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 92373 (360.83 KB)\n",
            "Trainable params: 92373 (360.83 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "loader_train = SingleLoader(dataset, sample_weights=weights_train)\n",
        "loader_valid = SingleLoader(dataset, sample_weights=weights_validation)\n",
        "model.fit(\n",
        "    loader_train.load(),\n",
        "    steps_per_epoch=loader_train.steps_per_epoch,\n",
        "    validation_data=loader_valid.load(),\n",
        "    validation_steps=loader_valid.steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wE9J_K8ERWV",
        "outputId": "53c35b04-d774-4a89-e42a-b64c31aaa625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.9496 - acc: 0.2143 - val_loss: 1.9486 - val_acc: 0.0740\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 1.9471 - acc: 0.2214 - val_loss: 1.9468 - val_acc: 0.0740\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.9444 - acc: 0.2429 - val_loss: 1.9454 - val_acc: 0.1440\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.9432 - acc: 0.3214 - val_loss: 1.9446 - val_acc: 0.3560\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 1.9381 - acc: 0.4357 - val_loss: 1.9428 - val_acc: 0.4700\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 1.9347 - acc: 0.4714 - val_loss: 1.9408 - val_acc: 0.4600\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.9345 - acc: 0.4500 - val_loss: 1.9384 - val_acc: 0.5980\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.9334 - acc: 0.4500 - val_loss: 1.9364 - val_acc: 0.6840\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 1.9302 - acc: 0.4929 - val_loss: 1.9347 - val_acc: 0.7680\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 1.9242 - acc: 0.5286 - val_loss: 1.9326 - val_acc: 0.8060\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 1.9232 - acc: 0.5286 - val_loss: 1.9304 - val_acc: 0.8020\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 1.9177 - acc: 0.5857 - val_loss: 1.9281 - val_acc: 0.7600\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 1.9178 - acc: 0.6357 - val_loss: 1.9252 - val_acc: 0.7280\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 1.9149 - acc: 0.5786 - val_loss: 1.9225 - val_acc: 0.7120\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.8998 - acc: 0.6357 - val_loss: 1.9195 - val_acc: 0.7180\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 1.9028 - acc: 0.6000 - val_loss: 1.9165 - val_acc: 0.7080\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 1.8916 - acc: 0.6357 - val_loss: 1.9134 - val_acc: 0.7060\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.8775 - acc: 0.6857 - val_loss: 1.9100 - val_acc: 0.7120\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 1.8794 - acc: 0.7000 - val_loss: 1.9068 - val_acc: 0.7300\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 1.8679 - acc: 0.6929 - val_loss: 1.9032 - val_acc: 0.7460\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7dfdad1d3c70>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "print(\"Evaluating model.\")\n",
        "loader_test = SingleLoader(dataset, sample_weights=weights_test)\n",
        "eval_results = model.evaluate(loader_test.load(), steps=loader_test.steps_per_epoch)\n",
        "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1o54uPDFfye",
        "outputId": "c4ca54c5-60c1-49e8-9e83-f82c7d0883e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model.\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.9014 - acc: 0.7450\n",
            "Done.\n",
            "Test loss: 1.9014073610305786\n",
            "Test accuracy: 0.7450000047683716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cora Data Using GAT Custom Traing Loop"
      ],
      "metadata": {
        "id": "8cJ_J0icxplt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(0)"
      ],
      "metadata": {
        "id": "WY-0KjAeIP52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "dataset = Cora(normalize_x=True, transforms=[LayerPreprocess(GATConv), AdjToSpTensor()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGrO35j7KaMf",
        "outputId": "9c6a6602-b288-4933-f6c6-dac95f67b447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-processing node features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# graph\n",
        "graph = dataset[0]\n",
        "nodes, adj_matrix, labels = graph.x, graph.a, graph.y"
      ],
      "metadata": {
        "id": "6yc8Q2LkKbjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weights\n",
        "mask_train, mask_validation, mask_test = dataset.mask_tr, dataset.mask_va, dataset.mask_te"
      ],
      "metadata": {
        "id": "Llf9eYy8Kbs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# params\n",
        "channels = 8  # number of channels in each head of the first GAT layer\n",
        "num_attn_heads = 8  # number of attention heads in first GAT layer\n",
        "dropout = 0.6  # dropout rate for the features and adjacency matrix\n",
        "l2_reg = 2.5e-4  # l2 regularization rate\n",
        "learning_rate = 5e-3  # learning rate\n",
        "epochs = 20  # number of training epochs\n",
        "patience = 100  # patience for early stopping"
      ],
      "metadata": {
        "id": "dN_VCOs3LM7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vars\n",
        "num_nodes = dataset.n_nodes  # number of nodes in the graph\n",
        "num_feat = dataset.n_node_features  # original size of node features\n",
        "num_labels = dataset.n_labels  # number of classes"
      ],
      "metadata": {
        "id": "a_0BiL-CKb2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "input = Input(shape=(num_feat,))\n",
        "adj_mat = Input((num_nodes,), sparse=True)\n",
        "x = Dropout(dropout)(input)\n",
        "x = GATConv(\n",
        "    channels,\n",
        "    attn_heads=num_attn_heads,\n",
        "    concat_heads=True,\n",
        "    dropout_rate=dropout,\n",
        "    activation=\"elu\",\n",
        "    kernel_regularizer=l2(l2_reg),\n",
        "    attn_kernel_regularizer=l2(l2_reg),\n",
        "    bias_regularizer=l2(l2_reg)\n",
        "    )([x, adj_mat])\n",
        "x = Dropout(dropout)(x)\n",
        "output = GATConv(\n",
        "    num_labels,\n",
        "    attn_heads=1,\n",
        "    concat_heads=False,\n",
        "    dropout_rate=dropout,\n",
        "    activation=\"softmax\",\n",
        "    kernel_regularizer=l2(l2_reg),\n",
        "    attn_kernel_regularizer=l2(l2_reg),\n",
        "    bias_regularizer=l2(l2_reg)\n",
        "    )([x, adj_mat])"
      ],
      "metadata": {
        "id": "XA10KDR-K2RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "model = Model(inputs=[input, adj_mat], outputs=output)\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "loss_func = CategoricalCrossentropy()"
      ],
      "metadata": {
        "id": "Yp86Ea1wLWwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training step\n",
        "@tf.function\n",
        "def train():\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model([nodes, adj_matrix], training=True)\n",
        "        loss = loss_func(labels[mask_train], predictions[mask_train])\n",
        "        loss += sum(model.losses)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "@tf.function\n",
        "def evaluate():\n",
        "    predictions = model([nodes, adj_matrix], training=False)\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    for mask in [mask_train, mask_validation, mask_test]:\n",
        "        loss = loss_func(labels[mask], predictions[mask])\n",
        "        loss += sum(model.losses)\n",
        "        losses.append(loss)\n",
        "        acc = tf.reduce_mean(categorical_accuracy(labels[mask], predictions[mask]))\n",
        "        accuracies.append(acc)\n",
        "    return losses, accuracies\n",
        "\n",
        "best_val_loss = 1e6\n",
        "best_test_acc = 0\n",
        "current_patience = patience = 100\n",
        "epochs = 100\n",
        "tic()\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train()\n",
        "    losses, accu = evaluate()\n",
        "    print(\n",
        "        \"Loss train: {:.4f}, Acc train: {:.4f}, \"\n",
        "        \"Loss validation: {:.4f}, Acc validation: {:.4f}, \"\n",
        "        \"Loss test: {:.4f}, Acc test: {:.4f}\".format(losses[0], accu[0], losses[1], accu[1], losses[2], accu[2])\n",
        "        )\n",
        "    if losses[1] < best_val_loss:\n",
        "        best_val_loss = losses[1]\n",
        "        best_test_acc = accu[2]\n",
        "        current_patience = patience\n",
        "        print(\"Improved\")\n",
        "    else:\n",
        "        current_patience -= 1\n",
        "        if current_patience == 0:\n",
        "            print(\"Test accuracy: {}\".format(best_test_acc))\n",
        "            break\n",
        "toc(\"GAT ({} epochs)\".format(epoch))"
      ],
      "metadata": {
        "id": "H3WNokDnIP2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9148d9e8-ed8d-4e25-f17e-744f7a3a7812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss train: 1.9467, Acc train: 0.3643, Loss validation: 1.9495, Acc validation: 0.2300, Loss test: 1.9497, Acc test: 0.2070\n",
            "Improved\n",
            "Loss train: 1.9441, Acc train: 0.6357, Loss validation: 1.9487, Acc validation: 0.4080, Loss test: 1.9486, Acc test: 0.3880\n",
            "Improved\n",
            "Loss train: 1.9416, Acc train: 0.7000, Loss validation: 1.9466, Acc validation: 0.4740, Loss test: 1.9465, Acc test: 0.4430\n",
            "Improved\n",
            "Loss train: 1.9392, Acc train: 0.7143, Loss validation: 1.9444, Acc validation: 0.3960, Loss test: 1.9442, Acc test: 0.4140\n",
            "Improved\n",
            "Loss train: 1.9366, Acc train: 0.5857, Loss validation: 1.9421, Acc validation: 0.3120, Loss test: 1.9419, Acc test: 0.3310\n",
            "Improved\n",
            "Loss train: 1.9339, Acc train: 0.5286, Loss validation: 1.9400, Acc validation: 0.2980, Loss test: 1.9399, Acc test: 0.3280\n",
            "Improved\n",
            "Loss train: 1.9310, Acc train: 0.6714, Loss validation: 1.9382, Acc validation: 0.4860, Loss test: 1.9379, Acc test: 0.4720\n",
            "Improved\n",
            "Loss train: 1.9278, Acc train: 0.8286, Loss validation: 1.9365, Acc validation: 0.6600, Loss test: 1.9360, Acc test: 0.6670\n",
            "Improved\n",
            "Loss train: 1.9244, Acc train: 0.8714, Loss validation: 1.9345, Acc validation: 0.7400, Loss test: 1.9339, Acc test: 0.7500\n",
            "Improved\n",
            "Loss train: 1.9208, Acc train: 0.9071, Loss validation: 1.9322, Acc validation: 0.7720, Loss test: 1.9315, Acc test: 0.7790\n",
            "Improved\n",
            "Loss train: 1.9170, Acc train: 0.9286, Loss validation: 1.9297, Acc validation: 0.7800, Loss test: 1.9290, Acc test: 0.8000\n",
            "Improved\n",
            "Loss train: 1.9129, Acc train: 0.9429, Loss validation: 1.9274, Acc validation: 0.7800, Loss test: 1.9266, Acc test: 0.7860\n",
            "Improved\n",
            "Loss train: 1.9086, Acc train: 0.9357, Loss validation: 1.9247, Acc validation: 0.7800, Loss test: 1.9238, Acc test: 0.7820\n",
            "Improved\n",
            "Loss train: 1.9040, Acc train: 0.9286, Loss validation: 1.9223, Acc validation: 0.7940, Loss test: 1.9214, Acc test: 0.7960\n",
            "Improved\n",
            "Loss train: 1.8991, Acc train: 0.9286, Loss validation: 1.9197, Acc validation: 0.8000, Loss test: 1.9188, Acc test: 0.7980\n",
            "Improved\n",
            "Loss train: 1.8940, Acc train: 0.9357, Loss validation: 1.9177, Acc validation: 0.7980, Loss test: 1.9167, Acc test: 0.7930\n",
            "Improved\n",
            "Loss train: 1.8885, Acc train: 0.9429, Loss validation: 1.9155, Acc validation: 0.8020, Loss test: 1.9142, Acc test: 0.7940\n",
            "Improved\n",
            "Loss train: 1.8827, Acc train: 0.9357, Loss validation: 1.9135, Acc validation: 0.7900, Loss test: 1.9119, Acc test: 0.7960\n",
            "Improved\n",
            "Loss train: 1.8765, Acc train: 0.9357, Loss validation: 1.9113, Acc validation: 0.7860, Loss test: 1.9094, Acc test: 0.7900\n",
            "Improved\n",
            "Loss train: 1.8701, Acc train: 0.9357, Loss validation: 1.9088, Acc validation: 0.7740, Loss test: 1.9067, Acc test: 0.7770\n",
            "Improved\n",
            "Loss train: 1.8633, Acc train: 0.9357, Loss validation: 1.9063, Acc validation: 0.7500, Loss test: 1.9040, Acc test: 0.7640\n",
            "Improved\n",
            "Loss train: 1.8563, Acc train: 0.9286, Loss validation: 1.9034, Acc validation: 0.7520, Loss test: 1.9009, Acc test: 0.7550\n",
            "Improved\n",
            "Loss train: 1.8489, Acc train: 0.9214, Loss validation: 1.9002, Acc validation: 0.7400, Loss test: 1.8974, Acc test: 0.7450\n",
            "Improved\n",
            "Loss train: 1.8414, Acc train: 0.9214, Loss validation: 1.8969, Acc validation: 0.7340, Loss test: 1.8937, Acc test: 0.7480\n",
            "Improved\n",
            "Loss train: 1.8335, Acc train: 0.9214, Loss validation: 1.8930, Acc validation: 0.7400, Loss test: 1.8895, Acc test: 0.7510\n",
            "Improved\n",
            "Loss train: 1.8253, Acc train: 0.9286, Loss validation: 1.8886, Acc validation: 0.7480, Loss test: 1.8847, Acc test: 0.7490\n",
            "Improved\n",
            "Loss train: 1.8168, Acc train: 0.9286, Loss validation: 1.8837, Acc validation: 0.7520, Loss test: 1.8796, Acc test: 0.7510\n",
            "Improved\n",
            "Loss train: 1.8079, Acc train: 0.9429, Loss validation: 1.8781, Acc validation: 0.7600, Loss test: 1.8738, Acc test: 0.7580\n",
            "Improved\n",
            "Loss train: 1.7987, Acc train: 0.9429, Loss validation: 1.8717, Acc validation: 0.7520, Loss test: 1.8673, Acc test: 0.7570\n",
            "Improved\n",
            "Loss train: 1.7892, Acc train: 0.9429, Loss validation: 1.8658, Acc validation: 0.7480, Loss test: 1.8611, Acc test: 0.7500\n",
            "Improved\n",
            "Loss train: 1.7792, Acc train: 0.9429, Loss validation: 1.8599, Acc validation: 0.7500, Loss test: 1.8549, Acc test: 0.7570\n",
            "Improved\n",
            "Loss train: 1.7689, Acc train: 0.9500, Loss validation: 1.8535, Acc validation: 0.7640, Loss test: 1.8481, Acc test: 0.7710\n",
            "Improved\n",
            "Loss train: 1.7582, Acc train: 0.9500, Loss validation: 1.8476, Acc validation: 0.7640, Loss test: 1.8418, Acc test: 0.7780\n",
            "Improved\n",
            "Loss train: 1.7471, Acc train: 0.9500, Loss validation: 1.8416, Acc validation: 0.7720, Loss test: 1.8354, Acc test: 0.7890\n",
            "Improved\n",
            "Loss train: 1.7357, Acc train: 0.9500, Loss validation: 1.8357, Acc validation: 0.7800, Loss test: 1.8290, Acc test: 0.7900\n",
            "Improved\n",
            "Loss train: 1.7238, Acc train: 0.9500, Loss validation: 1.8295, Acc validation: 0.7940, Loss test: 1.8225, Acc test: 0.7950\n",
            "Improved\n",
            "Loss train: 1.7116, Acc train: 0.9500, Loss validation: 1.8239, Acc validation: 0.7860, Loss test: 1.8166, Acc test: 0.7940\n",
            "Improved\n",
            "Loss train: 1.6990, Acc train: 0.9500, Loss validation: 1.8180, Acc validation: 0.7900, Loss test: 1.8102, Acc test: 0.7940\n",
            "Improved\n",
            "Loss train: 1.6861, Acc train: 0.9500, Loss validation: 1.8123, Acc validation: 0.7860, Loss test: 1.8042, Acc test: 0.7930\n",
            "Improved\n",
            "Loss train: 1.6728, Acc train: 0.9357, Loss validation: 1.8062, Acc validation: 0.7900, Loss test: 1.7979, Acc test: 0.7920\n",
            "Improved\n",
            "Loss train: 1.6593, Acc train: 0.9357, Loss validation: 1.8001, Acc validation: 0.7840, Loss test: 1.7915, Acc test: 0.7860\n",
            "Improved\n",
            "Loss train: 1.6453, Acc train: 0.9357, Loss validation: 1.7931, Acc validation: 0.7840, Loss test: 1.7840, Acc test: 0.7860\n",
            "Improved\n",
            "Loss train: 1.6312, Acc train: 0.9357, Loss validation: 1.7862, Acc validation: 0.7800, Loss test: 1.7766, Acc test: 0.7840\n",
            "Improved\n",
            "Loss train: 1.6168, Acc train: 0.9357, Loss validation: 1.7777, Acc validation: 0.7860, Loss test: 1.7678, Acc test: 0.7880\n",
            "Improved\n",
            "Loss train: 1.6022, Acc train: 0.9429, Loss validation: 1.7679, Acc validation: 0.7840, Loss test: 1.7576, Acc test: 0.7890\n",
            "Improved\n",
            "Loss train: 1.5874, Acc train: 0.9429, Loss validation: 1.7569, Acc validation: 0.7880, Loss test: 1.7464, Acc test: 0.7950\n",
            "Improved\n",
            "Loss train: 1.5726, Acc train: 0.9429, Loss validation: 1.7454, Acc validation: 0.7960, Loss test: 1.7347, Acc test: 0.7980\n",
            "Improved\n",
            "Loss train: 1.5576, Acc train: 0.9429, Loss validation: 1.7348, Acc validation: 0.8040, Loss test: 1.7240, Acc test: 0.7960\n",
            "Improved\n",
            "Loss train: 1.5425, Acc train: 0.9500, Loss validation: 1.7241, Acc validation: 0.8040, Loss test: 1.7134, Acc test: 0.7980\n",
            "Improved\n",
            "Loss train: 1.5273, Acc train: 0.9500, Loss validation: 1.7137, Acc validation: 0.8040, Loss test: 1.7031, Acc test: 0.8040\n",
            "Improved\n",
            "Loss train: 1.5119, Acc train: 0.9500, Loss validation: 1.7036, Acc validation: 0.8040, Loss test: 1.6931, Acc test: 0.8050\n",
            "Improved\n",
            "Loss train: 1.4965, Acc train: 0.9500, Loss validation: 1.6940, Acc validation: 0.7980, Loss test: 1.6835, Acc test: 0.8020\n",
            "Improved\n",
            "Loss train: 1.4812, Acc train: 0.9500, Loss validation: 1.6833, Acc validation: 0.8020, Loss test: 1.6726, Acc test: 0.8030\n",
            "Improved\n",
            "Loss train: 1.4657, Acc train: 0.9500, Loss validation: 1.6742, Acc validation: 0.7960, Loss test: 1.6634, Acc test: 0.8010\n",
            "Improved\n",
            "Loss train: 1.4502, Acc train: 0.9500, Loss validation: 1.6651, Acc validation: 0.7980, Loss test: 1.6538, Acc test: 0.7990\n",
            "Improved\n",
            "Loss train: 1.4347, Acc train: 0.9500, Loss validation: 1.6558, Acc validation: 0.8000, Loss test: 1.6441, Acc test: 0.8010\n",
            "Improved\n",
            "Loss train: 1.4193, Acc train: 0.9500, Loss validation: 1.6465, Acc validation: 0.8000, Loss test: 1.6345, Acc test: 0.8030\n",
            "Improved\n",
            "Loss train: 1.4037, Acc train: 0.9429, Loss validation: 1.6370, Acc validation: 0.7960, Loss test: 1.6245, Acc test: 0.8030\n",
            "Improved\n",
            "Loss train: 1.3879, Acc train: 0.9429, Loss validation: 1.6288, Acc validation: 0.8000, Loss test: 1.6156, Acc test: 0.8010\n",
            "Improved\n",
            "Loss train: 1.3725, Acc train: 0.9429, Loss validation: 1.6224, Acc validation: 0.7940, Loss test: 1.6084, Acc test: 0.7990\n",
            "Improved\n",
            "Loss train: 1.3570, Acc train: 0.9500, Loss validation: 1.6151, Acc validation: 0.7960, Loss test: 1.6002, Acc test: 0.8000\n",
            "Improved\n",
            "Loss train: 1.3418, Acc train: 0.9500, Loss validation: 1.6060, Acc validation: 0.7980, Loss test: 1.5902, Acc test: 0.8040\n",
            "Improved\n",
            "Loss train: 1.3270, Acc train: 0.9500, Loss validation: 1.5991, Acc validation: 0.8000, Loss test: 1.5824, Acc test: 0.8060\n",
            "Improved\n",
            "Loss train: 1.3124, Acc train: 0.9500, Loss validation: 1.5922, Acc validation: 0.7920, Loss test: 1.5745, Acc test: 0.7990\n",
            "Improved\n",
            "Loss train: 1.2980, Acc train: 0.9500, Loss validation: 1.5852, Acc validation: 0.7940, Loss test: 1.5668, Acc test: 0.7980\n",
            "Improved\n",
            "Loss train: 1.2838, Acc train: 0.9500, Loss validation: 1.5778, Acc validation: 0.7960, Loss test: 1.5591, Acc test: 0.7960\n",
            "Improved\n",
            "Loss train: 1.2695, Acc train: 0.9500, Loss validation: 1.5691, Acc validation: 0.7960, Loss test: 1.5503, Acc test: 0.7970\n",
            "Improved\n",
            "Loss train: 1.2556, Acc train: 0.9500, Loss validation: 1.5594, Acc validation: 0.7980, Loss test: 1.5406, Acc test: 0.8000\n",
            "Improved\n",
            "Loss train: 1.2418, Acc train: 0.9500, Loss validation: 1.5497, Acc validation: 0.8000, Loss test: 1.5311, Acc test: 0.8000\n",
            "Improved\n",
            "Loss train: 1.2280, Acc train: 0.9500, Loss validation: 1.5391, Acc validation: 0.8020, Loss test: 1.5209, Acc test: 0.8010\n",
            "Improved\n",
            "Loss train: 1.2145, Acc train: 0.9500, Loss validation: 1.5290, Acc validation: 0.8040, Loss test: 1.5111, Acc test: 0.7990\n",
            "Improved\n",
            "Loss train: 1.2012, Acc train: 0.9500, Loss validation: 1.5204, Acc validation: 0.8020, Loss test: 1.5026, Acc test: 0.8000\n",
            "Improved\n",
            "Loss train: 1.1880, Acc train: 0.9500, Loss validation: 1.5124, Acc validation: 0.8040, Loss test: 1.4948, Acc test: 0.8000\n",
            "Improved\n",
            "Loss train: 1.1751, Acc train: 0.9500, Loss validation: 1.5028, Acc validation: 0.8020, Loss test: 1.4854, Acc test: 0.8030\n",
            "Improved\n",
            "Loss train: 1.1627, Acc train: 0.9500, Loss validation: 1.4925, Acc validation: 0.8020, Loss test: 1.4751, Acc test: 0.8040\n",
            "Improved\n",
            "Loss train: 1.1506, Acc train: 0.9500, Loss validation: 1.4817, Acc validation: 0.8040, Loss test: 1.4643, Acc test: 0.8080\n",
            "Improved\n",
            "Loss train: 1.1390, Acc train: 0.9500, Loss validation: 1.4730, Acc validation: 0.8020, Loss test: 1.4554, Acc test: 0.8080\n",
            "Improved\n",
            "Loss train: 1.1279, Acc train: 0.9500, Loss validation: 1.4641, Acc validation: 0.7980, Loss test: 1.4462, Acc test: 0.8040\n",
            "Improved\n",
            "Loss train: 1.1170, Acc train: 0.9571, Loss validation: 1.4556, Acc validation: 0.8020, Loss test: 1.4373, Acc test: 0.8030\n",
            "Improved\n",
            "Loss train: 1.1065, Acc train: 0.9643, Loss validation: 1.4474, Acc validation: 0.7980, Loss test: 1.4289, Acc test: 0.8040\n",
            "Improved\n",
            "Loss train: 1.0964, Acc train: 0.9643, Loss validation: 1.4400, Acc validation: 0.7960, Loss test: 1.4214, Acc test: 0.8040\n",
            "Improved\n",
            "Loss train: 1.0865, Acc train: 0.9643, Loss validation: 1.4329, Acc validation: 0.7940, Loss test: 1.4141, Acc test: 0.8040\n",
            "Improved\n",
            "Loss train: 1.0767, Acc train: 0.9714, Loss validation: 1.4261, Acc validation: 0.7960, Loss test: 1.4070, Acc test: 0.7980\n",
            "Improved\n",
            "Loss train: 1.0671, Acc train: 0.9714, Loss validation: 1.4195, Acc validation: 0.7980, Loss test: 1.4000, Acc test: 0.7990\n",
            "Improved\n",
            "Loss train: 1.0577, Acc train: 0.9714, Loss validation: 1.4151, Acc validation: 0.7980, Loss test: 1.3950, Acc test: 0.8010\n",
            "Improved\n",
            "Loss train: 1.0482, Acc train: 0.9714, Loss validation: 1.4123, Acc validation: 0.7900, Loss test: 1.3915, Acc test: 0.8000\n",
            "Improved\n",
            "Loss train: 1.0390, Acc train: 0.9714, Loss validation: 1.4096, Acc validation: 0.7900, Loss test: 1.3882, Acc test: 0.8010\n",
            "Improved\n",
            "Loss train: 1.0300, Acc train: 0.9714, Loss validation: 1.4077, Acc validation: 0.7920, Loss test: 1.3858, Acc test: 0.7980\n",
            "Improved\n",
            "Loss train: 1.0211, Acc train: 0.9714, Loss validation: 1.4047, Acc validation: 0.7920, Loss test: 1.3826, Acc test: 0.7970\n",
            "Improved\n",
            "Loss train: 1.0124, Acc train: 0.9643, Loss validation: 1.4017, Acc validation: 0.7920, Loss test: 1.3796, Acc test: 0.7970\n",
            "Improved\n",
            "Loss train: 1.0040, Acc train: 0.9643, Loss validation: 1.3991, Acc validation: 0.7900, Loss test: 1.3769, Acc test: 0.7960\n",
            "Improved\n",
            "Loss train: 0.9958, Acc train: 0.9571, Loss validation: 1.3947, Acc validation: 0.7920, Loss test: 1.3726, Acc test: 0.7920\n",
            "Improved\n",
            "Loss train: 0.9883, Acc train: 0.9571, Loss validation: 1.3897, Acc validation: 0.8000, Loss test: 1.3675, Acc test: 0.7940\n",
            "Improved\n",
            "Loss train: 0.9811, Acc train: 0.9571, Loss validation: 1.3853, Acc validation: 0.7900, Loss test: 1.3631, Acc test: 0.7970\n",
            "Improved\n",
            "Loss train: 0.9741, Acc train: 0.9571, Loss validation: 1.3803, Acc validation: 0.7900, Loss test: 1.3581, Acc test: 0.8000\n",
            "Improved\n",
            "Loss train: 0.9670, Acc train: 0.9571, Loss validation: 1.3725, Acc validation: 0.7980, Loss test: 1.3502, Acc test: 0.8040\n",
            "Improved\n",
            "Loss train: 0.9601, Acc train: 0.9571, Loss validation: 1.3656, Acc validation: 0.7980, Loss test: 1.3431, Acc test: 0.8060\n",
            "Improved\n",
            "Loss train: 0.9531, Acc train: 0.9571, Loss validation: 1.3571, Acc validation: 0.7980, Loss test: 1.3346, Acc test: 0.8100\n",
            "Improved\n",
            "Loss train: 0.9462, Acc train: 0.9571, Loss validation: 1.3500, Acc validation: 0.7980, Loss test: 1.3275, Acc test: 0.8120\n",
            "Improved\n",
            "Loss train: 0.9394, Acc train: 0.9643, Loss validation: 1.3428, Acc validation: 0.8000, Loss test: 1.3202, Acc test: 0.8130\n",
            "Improved\n",
            "GAT (100 epochs)\n",
            "Elapsed: 11.00s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cora Data Using ARMA"
      ],
      "metadata": {
        "id": "PbKOG5XuNeO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "dataset = Citation(\"cora\", transforms=[LayerPreprocess(ARMAConv)])"
      ],
      "metadata": {
        "id": "3vbW0FCUIQAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weights\n",
        "mask_train, mask_validation, mask_test = dataset.mask_tr, dataset.mask_va, dataset.mask_te"
      ],
      "metadata": {
        "id": "GepXUNA0IWpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# params\n",
        "channels = 16  # number of channels in the first layer\n",
        "iterations = 1  # number of iterations to approximate each ARMA(1)\n",
        "order = 2  # order of the ARMA filter (number of parallel stacks)\n",
        "share_weights = True  # share weights in each ARMA stack\n",
        "dropout_skip = 0.75  # dropout rate for the internal skip connection of ARMA\n",
        "dropout = 0.5  # dropout rate for the features\n",
        "l2_reg = 5e-5  # l2 regularization rate\n",
        "learning_rate = 1e-2  # learning rate\n",
        "epochs = 20  # number of training epochs\n",
        "patience = 100  # patience for early stopping\n",
        "adj_matrix_dtype = dataset[0].a.dtype  # only needed for TF 2.1"
      ],
      "metadata": {
        "id": "zn_8z54aPz5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vars\n",
        "num_nodes = dataset.n_nodes  # number of nodes in the graph\n",
        "num_feat = dataset.n_node_features  # original size of node features\n",
        "num_labels = dataset.n_labels  # number of classes"
      ],
      "metadata": {
        "id": "lzLJoHu8QDwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "input = Input(shape=(num_feat,))\n",
        "adj_mat = Input((num_nodes,), sparse=True, dtype=adj_matrix_dtype)\n",
        "x = ARMAConv(\n",
        "    channels,\n",
        "    iterations=iterations,\n",
        "    order=order,\n",
        "    share_weights=share_weights,\n",
        "    dropout_rate=dropout_skip,\n",
        "    activation=\"elu\",\n",
        "    gcn_activation=\"elu\",\n",
        "    kernel_regularizer=l2(l2_reg)\n",
        "    )([input, adj_mat])\n",
        "x = Dropout(dropout)(x)\n",
        "output = ARMAConv(\n",
        "    num_labels,\n",
        "    iterations=1,\n",
        "    order=1,\n",
        "    share_weights=share_weights,\n",
        "    dropout_rate=dropout_skip,\n",
        "    activation=\"softmax\",\n",
        "    gcn_activation=None,\n",
        "    kernel_regularizer=l2(l2_reg)\n",
        "    )([x, adj_mat])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onlEQzXiQIQV",
        "outputId": "0dd60ada-ee52-4e5d-de13-28c414012260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "model = Model(inputs=[input, adj_mat], outputs=output)\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\",\n",
        "              weighted_metrics=[\"acc\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5HT2BP5QtxH",
        "outputId": "710eb5cd-1cdd-4b5b-ebf6-a03d89a7afd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)        [(None, 1433)]               0         []                            \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)        [(None, 2708)]               0         []                            \n",
            "                                                                                                  \n",
            " arma_conv (ARMAConv)        (None, 16)                   91744     ['input_7[0][0]',             \n",
            "                                                                     'input_8[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)        (None, 16)                   0         ['arma_conv[0][0]']           \n",
            "                                                                                                  \n",
            " arma_conv_1 (ARMAConv)      (None, 7)                    231       ['dropout_14[0][0]',          \n",
            "                                                                     'input_8[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 91975 (359.28 KB)\n",
            "Trainable params: 91975 (359.28 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "loader_train = SingleLoader(dataset, sample_weights=weights_train)\n",
        "loader_valid = SingleLoader(dataset, sample_weights=weights_valid)\n",
        "model.fit(\n",
        "    loader_train.load(),\n",
        "    steps_per_epoch=loader_train.steps_per_epoch,\n",
        "    validation_data=loader_valid.load(),\n",
        "    validation_steps=loader_valid.steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vofg_9kLQ8p8",
        "outputId": "88ab2973-ea18-459d-c8fd-a2b05543ad5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0083 - acc: 0.1429 - val_loss: 0.0067 - val_acc: 0.1640\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0067 - acc: 0.1929 - val_loss: 0.0052 - val_acc: 0.2220\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0053 - acc: 0.2357 - val_loss: 0.0040 - val_acc: 0.2740\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0041 - acc: 0.2786 - val_loss: 0.0031 - val_acc: 0.3840\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - acc: 0.4000 - val_loss: 0.0024 - val_acc: 0.5000\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0024 - acc: 0.4643 - val_loss: 0.0020 - val_acc: 0.6120\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - acc: 0.4857 - val_loss: 0.0018 - val_acc: 0.6960\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0017 - acc: 0.6143 - val_loss: 0.0017 - val_acc: 0.7180\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0017 - acc: 0.6714 - val_loss: 0.0017 - val_acc: 0.7400\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - acc: 0.6000 - val_loss: 0.0018 - val_acc: 0.7500\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - acc: 0.6286 - val_loss: 0.0019 - val_acc: 0.7480\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - acc: 0.6929 - val_loss: 0.0019 - val_acc: 0.7400\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - acc: 0.6214 - val_loss: 0.0020 - val_acc: 0.7340\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - acc: 0.6143 - val_loss: 0.0019 - val_acc: 0.7360\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - acc: 0.6357 - val_loss: 0.0019 - val_acc: 0.7480\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0018 - acc: 0.6571 - val_loss: 0.0018 - val_acc: 0.7440\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - acc: 0.6643 - val_loss: 0.0017 - val_acc: 0.7380\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - acc: 0.5929 - val_loss: 0.0016 - val_acc: 0.7380\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - acc: 0.6929 - val_loss: 0.0015 - val_acc: 0.7140\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - acc: 0.7429 - val_loss: 0.0014 - val_acc: 0.7060\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7dfdb80f2c20>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "print(\"Evaluating model.\")\n",
        "loader_test = SingleLoader(dataset, sample_weights=mask_test)\n",
        "eval_results = model.evaluate(loader_test.load(), steps=loader_te.steps_per_epoch)\n",
        "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjmWJKMuIW6G",
        "outputId": "c6680bef-bbc9-4c82-e0f6-50e7fa183236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model.\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.6251 - acc: 0.7600\n",
            "Done.\n",
            "Test loss: 0.6251000165939331\n",
            "Test accuracy: 0.7599999904632568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Citation networks SimpleGCN Custom Transform"
      ],
      "metadata": {
        "id": "1i8RMJYbRgjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define SGCN\n",
        "class SGCN:\n",
        "    def __init__(self, K):\n",
        "        self.K = K # propagation steps for SGCN\n",
        "    def __call__(self, graph):\n",
        "        output = graph.a\n",
        "        for _ in range(self.K-1):\n",
        "            output = output.dot(output)\n",
        "        output.sort_indices()\n",
        "        graph.a = output\n",
        "        return graph"
      ],
      "metadata": {
        "id": "iI9jS_Z_UAM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "K = 2  # propagation steps for SGCN\n",
        "dataset = Citation(\"cora\", transforms=[LayerPreprocess(GCNConv), SGCN(K)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMO_Ef-KUAX2",
        "outputId": "5ef0dd57-5eb7-4fd7-eafb-4a90004d936b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weights\n",
        "mask_train, mask_validation, mask_test = dataset.mask_tr, dataset.mask_va, dataset.mask_te"
      ],
      "metadata": {
        "id": "Ez0CFKVIU5Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# params\n",
        "l2_reg = 5e-6  # L2 regularization rate\n",
        "learning_rate = 0.2  # learning rate\n",
        "epochs = 20  # number of training epochs\n",
        "patience = 200  # patience for early stopping\n",
        "adj_matrix_dtype = dataset[0].a.dtype  # only needed for TF 2.1"
      ],
      "metadata": {
        "id": "uL-2P6flUAgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vars\n",
        "num_nodes = dataset.n_nodes  # number of nodes in the graph\n",
        "num_feat = dataset.n_node_features  # original size of node features\n",
        "num_labels = dataset.n_labels  # number of classes"
      ],
      "metadata": {
        "id": "MvZ2mIpZURtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "input = Input(shape=(num_feat,))\n",
        "adj_mat = Input((num_nodes,), sparse=True, dtype=adj_matrix_dtype)\n",
        "output = GCNConv(num_labels, activation=\"softmax\",\n",
        "                 kernel_regularizer=l2(l2_reg), use_bias=False)([input, adj_mat])"
      ],
      "metadata": {
        "id": "EVND6hAXUR4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "model = Model(inputs=[input, adj_mat], outputs=output)\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", weighted_metrics=[\"acc\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYEXV4jHVhFy",
        "outputId": "fa78dbe7-9305-4da1-e5ba-a411b4f88d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 1433)]               0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 2708)]               0         []                            \n",
            "                                                                                                  \n",
            " gcn_conv (GCNConv)          (None, 7)                    10031     ['input_1[0][0]',             \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10031 (39.18 KB)\n",
            "Trainable params: 10031 (39.18 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "loader_train = SingleLoader(dataset, sample_weights=weights_train)\n",
        "loader_valid = SingleLoader(dataset, sample_weights=weights_valid)\n",
        "model.fit(\n",
        "    loader_train.load(),\n",
        "    steps_per_epoch=loader_train.steps_per_epoch,\n",
        "    validation_data=loader_valid.load(),\n",
        "    validation_steps=loader_valid.steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po3fvGxQUSEQ",
        "outputId": "d079098f-39af-4a2a-a9bc-5b0928cca999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 7.9237e-04 - acc: 0.1000 - val_loss: 6.5436e-04 - val_acc: 0.6820\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.3699e-04 - acc: 0.9000 - val_loss: 6.4911e-04 - val_acc: 0.7580\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.8026e-04 - acc: 0.9571 - val_loss: 7.0950e-04 - val_acc: 0.7700\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.2773e-04 - acc: 0.9786 - val_loss: 7.3929e-04 - val_acc: 0.7700\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 5.5492e-04 - acc: 0.9857 - val_loss: 7.1382e-04 - val_acc: 0.7680\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.3130e-04 - acc: 0.9857 - val_loss: 6.6454e-04 - val_acc: 0.7600\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.9043e-04 - acc: 0.9857 - val_loss: 6.2570e-04 - val_acc: 0.7560\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.6868e-04 - acc: 0.9786 - val_loss: 6.0884e-04 - val_acc: 0.7560\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.7360e-04 - acc: 0.9786 - val_loss: 6.0598e-04 - val_acc: 0.7600\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.8725e-04 - acc: 0.9571 - val_loss: 6.0550e-04 - val_acc: 0.7600\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.9087e-04 - acc: 0.9286 - val_loss: 6.0362e-04 - val_acc: 0.7520\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.8188e-04 - acc: 0.9214 - val_loss: 6.0351e-04 - val_acc: 0.7520\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.6968e-04 - acc: 0.9286 - val_loss: 6.0817e-04 - val_acc: 0.7580\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.6287e-04 - acc: 0.9286 - val_loss: 6.1646e-04 - val_acc: 0.7640\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.6270e-04 - acc: 0.9357 - val_loss: 6.2384e-04 - val_acc: 0.7740\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.6472e-04 - acc: 0.9500 - val_loss: 6.2591e-04 - val_acc: 0.7680\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.6435e-04 - acc: 0.9714 - val_loss: 6.2169e-04 - val_acc: 0.7700\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.6094e-04 - acc: 0.9857 - val_loss: 6.1346e-04 - val_acc: 0.7700\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.5680e-04 - acc: 0.9857 - val_loss: 6.0447e-04 - val_acc: 0.7660\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.5402e-04 - acc: 0.9857 - val_loss: 5.9742e-04 - val_acc: 0.7720\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7dfdacd7e890>"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "print(\"Evaluating model.\")\n",
        "loader_test = SingleLoader(dataset, sample_weights=mask_test)\n",
        "eval_results = model.evaluate(loader_test.load(), steps=loader_te.steps_per_epoch)\n",
        "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XQkFPfnUAo4",
        "outputId": "33a16937-aab3-4c69-e70f-ba7c706612e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model.\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.4532 - acc: 0.8020\n",
            "Done.\n",
            "Test loss: 0.4532226026058197\n",
            "Test accuracy: 0.8019999861717224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Open Graph Benchmark Dataset"
      ],
      "metadata": {
        "id": "wxpuoCBvRhK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clear_session()"
      ],
      "metadata": {
        "id": "qyJE6pMqr1bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "dataset_name = \"ogbn-arxiv\"\n",
        "ogb_dataset = NodePropPredDataset(dataset_name)\n",
        "dataset = OGB(ogb_dataset, transforms=[GCNFilter(), AdjToSpTensor()])"
      ],
      "metadata": {
        "id": "K_QUj45FYVuR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de2a048-e1a6-49ff-cb0f-b8d345be2581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.08 GB: 100%|| 81/81 [00:05<00:00, 15.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/arxiv.zip\n",
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1/1 [00:00<00:00, 1665.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# graph\n",
        "graph = dataset[0]\n",
        "nodes, adj_matrix, labels = graph.x, graph.a, graph.y"
      ],
      "metadata": {
        "id": "SmMTGVWZYV6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# params\n",
        "channels = 256  # number of channels for GCN layers\n",
        "dropout = 0.5  # dropout rate for the features\n",
        "learning_rate = 1e-2  # learning rate\n",
        "epochs = 20  # number of training epochs"
      ],
      "metadata": {
        "id": "2Rz6RWU6YWFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vars\n",
        "num_nodes = dataset.n_nodes  # number of nodes in the graph\n",
        "num_feat = dataset.n_node_features  # original size of node features\n",
        "num_labels = ogb_dataset.num_classes  # number of classes"
      ],
      "metadata": {
        "id": "xPP8_NWWYerG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data splits\n",
        "idx = ogb_dataset.get_idx_split()\n",
        "idx_train, idx_val, idx_test = idx[\"train\"], idx[\"valid\"], idx[\"test\"]\n",
        "mask_train = np.zeros(num_nodes, dtype=bool)\n",
        "mask_valid = np.zeros(num_nodes, dtype=bool)\n",
        "mask_test = np.zeros(num_nodes, dtype=bool)\n",
        "mask_train[idx_train] = True\n",
        "mask_valid[idx_val] = True\n",
        "mask_test[idx_test] = True\n",
        "masks = [mask_train, mask_valid, mask_test]"
      ],
      "metadata": {
        "id": "B-lRRfqcYe1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "node_input = Input(shape=(num_feat,))\n",
        "adj_mat_input = Input((num_nodes,), sparse=True)\n",
        "x = GCNConv(channels, activation=\"relu\")([node_input, adj_mat_input])\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(dropout)(x)\n",
        "x = GCNConv(channels, activation=\"relu\")([x, adj_mat_input])\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(dropout)(x)\n",
        "output = GCNConv(num_labels, activation=\"softmax\")([x, adj_mat_input])"
      ],
      "metadata": {
        "id": "Fq5yl3ElYheh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "model = Model(inputs=[node_input, adj_mat_input], outputs=output)\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "loss_func = SparseCategoricalCrossentropy()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e91FQpwlYjdE",
        "outputId": "d239d5eb-878b-4614-c2b0-0f53e9775417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 128)]                0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 169343)]             0         []                            \n",
            "                                                                                                  \n",
            " gcn_conv (GCNConv)          (None, 256)                  33024     ['input_1[0][0]',             \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 256)                  1024      ['gcn_conv[0][0]']            \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 256)                  0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " gcn_conv_1 (GCNConv)        (None, 256)                  65792     ['dropout[0][0]',             \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 256)                  1024      ['gcn_conv_1[0][0]']          \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 256)                  0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " gcn_conv_2 (GCNConv)        (None, 40)                   10280     ['dropout_1[0][0]',           \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 111144 (434.16 KB)\n",
            "Trainable params: 110120 (430.16 KB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training function\n",
        "@tf.function\n",
        "def train(inputs, target, mask):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = loss_func(target[mask], predictions[mask]) + sum(model.losses)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "HYjbc4nyYjns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation with OGB\n",
        "evaluator = Evaluator(dataset_name)"
      ],
      "metadata": {
        "id": "e3BAzv-bYmgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train and evaluate model\n",
        "def evaluate(nodes, adj_mat, labels, model, masks, evaluator):\n",
        "    pred = model([nodes, adj_mat], training=False)\n",
        "    pred = pred.numpy().argmax(-1)[:, None]\n",
        "    train_mask, val_mask, test_mask = masks\n",
        "    train_auc = evaluator.eval({\"y_true\": labels[train_mask], \"y_pred\": pred[train_mask]})[\"acc\"]\n",
        "    val_auc = evaluator.eval({\"y_true\": labels[val_mask], \"y_pred\": pred[val_mask]})[\"acc\"]\n",
        "    test_auc = evaluator.eval({\"y_true\": labels[test_mask], \"y_pred\": pred[test_mask]})[\"acc\"]\n",
        "    return train_auc, val_auc, test_auc\n",
        "\n",
        "for i in range(1, 1 + epochs):\n",
        "    train_loss = train([nodes, adj_matrix], labels, mask_train)\n",
        "    train_acc, val_acc, test_acc = evaluate(nodes, adj_matrix, labels, model, masks, evaluator)\n",
        "    print(\n",
        "        \"Ep. {} - Loss: {:.3f} - Acc: {:.3f} - Val acc: {:.3f} - Test acc: \"\n",
        "        \"{:.3f}\".format(i, train_loss, train_acc, val_acc, test_acc)\n",
        "        )\n",
        "print(\"Evaluating model!\")\n",
        "train_acc, val_acc, test_acc = evaluate(nodes, adj_matrix, labels, model, masks, evaluator)\n",
        "print(\"Done! - Test acc: {:.3f}\".format(test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M09gOWxXYyIR",
        "outputId": "712fb716-1ea1-4a87-af35-6434557de115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep. 1 - Loss: 5.482 - Acc: 0.186 - Val acc: 0.336 - Test acc: 0.343\n",
            "Ep. 2 - Loss: 3.007 - Acc: 0.180 - Val acc: 0.193 - Test acc: 0.206\n",
            "Ep. 3 - Loss: 2.619 - Acc: 0.224 - Val acc: 0.274 - Test acc: 0.332\n",
            "Ep. 4 - Loss: 2.248 - Acc: 0.153 - Val acc: 0.165 - Test acc: 0.158\n",
            "Ep. 5 - Loss: 2.143 - Acc: 0.124 - Val acc: 0.139 - Test acc: 0.134\n",
            "Ep. 6 - Loss: 2.002 - Acc: 0.115 - Val acc: 0.129 - Test acc: 0.124\n",
            "Ep. 7 - Loss: 1.932 - Acc: 0.074 - Val acc: 0.064 - Test acc: 0.059\n",
            "Ep. 8 - Loss: 1.884 - Acc: 0.042 - Val acc: 0.032 - Test acc: 0.024\n",
            "Ep. 9 - Loss: 1.827 - Acc: 0.029 - Val acc: 0.021 - Test acc: 0.013\n",
            "Ep. 10 - Loss: 1.799 - Acc: 0.019 - Val acc: 0.012 - Test acc: 0.007\n",
            "Ep. 11 - Loss: 1.768 - Acc: 0.012 - Val acc: 0.007 - Test acc: 0.004\n",
            "Ep. 12 - Loss: 1.740 - Acc: 0.006 - Val acc: 0.004 - Test acc: 0.002\n",
            "Ep. 13 - Loss: 1.715 - Acc: 0.004 - Val acc: 0.003 - Test acc: 0.002\n",
            "Ep. 14 - Loss: 1.702 - Acc: 0.003 - Val acc: 0.002 - Test acc: 0.001\n",
            "Ep. 15 - Loss: 1.678 - Acc: 0.003 - Val acc: 0.002 - Test acc: 0.001\n",
            "Ep. 16 - Loss: 1.653 - Acc: 0.003 - Val acc: 0.003 - Test acc: 0.001\n",
            "Ep. 17 - Loss: 1.644 - Acc: 0.003 - Val acc: 0.003 - Test acc: 0.002\n",
            "Ep. 18 - Loss: 1.625 - Acc: 0.004 - Val acc: 0.003 - Test acc: 0.002\n",
            "Ep. 19 - Loss: 1.607 - Acc: 0.005 - Val acc: 0.005 - Test acc: 0.003\n",
            "Ep. 20 - Loss: 1.603 - Acc: 0.009 - Val acc: 0.007 - Test acc: 0.006\n",
            "Evaluating model!\n",
            "Done! - Test acc: 0.006\n"
          ]
        }
      ]
    }
  ]
}